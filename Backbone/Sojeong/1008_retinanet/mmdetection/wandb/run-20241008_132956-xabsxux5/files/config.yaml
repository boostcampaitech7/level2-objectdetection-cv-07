_cfg_dict:
    value:
        auto_scale_lr:
            base_batch_size: 16
            enable: false
        checkpoint_config:
            interval: 1
        custom_hooks:
            - type: NumClassCheckHook
        data:
            samples_per_gpu: 2
            test:
                ann_file: data/coco/annotations/instances_val2017.json
                img_prefix: data/coco/val2017/
                pipeline:
                    - type: LoadImageFromFile
                    - flip: false
                      img_scale:
                        - 1333
                        - 800
                      transforms:
                        - keep_ratio: true
                          type: Resize
                        - type: RandomFlip
                        - mean:
                            - 123.675
                            - 116.28
                            - 103.53
                          std:
                            - 58.395
                            - 57.12
                            - 57.375
                          to_rgb: true
                          type: Normalize
                        - size_divisor: 32
                          type: Pad
                        - keys:
                            - img
                          type: ImageToTensor
                        - keys:
                            - img
                          type: Collect
                      type: MultiScaleFlipAug
                type: CocoDataset
            train:
                ann_file: data/coco/annotations/instances_train2017.json
                img_prefix: data/coco/train2017/
                pipeline:
                    - type: LoadImageFromFile
                    - type: LoadAnnotations
                      with_bbox: true
                    - img_scale:
                        - 1333
                        - 800
                      keep_ratio: true
                      type: Resize
                    - flip_ratio: 0.5
                      type: RandomFlip
                    - mean:
                        - 123.675
                        - 116.28
                        - 103.53
                      std:
                        - 58.395
                        - 57.12
                        - 57.375
                      to_rgb: true
                      type: Normalize
                    - size_divisor: 32
                      type: Pad
                    - type: DefaultFormatBundle
                    - keys:
                        - img
                        - gt_bboxes
                        - gt_labels
                      type: Collect
                type: CocoDataset
            val:
                ann_file: data/coco/annotations/instances_val2017.json
                img_prefix: data/coco/val2017/
                pipeline:
                    - type: LoadImageFromFile
                    - flip: false
                      img_scale:
                        - 1333
                        - 800
                      transforms:
                        - keep_ratio: true
                          type: Resize
                        - type: RandomFlip
                        - mean:
                            - 123.675
                            - 116.28
                            - 103.53
                          std:
                            - 58.395
                            - 57.12
                            - 57.375
                          to_rgb: true
                          type: Normalize
                        - size_divisor: 32
                          type: Pad
                        - keys:
                            - img
                          type: ImageToTensor
                        - keys:
                            - img
                          type: Collect
                      type: MultiScaleFlipAug
                type: CocoDataset
            workers_per_gpu: 2
        data_root: data/coco/
        dataset_type: CocoDataset
        dist_params:
            backend: nccl
        evaluation:
            interval: 1
            metric: bbox
        img_norm_cfg:
            mean:
                - 123.675
                - 116.28
                - 103.53
            std:
                - 58.395
                - 57.12
                - 57.375
            to_rgb: true
        load_from: null
        log_config:
            hooks:
                - type: TextLoggerHook
            interval: 50
        log_level: INFO
        lr_config:
            policy: step
            step:
                - 8
                - 11
            warmup: linear
            warmup_iters: 500
            warmup_ratio: 0.001
        model:
            backbone:
                depth: 50
                frozen_stages: 1
                init_cfg:
                    checkpoint: torchvision://resnet50
                    type: Pretrained
                norm_cfg:
                    requires_grad: true
                    type: BN
                norm_eval: true
                num_stages: 4
                out_indices:
                    - 0
                    - 1
                    - 2
                    - 3
                style: pytorch
                type: ResNet
            neck:
                in_channels:
                    - 256
                    - 512
                    - 1024
                    - 2048
                num_outs: 5
                out_channels: 256
                type: FPN
            roi_head:
                bbox_head:
                    bbox_coder:
                        target_means:
                            - 0
                            - 0
                            - 0
                            - 0
                        target_stds:
                            - 0.1
                            - 0.1
                            - 0.2
                            - 0.2
                        type: DeltaXYWHBBoxCoder
                    fc_out_channels: 1024
                    in_channels: 256
                    loss_bbox:
                        loss_weight: 1
                        type: L1Loss
                    loss_cls:
                        loss_weight: 1
                        type: CrossEntropyLoss
                        use_sigmoid: false
                    num_classes: 80
                    reg_class_agnostic: false
                    roi_feat_size: 7
                    type: Shared2FCBBoxHead
                bbox_roi_extractor:
                    featmap_strides:
                        - 4
                        - 8
                        - 16
                        - 32
                    out_channels: 256
                    roi_layer:
                        output_size: 7
                        sampling_ratio: 0
                        type: RoIAlign
                    type: SingleRoIExtractor
                type: StandardRoIHead
            rpn_head:
                anchor_generator:
                    ratios:
                        - 0.5
                        - 1
                        - 2
                    scales:
                        - 8
                    strides:
                        - 4
                        - 8
                        - 16
                        - 32
                        - 64
                    type: AnchorGenerator
                bbox_coder:
                    target_means:
                        - 0
                        - 0
                        - 0
                        - 0
                    target_stds:
                        - 1
                        - 1
                        - 1
                        - 1
                    type: DeltaXYWHBBoxCoder
                feat_channels: 256
                in_channels: 256
                loss_bbox:
                    loss_weight: 1
                    type: L1Loss
                loss_cls:
                    loss_weight: 1
                    type: CrossEntropyLoss
                    use_sigmoid: true
                type: RPNHead
            test_cfg:
                rcnn:
                    max_per_img: 100
                    nms:
                        iou_threshold: 0.5
                        type: nms
                    score_thr: 0.05
                rpn:
                    max_per_img: 1000
                    min_bbox_size: 0
                    nms:
                        iou_threshold: 0.7
                        type: nms
                    nms_pre: 1000
            train_cfg:
                rcnn:
                    assigner:
                        ignore_iof_thr: -1
                        match_low_quality: false
                        min_pos_iou: 0.5
                        neg_iou_thr: 0.5
                        pos_iou_thr: 0.5
                        type: MaxIoUAssigner
                    debug: false
                    pos_weight: -1
                    sampler:
                        add_gt_as_proposals: true
                        neg_pos_ub: -1
                        num: 512
                        pos_fraction: 0.25
                        type: RandomSampler
                rpn:
                    allowed_border: -1
                    assigner:
                        ignore_iof_thr: -1
                        match_low_quality: true
                        min_pos_iou: 0.3
                        neg_iou_thr: 0.3
                        pos_iou_thr: 0.7
                        type: MaxIoUAssigner
                    debug: false
                    pos_weight: -1
                    sampler:
                        add_gt_as_proposals: false
                        neg_pos_ub: -1
                        num: 256
                        pos_fraction: 0.5
                        type: RandomSampler
                rpn_proposal:
                    max_per_img: 1000
                    min_bbox_size: 0
                    nms:
                        iou_threshold: 0.7
                        type: nms
                    nms_pre: 2000
            type: FasterRCNN
        mp_start_method: fork
        opencv_num_threads: 0
        optimizer:
            lr: 0.02
            momentum: 0.9
            type: SGD
            weight_decay: 0.0001
        optimizer_config:
            grad_clip: null
        resume_from: null
        runner:
            max_epochs: 12
            type: EpochBasedRunner
        test_pipeline:
            - type: LoadImageFromFile
            - flip: false
              img_scale:
                - 1333
                - 800
              transforms:
                - keep_ratio: true
                  type: Resize
                - type: RandomFlip
                - mean:
                    - 123.675
                    - 116.28
                    - 103.53
                  std:
                    - 58.395
                    - 57.12
                    - 57.375
                  to_rgb: true
                  type: Normalize
                - size_divisor: 32
                  type: Pad
                - keys:
                    - img
                  type: ImageToTensor
                - keys:
                    - img
                  type: Collect
              type: MultiScaleFlipAug
        train_pipeline:
            - type: LoadImageFromFile
            - type: LoadAnnotations
              with_bbox: true
            - img_scale:
                - 1333
                - 800
              keep_ratio: true
              type: Resize
            - flip_ratio: 0.5
              type: RandomFlip
            - mean:
                - 123.675
                - 116.28
                - 103.53
              std:
                - 58.395
                - 57.12
                - 57.375
              to_rgb: true
              type: Normalize
            - size_divisor: 32
              type: Pad
            - type: DefaultFormatBundle
            - keys:
                - img
                - gt_bboxes
                - gt_labels
              type: Collect
        workflow:
            - - train
              - 1
_filename:
    value: ./configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py
_text:
    value: |
        /data/ephemeral/home/Sojeong/level2-objectdetection-cv-07/Backbone/Sojeong/1008_retinanet/mmdetection/configs/_base_/models/faster_rcnn_r50_fpn.py
        # model settings
        model = dict(
            type='FasterRCNN',
            backbone=dict(
                type='ResNet',
                depth=50,
                num_stages=4,
                out_indices=(0, 1, 2, 3),
                frozen_stages=1,
                norm_cfg=dict(type='BN', requires_grad=True),
                norm_eval=True,
                style='pytorch',
                init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),
            neck=dict(
                type='FPN',
                in_channels=[256, 512, 1024, 2048],
                out_channels=256,
                num_outs=5),
            rpn_head=dict(
                type='RPNHead',
                in_channels=256,
                feat_channels=256,
                anchor_generator=dict(
                    type='AnchorGenerator',
                    scales=[8],
                    ratios=[0.5, 1.0, 2.0],
                    strides=[4, 8, 16, 32, 64]),
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[.0, .0, .0, .0],
                    target_stds=[1.0, 1.0, 1.0, 1.0]),
                loss_cls=dict(
                    type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
                loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
            roi_head=dict(
                type='StandardRoIHead',
                bbox_roi_extractor=dict(
                    type='SingleRoIExtractor',
                    roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
                    out_channels=256,
                    featmap_strides=[4, 8, 16, 32]),
                bbox_head=dict(
                    type='Shared2FCBBoxHead',
                    in_channels=256,
                    fc_out_channels=1024,
                    roi_feat_size=7,
                    num_classes=80,
                    bbox_coder=dict(
                        type='DeltaXYWHBBoxCoder',
                        target_means=[0., 0., 0., 0.],
                        target_stds=[0.1, 0.1, 0.2, 0.2]),
                    reg_class_agnostic=False,
                    loss_cls=dict(
                        type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
                    loss_bbox=dict(type='L1Loss', loss_weight=1.0))),
            # model training and testing settings
            train_cfg=dict(
                rpn=dict(
                    assigner=dict(
                        type='MaxIoUAssigner',
                        pos_iou_thr=0.7,
                        neg_iou_thr=0.3,
                        min_pos_iou=0.3,
                        match_low_quality=True,
                        ignore_iof_thr=-1),
                    sampler=dict(
                        type='RandomSampler',
                        num=256,
                        pos_fraction=0.5,
                        neg_pos_ub=-1,
                        add_gt_as_proposals=False),
                    allowed_border=-1,
                    pos_weight=-1,
                    debug=False),
                rpn_proposal=dict(
                    nms_pre=2000,
                    max_per_img=1000,
                    nms=dict(type='nms', iou_threshold=0.7),
                    min_bbox_size=0),
                rcnn=dict(
                    assigner=dict(
                        type='MaxIoUAssigner',
                        pos_iou_thr=0.5,
                        neg_iou_thr=0.5,
                        min_pos_iou=0.5,
                        match_low_quality=False,
                        ignore_iof_thr=-1),
                    sampler=dict(
                        type='RandomSampler',
                        num=512,
                        pos_fraction=0.25,
                        neg_pos_ub=-1,
                        add_gt_as_proposals=True),
                    pos_weight=-1,
                    debug=False)),
            test_cfg=dict(
                rpn=dict(
                    nms_pre=1000,
                    max_per_img=1000,
                    nms=dict(type='nms', iou_threshold=0.7),
                    min_bbox_size=0),
                rcnn=dict(
                    score_thr=0.05,
                    nms=dict(type='nms', iou_threshold=0.5),
                    max_per_img=100)
                # soft-nms is also supported for rcnn testing
                # e.g., nms=dict(type='soft_nms', iou_threshold=0.5, min_score=0.05)
            ))

        /data/ephemeral/home/Sojeong/level2-objectdetection-cv-07/Backbone/Sojeong/1008_retinanet/mmdetection/configs/_base_/datasets/coco_detection.py
        # dataset settings
        dataset_type = 'CocoDataset'
        data_root = 'data/coco/'
        img_norm_cfg = dict(
            mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
        train_pipeline = [
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),
        ]
        test_pipeline = [
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(type='Normalize', **img_norm_cfg),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img']),
                ])
        ]
        data = dict(
            samples_per_gpu=2,
            workers_per_gpu=2,
            train=dict(
                type=dataset_type,
                ann_file=data_root + 'annotations/instances_train2017.json',
                img_prefix=data_root + 'train2017/',
                pipeline=train_pipeline),
            val=dict(
                type=dataset_type,
                ann_file=data_root + 'annotations/instances_val2017.json',
                img_prefix=data_root + 'val2017/',
                pipeline=test_pipeline),
            test=dict(
                type=dataset_type,
                ann_file=data_root + 'annotations/instances_val2017.json',
                img_prefix=data_root + 'val2017/',
                pipeline=test_pipeline))
        evaluation = dict(interval=1, metric='bbox')

        /data/ephemeral/home/Sojeong/level2-objectdetection-cv-07/Backbone/Sojeong/1008_retinanet/mmdetection/configs/_base_/schedules/schedule_1x.py
        # optimizer
        optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)
        optimizer_config = dict(grad_clip=None)
        # learning policy
        lr_config = dict(
            policy='step',
            warmup='linear',
            warmup_iters=500,
            warmup_ratio=0.001,
            step=[8, 11])
        runner = dict(type='EpochBasedRunner', max_epochs=12)

        /data/ephemeral/home/Sojeong/level2-objectdetection-cv-07/Backbone/Sojeong/1008_retinanet/mmdetection/configs/_base_/default_runtime.py
        checkpoint_config = dict(interval=1)
        # yapf:disable
        log_config = dict(
            interval=50,
            hooks=[
                dict(type='TextLoggerHook'),
                # dict(type='TensorboardLoggerHook')
            ])
        # yapf:enable
        custom_hooks = [dict(type='NumClassCheckHook')]

        dist_params = dict(backend='nccl')
        log_level = 'INFO'
        load_from = None
        resume_from = None
        workflow = [('train', 1)]

        # disable opencv multithreading to avoid system being overloaded
        opencv_num_threads = 0
        # set multi-process start method as `fork` to speed up the training
        mp_start_method = 'fork'

        # Default setting for scaling LR automatically
        #   - `enable` means enable scaling LR automatically
        #       or not by default.
        #   - `base_batch_size` = (8 GPUs) x (2 samples per GPU).
        auto_scale_lr = dict(enable=False, base_batch_size=16)

        /data/ephemeral/home/Sojeong/level2-objectdetection-cv-07/Backbone/Sojeong/1008_retinanet/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py
        _base_ = [
            '../_base_/models/faster_rcnn_r50_fpn.py',
            '../_base_/datasets/coco_detection.py',
            '../_base_/schedules/schedule_1x.py', '../_base_/default_runtime.py'
        ]
_wandb:
    value:
        cli_version: 0.18.3
        m: []
        python_version: 3.10.13
        t:
            "1":
                - 1
                - 5
                - 37
                - 38
                - 41
                - 53
                - 55
                - 80
            "2":
                - 1
                - 5
                - 37
                - 38
                - 41
                - 53
                - 55
                - 80
            "3":
                - 13
                - 16
                - 23
                - 55
            "4": 3.10.13
            "5": 0.18.3
            "8":
                - 5
            "12": 0.18.3
            "13": linux-x86_64
checkpoint_interval:
    value: 1
classes:
    value:
        - General trash
        - Paper
        - Paper pack
        - Metal
        - Glass
        - Plastic
        - Styrofoam
        - Plastic bag
        - Battery
        - Clothing
config_path:
    value: ./configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py
gpu_ids:
    value:
        - 0
grad_clip_max_norm:
    value: 35
grad_clip_norm_type:
    value: 2
img_scale:
    value:
        - 512
        - 512
max_keep_ckpts:
    value: 3
num_classes:
    value: 10
root:
    value: /data/ephemeral/home/data/dataset/
samples_per_gpu:
    value: 4
seed:
    value: 2022
wandb_entity:
    value: null
wandb_project:
    value: faster-rcnn-training
wandb_run_name:
    value: faster-rcnn-run
work_dir:
    value: ./work_dirs/faster_rcnn_r50_fpn_1x_trash
