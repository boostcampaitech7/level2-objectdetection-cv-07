_cfg_dict:
    value:
        auto_scale_lr:
            base_batch_size: 16
            enable: false
        checkpoint_config:
            interval: 1
            max_keep_ckpts: 3
        custom_hooks:
            - type: NumClassCheckHook
        data:
            samples_per_gpu: 4
            test:
                ann_file: /data/ephemeral/home/data/dataset/test.json
                classes:
                    - General trash
                    - Paper
                    - Paper pack
                    - Metal
                    - Glass
                    - Plastic
                    - Styrofoam
                    - Plastic bag
                    - Battery
                    - Clothing
                img_prefix: /data/ephemeral/home/data/dataset/
                pipeline:
                    - type: LoadImageFromFile
                    - flip: false
                      img_scale:
                        - 512
                        - 512
                      transforms:
                        - keep_ratio: true
                          type: Resize
                        - type: RandomFlip
                        - mean:
                            - 123.675
                            - 116.28
                            - 103.53
                          std:
                            - 58.395
                            - 57.12
                            - 57.375
                          to_rgb: true
                          type: Normalize
                        - size_divisor: 32
                          type: Pad
                        - keys:
                            - img
                          type: ImageToTensor
                        - keys:
                            - img
                          type: Collect
                      type: MultiScaleFlipAug
                type: CocoDataset
            train:
                ann_file: /data/ephemeral/home/data/dataset/train.json
                classes:
                    - General trash
                    - Paper
                    - Paper pack
                    - Metal
                    - Glass
                    - Plastic
                    - Styrofoam
                    - Plastic bag
                    - Battery
                    - Clothing
                img_prefix: /data/ephemeral/home/data/dataset/
                pipeline:
                    - type: LoadImageFromFile
                    - type: LoadAnnotations
                      with_bbox: true
                    - img_scale:
                        - 512
                        - 512
                      keep_ratio: true
                      type: Resize
                    - flip_ratio: 0.5
                      type: RandomFlip
                    - mean:
                        - 123.675
                        - 116.28
                        - 103.53
                      std:
                        - 58.395
                        - 57.12
                        - 57.375
                      to_rgb: true
                      type: Normalize
                    - size_divisor: 32
                      type: Pad
                    - type: DefaultFormatBundle
                    - keys:
                        - img
                        - gt_bboxes
                        - gt_labels
                      type: Collect
                type: CocoDataset
            val:
                ann_file: data/coco/annotations/instances_val2017.json
                img_prefix: data/coco/val2017/
                pipeline:
                    - type: LoadImageFromFile
                    - flip: false
                      img_scale:
                        - 1333
                        - 800
                      transforms:
                        - keep_ratio: true
                          type: Resize
                        - type: RandomFlip
                        - mean:
                            - 123.675
                            - 116.28
                            - 103.53
                          std:
                            - 58.395
                            - 57.12
                            - 57.375
                          to_rgb: true
                          type: Normalize
                        - size_divisor: 32
                          type: Pad
                        - keys:
                            - img
                          type: ImageToTensor
                        - keys:
                            - img
                          type: Collect
                      type: MultiScaleFlipAug
                type: CocoDataset
            workers_per_gpu: 2
        data_root: data/coco/
        dataset_type: CocoDataset
        device: cuda
        dist_params:
            backend: nccl
        evaluation:
            interval: 1
            metric: bbox
        gpu_ids:
            - 0
        img_norm_cfg:
            mean:
                - 123.675
                - 116.28
                - 103.53
            std:
                - 58.395
                - 57.12
                - 57.375
            to_rgb: true
        load_from: null
        log_config:
            hooks:
                - type: TextLoggerHook
            interval: 50
        log_level: INFO
        lr_config:
            policy: step
            step:
                - 8
                - 11
            warmup: linear
            warmup_iters: 500
            warmup_ratio: 0.001
        model:
            backbone:
                depth: 50
                frozen_stages: 1
                init_cfg:
                    checkpoint: torchvision://resnet50
                    type: Pretrained
                norm_cfg:
                    requires_grad: true
                    type: BN
                norm_eval: true
                num_stages: 4
                out_indices:
                    - 0
                    - 1
                    - 2
                    - 3
                style: pytorch
                type: ResNet
            bbox_head:
                anchor_generator:
                    octave_base_scale: 4
                    ratios:
                        - 0.5
                        - 1
                        - 2
                    scales_per_octave: 3
                    strides:
                        - 8
                        - 16
                        - 32
                        - 64
                        - 128
                    type: AnchorGenerator
                bbox_coder:
                    target_means:
                        - 0
                        - 0
                        - 0
                        - 0
                    target_stds:
                        - 1
                        - 1
                        - 1
                        - 1
                    type: DeltaXYWHBBoxCoder
                feat_channels: 256
                in_channels: 256
                loss_bbox:
                    loss_weight: 1
                    type: L1Loss
                loss_cls:
                    alpha: 0.25
                    gamma: 2
                    loss_weight: 1
                    type: FocalLoss
                    use_sigmoid: true
                num_classes: 10
                stacked_convs: 4
                type: RetinaHead
            neck:
                add_extra_convs: on_input
                in_channels:
                    - 256
                    - 512
                    - 1024
                    - 2048
                num_outs: 5
                out_channels: 256
                start_level: 1
                type: FPN
            test_cfg:
                max_per_img: 100
                min_bbox_size: 0
                nms:
                    iou_threshold: 0.5
                    type: nms
                nms_pre: 1000
                score_thr: 0.05
            train_cfg:
                allowed_border: -1
                assigner:
                    ignore_iof_thr: -1
                    min_pos_iou: 0
                    neg_iou_thr: 0.4
                    pos_iou_thr: 0.5
                    type: MaxIoUAssigner
                debug: false
                pos_weight: -1
            type: RetinaNet
        mp_start_method: fork
        opencv_num_threads: 0
        optimizer:
            lr: 0.01
            momentum: 0.9
            type: SGD
            weight_decay: 0.0001
        optimizer_config:
            grad_clip:
                max_norm: 35
                norm_type: 2
        resume_from: null
        runner:
            max_epochs: 12
            type: EpochBasedRunner
        seed: 2022
        test_pipeline:
            - type: LoadImageFromFile
            - flip: false
              img_scale:
                - 1333
                - 800
              transforms:
                - keep_ratio: true
                  type: Resize
                - type: RandomFlip
                - mean:
                    - 123.675
                    - 116.28
                    - 103.53
                  std:
                    - 58.395
                    - 57.12
                    - 57.375
                  to_rgb: true
                  type: Normalize
                - size_divisor: 32
                  type: Pad
                - keys:
                    - img
                  type: ImageToTensor
                - keys:
                    - img
                  type: Collect
              type: MultiScaleFlipAug
        train_pipeline:
            - type: LoadImageFromFile
            - type: LoadAnnotations
              with_bbox: true
            - img_scale:
                - 1333
                - 800
              keep_ratio: true
              type: Resize
            - flip_ratio: 0.5
              type: RandomFlip
            - mean:
                - 123.675
                - 116.28
                - 103.53
              std:
                - 58.395
                - 57.12
                - 57.375
              to_rgb: true
              type: Normalize
            - size_divisor: 32
              type: Pad
            - type: DefaultFormatBundle
            - keys:
                - img
                - gt_bboxes
                - gt_labels
              type: Collect
        work_dir: ./work_dirs/retinanet
        workflow:
            - - train
              - 1
_filename:
    value: ./configs/retinanet/retinanet_r50_fpn_1x_coco.py
_text:
    value: |
        /data/ephemeral/home/Sojeong/level2-objectdetection-cv-07/Backbone/Sojeong/1008_retinanet/mmdetection/configs/_base_/models/retinanet_r50_fpn.py
        # model settings
        model = dict(
            type='RetinaNet',
            backbone=dict(
                type='ResNet',
                depth=50,
                num_stages=4,
                out_indices=(0, 1, 2, 3),
                frozen_stages=1,
                norm_cfg=dict(type='BN', requires_grad=True),
                norm_eval=True,
                style='pytorch',
                init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),
            neck=dict(
                type='FPN',
                in_channels=[256, 512, 1024, 2048],
                out_channels=256,
                start_level=1,
                add_extra_convs='on_input',
                num_outs=5),
            bbox_head=dict(
                type='RetinaHead',
                num_classes=80,
                in_channels=256,
                stacked_convs=4,
                feat_channels=256,
                anchor_generator=dict(
                    type='AnchorGenerator',
                    octave_base_scale=4,
                    scales_per_octave=3,
                    ratios=[0.5, 1.0, 2.0],
                    strides=[8, 16, 32, 64, 128]),
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[.0, .0, .0, .0],
                    target_stds=[1.0, 1.0, 1.0, 1.0]),
                loss_cls=dict(
                    type='FocalLoss',
                    use_sigmoid=True,
                    gamma=2.0,
                    alpha=0.25,
                    loss_weight=1.0),
                loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
            # model training and testing settings
            train_cfg=dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.4,
                    min_pos_iou=0,
                    ignore_iof_thr=-1),
                allowed_border=-1,
                pos_weight=-1,
                debug=False),
            test_cfg=dict(
                nms_pre=1000,
                min_bbox_size=0,
                score_thr=0.05,
                nms=dict(type='nms', iou_threshold=0.5),
                max_per_img=100))

        /data/ephemeral/home/Sojeong/level2-objectdetection-cv-07/Backbone/Sojeong/1008_retinanet/mmdetection/configs/_base_/datasets/coco_detection.py
        # dataset settings
        dataset_type = 'CocoDataset'
        data_root = 'data/coco/'
        img_norm_cfg = dict(
            mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
        train_pipeline = [
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),
        ]
        test_pipeline = [
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(type='Normalize', **img_norm_cfg),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img']),
                ])
        ]
        data = dict(
            samples_per_gpu=2,
            workers_per_gpu=2,
            train=dict(
                type=dataset_type,
                ann_file=data_root + 'annotations/instances_train2017.json',
                img_prefix=data_root + 'train2017/',
                pipeline=train_pipeline),
            val=dict(
                type=dataset_type,
                ann_file=data_root + 'annotations/instances_val2017.json',
                img_prefix=data_root + 'val2017/',
                pipeline=test_pipeline),
            test=dict(
                type=dataset_type,
                ann_file=data_root + 'annotations/instances_val2017.json',
                img_prefix=data_root + 'val2017/',
                pipeline=test_pipeline))
        evaluation = dict(interval=1, metric='bbox')

        /data/ephemeral/home/Sojeong/level2-objectdetection-cv-07/Backbone/Sojeong/1008_retinanet/mmdetection/configs/_base_/schedules/schedule_1x.py
        # optimizer
        optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)
        optimizer_config = dict(grad_clip=None)
        # learning policy
        lr_config = dict(
            policy='step',
            warmup='linear',
            warmup_iters=500,
            warmup_ratio=0.001,
            step=[8, 11])
        runner = dict(type='EpochBasedRunner', max_epochs=12)

        /data/ephemeral/home/Sojeong/level2-objectdetection-cv-07/Backbone/Sojeong/1008_retinanet/mmdetection/configs/_base_/default_runtime.py
        checkpoint_config = dict(interval=1)
        # yapf:disable
        log_config = dict(
            interval=50,
            hooks=[
                dict(type='TextLoggerHook'),
                # dict(type='TensorboardLoggerHook')
            ])
        # yapf:enable
        custom_hooks = [dict(type='NumClassCheckHook')]

        dist_params = dict(backend='nccl')
        log_level = 'INFO'
        load_from = None
        resume_from = None
        workflow = [('train', 1)]

        # disable opencv multithreading to avoid system being overloaded
        opencv_num_threads = 0
        # set multi-process start method as `fork` to speed up the training
        mp_start_method = 'fork'

        # Default setting for scaling LR automatically
        #   - `enable` means enable scaling LR automatically
        #       or not by default.
        #   - `base_batch_size` = (8 GPUs) x (2 samples per GPU).
        auto_scale_lr = dict(enable=False, base_batch_size=16)

        /data/ephemeral/home/Sojeong/level2-objectdetection-cv-07/Backbone/Sojeong/1008_retinanet/mmdetection/configs/retinanet/retinanet_r50_fpn_1x_coco.py
        _base_ = [
            '../_base_/models/retinanet_r50_fpn.py',
            '../_base_/datasets/coco_detection.py',
            '../_base_/schedules/schedule_1x.py', '../_base_/default_runtime.py'
        ]
        # optimizer
        optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
_wandb:
    value:
        cli_version: 0.18.3
        m: []
        python_version: 3.10.13
        t:
            "1":
                - 1
                - 5
                - 37
                - 38
                - 41
                - 53
                - 55
                - 80
            "2":
                - 1
                - 5
                - 37
                - 38
                - 41
                - 53
                - 55
                - 80
            "3":
                - 13
                - 16
                - 23
                - 55
            "4": 3.10.13
            "5": 0.18.3
            "8":
                - 5
            "12": 0.18.3
            "13": linux-x86_64
