{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from map_boxes import mean_average_precision_for_boxes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = 'valid'\n",
    "GT_JSON = f'../../../Other/Dongjin/1010_split/result/{select}_3_5.json'\n",
    "PRED_CSV = f'./result/deta-swin-large_3_img_size_720_{select}.csv'\n",
    "\n",
    "LABEL_NAME = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\",\n",
    "              \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "958it [00:00, 5201.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# load ground truth\n",
    "with open(GT_JSON, 'r') as outfile:\n",
    "    test_anno = (json.load(outfile))\n",
    "\n",
    "# load prediction\n",
    "pred_df = pd.read_csv(PRED_CSV)\n",
    "\n",
    "pred = []\n",
    "file_names = pred_df['image_id'].values.tolist()\n",
    "bboxes = pred_df['PredictionString'].values.tolist()\n",
    "\n",
    "for file_name, bbox in tqdm(zip(file_names, bboxes)):\n",
    "    boxes = np.array(str(bbox).strip().split(' '))\n",
    "\n",
    "    if len(boxes) % 6 == 0:\n",
    "        boxes = boxes.reshape(-1, 6)\n",
    "    elif isinstance(bbox, float):\n",
    "        print(f'{file_name} empty box')\n",
    "        continue\n",
    "    else:\n",
    "        raise Exception('error', 'invalid box type')\n",
    "    \n",
    "    for box in boxes:\n",
    "        pred.append([file_name, box[0], box[1], float(box[2]), float(box[4]), float(box[3]), float(box[5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "gt = []\n",
    "coco = COCO(GT_JSON)\n",
    "\n",
    "for image_id in coco.getImgIds():\n",
    "    image_info = coco.loadImgs(image_id)[0]\n",
    "    annotation_id = coco.getAnnIds(imgIds=image_info['id'])\n",
    "    annotation_info_list = coco.loadAnns(annotation_id)\n",
    "    file_name = image_info['file_name']\n",
    "\n",
    "    for annotation in annotation_info_list:\n",
    "        gt.append([file_name, annotation['category_id'],\n",
    "                float(annotation['bbox'][0]),\n",
    "                float(annotation['bbox'][0]) + float(annotation['bbox'][2]),\n",
    "                float(annotation['bbox'][1]),\n",
    "                float(annotation['bbox'][1]) + float(annotation['bbox'][3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in annotations: 958\n",
      "Number of files in predictions: 958\n",
      "Unique classes: 10\n",
      "Detections length: 958\n",
      "Annotations length: 958\n",
      "0                              | 0.423034 |     804\n",
      "1                              | 0.618705 |    1214\n",
      "2                              | 0.671341 |     180\n",
      "3                              | 0.648315 |     190\n",
      "4                              | 0.786109 |     229\n",
      "5                              | 0.583906 |     595\n",
      "6                              | 0.560847 |     328\n",
      "7                              | 0.765935 |     941\n",
      "8                              | 0.870503 |      51\n",
      "9                              | 0.744020 |      55\n",
      "mAP: 0.667272\n",
      "0.6672715213606737\n"
     ]
    }
   ],
   "source": [
    "mean_ap, average_precisions = mean_average_precision_for_boxes(gt, pred, iou_threshold=0.5)\n",
    "print(mean_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou_calc(boxes1, boxes2):\n",
    "    \"\"\" \n",
    "    <https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py>\n",
    "    Return intersection-over-union (Jaccard index) of boxes.\n",
    "    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n",
    "    \"\"\"\n",
    "\n",
    "    def box_area(box):\n",
    "        return (box[2] - box[0]) * (box[3] - box[1])\n",
    "    \n",
    "    area1 = box_area(boxes1.T)\n",
    "    area2 = box_area(boxes2.T)\n",
    "\n",
    "    lt = np.maximum(boxes1[:, None, :2], boxes2[:, :2]) # left top?\n",
    "    rb = np.minimum(boxes1[:, None, 2:], boxes2[:, 2:]) # right bottom?\n",
    "\n",
    "    inter = np.prod(np.clip(rb - lt, a_min=0, a_max=None), 2)\n",
    "    return inter / (area1[:, None] + area2 - inter) # iou = inter / (area1 + area2 - inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
