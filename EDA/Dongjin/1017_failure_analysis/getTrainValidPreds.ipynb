{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection, Trainer\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "sys.path.append(\"../../../timm/Dongjin/1011_model_search\")\n",
    "import utils\n",
    "import dataset\n",
    "import train_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_path = '../../../timm/Dongjin/1011_model_search/result/jozhang97/deta-swin-large_3_img_size_720'\n",
    "checkpoint_dir = 'checkpoint-15704'\n",
    "device = 'cuda'\n",
    "\n",
    "checkpoint_path = os.path.join(model_path, checkpoint_dir)\n",
    "run_name = os.path.split(model_path)[-1]\n",
    "json_path = os.path.join(model_path, run_name + '.json')\n",
    "\n",
    "conf = utils.read_json(json_path)\n",
    "train_info_path = os.path.join(conf['coco_dir_path'], conf['train_info_name'])\n",
    "valid_info_path = os.path.join(conf['coco_dir_path'], conf['valid_info_name'])\n",
    "\n",
    "coco_train = COCO(train_info_path)\n",
    "coco_valid = COCO(valid_info_path)\n",
    "\n",
    "id2label = utils.get_id2label(conf['classes'])\n",
    "label2id = utils.get_label2id(id2label)\n",
    "\n",
    "train = dataset.COCO2dataset(conf['data_dir_path'], coco_train)\n",
    "valid = dataset.COCO2dataset(conf['data_dir_path'], coco_valid)\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint_path)\n",
    "model = AutoModelForObjectDetection.from_pretrained(checkpoint_path)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_eval(conf, model, image_processor, coco_data, data, result_path):\n",
    "    batch_size = 8\n",
    "\n",
    "    image_names = []\n",
    "    prediction_strings = []\n",
    "    batch_indices = get_batch_indices(batch_size, len(data))\n",
    "\n",
    "    for batch_index in tqdm(batch_indices):\n",
    "        batch = data[batch_index]\n",
    "        image_name, prediction_string = get_predictions(batch, coco_data, model, image_processor)\n",
    "        \n",
    "        image_names.extend(image_name)\n",
    "        prediction_strings.extend(prediction_string)\n",
    "\n",
    "    submission = pd.DataFrame()\n",
    "    submission['PredictionString'] = prediction_strings\n",
    "    submission['image_id'] = image_names\n",
    "    submission.to_csv(result_path, index=None)\n",
    "\n",
    "\n",
    "def get_batch_indices(batch_size, n):\n",
    "    i = 0\n",
    "    batch_index = []\n",
    "    batch_indices = []\n",
    "\n",
    "    while True:\n",
    "        if (i == n): \n",
    "            batch_indices.append(batch_index)\n",
    "            break\n",
    "\n",
    "        batch_index.append(i)\n",
    "\n",
    "        if (len(batch_index) % batch_size == 0):\n",
    "            batch_indices.append(batch_index)\n",
    "            batch_index = []\n",
    "            \n",
    "        i += 1  \n",
    "\n",
    "    return batch_indices\n",
    "        \n",
    "\n",
    "def get_predictions(batch, coco_data, model, image_processor):\n",
    "    threshold = 0.05\n",
    "    device = \"cuda\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        images = batch['image']\n",
    "        image_ids = batch['image_id']\n",
    "        image_infos = coco_data.loadImgs(image_ids)\n",
    "\n",
    "        inputs = image_processor(images=images, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs.to(device))\n",
    "        target_sizes = [image.size for image in images]\n",
    "        results = image_processor.post_process_object_detection(outputs, threshold=threshold, target_sizes=target_sizes)\n",
    "        \n",
    "        image_names = [image_info['file_name'] for image_info in image_infos]\n",
    "        prediction_strings = []\n",
    "\n",
    "        for result in results:\n",
    "            _, indices = torch.sort(result['scores'], descending=True)\n",
    "            result[\"scores\"] = result[\"scores\"][indices].detach().cpu().numpy() \n",
    "            result[\"labels\"] = result[\"labels\"][indices].detach().cpu().numpy() \n",
    "            result[\"boxes\"] = result[\"boxes\"][indices].detach().cpu().numpy() \n",
    "\n",
    "            prediction_string = ''\n",
    "\n",
    "            for box, score, label in zip(result[\"boxes\"], result[\"scores\"], result[\"labels\"]):\n",
    "                prediction_string += str(label) + ' ' + str(score) + ' ' + str(box[0]) + ' ' + str(\n",
    "                        box[1]) + ' ' + str(box[2]) + ' ' + str(box[3]) + ' '\n",
    "\n",
    "            prediction_strings.append(prediction_string)\n",
    "        \n",
    "        return image_names, prediction_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_eval(conf, model, image_processor, coco_valid, valid, run_name + '_valid.csv')\n",
    "test_eval(conf, model, image_processor, coco_train, train, run_name + '_train.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
