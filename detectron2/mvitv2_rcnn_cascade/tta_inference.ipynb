{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 기존 데이터셋 삭제\n",
    "dataset_name = 'coco_trash_final'\n",
    "if dataset_name in DatasetCatalog:\n",
    "    DatasetCatalog.remove(dataset_name)\n",
    "if dataset_name in MetadataCatalog:\n",
    "    MetadataCatalog.remove(dataset_name)\n",
    "\n",
    "# Register Dataset\n",
    "try:\n",
    "    register_coco_instances('coco_trash_final', {}, '/data/ephemeral/home/data/dataset/test.json', '/data/ephemeral/home/data/dataset/')\n",
    "except AssertionError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import (\n",
    "    AMPTrainer,\n",
    "    SimpleTrainer,\n",
    "    default_argument_parser,\n",
    "    default_setup,\n",
    "    default_writers,\n",
    "    hooks,\n",
    "    launch,\n",
    ")\n",
    "from detectron2.modeling import GeneralizedRCNNWithTTA, GeneralizedRCNN\n",
    "import logging\n",
    "from detectron2.engine.defaults import create_ddp_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.evaluation import inference_on_dataset, print_csv_format\n",
    "from detectron2.config import LazyConfig, instantiate\n",
    "from omegaconf import OmegaConf\n",
    "from detectron2.config import get_cfg\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# 설정 파일 로드 (LazyConfig)\n",
    "cfg = LazyConfig.load('/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/vitdet_rcnn_cascade/output/config.yaml')\n",
    "cfg.dataloader.test.dataset.names = 'coco_trash_final'\n",
    "\n",
    "model = instantiate(cfg.model)\n",
    "model.to(cfg.train.device)\n",
    "\n",
    "# tta_cfg를 CfgNode로 생성\n",
    "tta_cfg = cfg.clone()\n",
    "tta_cfg.TEST.AUG.ENABLED = True\n",
    "tta_cfg.TEST.AUG.MIN_SIZES = (400, 500, 600, 700, 800)\n",
    "tta_cfg.TEST.AUG.MAX_SIZE = 1333\n",
    "tta_cfg.TEST.AUG.FLIP = True\n",
    "tta_cfg.MODEL.KEYPOINT_ON = False\n",
    "tta_cfg.MODEL.LOAD_PROPOSALS = False\n",
    "tta_cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10  # 클래스 수에 맞게 조정\n",
    "tta_cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5\n",
    "tta_cfg.TEST.DETECTIONS_PER_IMAGE = 100\n",
    "\n",
    "# 기존 cfg에서 필요한 설정을 복사\n",
    "tta_cfg.MODEL.WEIGHTS = cfg.MODEL.WEIGHTS\n",
    "tta_cfg.MODEL.DEVICE = cfg.MODEL.DEVICE\n",
    "\n",
    "model = GeneralizedRCNNWithTTA(cfg, model)\n",
    "\n",
    "model = create_ddp_model(model)\n",
    "# 모델 가중치 로드\n",
    "DetectionCheckpointer(model).load('/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/vitdet_rcnn_cascade/output/model_0049999.pth')\n",
    "\n",
    "# 테스트 데이터셋 로드\n",
    "test_loader = instantiate(cfg.dataloader.test)\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "# 예측 수행\n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "\n",
    "for data in tqdm(test_loader):\n",
    "    \n",
    "    prediction_string = ''\n",
    "    input=data[0]\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data)[0]['instances']  # model에 올바른 형식으로 전달\n",
    "    \n",
    "    # 예측 결과 처리\n",
    "    targets = outputs.pred_classes.cpu().tolist()\n",
    "    boxes = [i.cpu().detach().numpy() for i in outputs.pred_boxes]\n",
    "    scores = outputs.scores.cpu().tolist()\n",
    "    \n",
    "    for target, box, score in zip(targets, boxes, scores):\n",
    "        prediction_string += (str(target) + ' ' + str(score) + ' ' + str(box[0]) + ' ' \n",
    "        + str(box[1]) + ' ' + str(box[2]) + ' ' + str(box[3]) + ' ')\n",
    "    \n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(input['file_name'].replace('/data/ephemeral/home/data/dataset/', ''))\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv(os.path.join(cfg.train.output_dir, 'submission_det4.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
