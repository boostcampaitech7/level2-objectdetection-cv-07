{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 모듈 import\n",
    "\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.utils import get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "# config file 들고오기\n",
    "cfg = Config.fromfile('/data/ephemeral/home/Jihwan/level2-objectdetection-cv-07/mmdetection/configs/detr/detr_r50_8x2_150e_coco.py')\n",
    "\n",
    "root='/data/ephemeral/home/dataset/'\n",
    "\n",
    "# dataset config 수정\n",
    "cfg.data.train.classes = classes\n",
    "cfg.data.train.img_prefix = root\n",
    "cfg.data.train.ann_file = root + 'train.json' # train json 정보\n",
    "#cfg.data.train.pipeline[2]['img_scale'] = (512,512) # Resize\n",
    "\n",
    "cfg.data.test.classes = classes\n",
    "cfg.data.test.img_prefix = root\n",
    "cfg.data.test.ann_file = root + 'test.json' # test json 정보\n",
    "#cfg.data.test.pipeline[1]['img_scale'] = (512,512) # Resize\n",
    "\n",
    "cfg.data.samples_per_gpu = 4\n",
    "\n",
    "cfg.seed = 2022\n",
    "cfg.gpu_ids = [0]\n",
    "cfg.work_dir = './work_dirs/detr_r50'\n",
    "\n",
    "cfg.model.bbox_head.num_classes = 10\n",
    "\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
    "cfg.checkpoint_config = dict(max_keep_ckpts=3, interval=1)\n",
    "cfg.device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# build_dataset\n",
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "CocoDataset Train dataset with number of images 4883, and instance counts: \n",
       "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
       "| category          | count | category      | count | category        | count | category    | count | category     | count |\n",
       "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
       "| 0 [General trash] | 3965  | 1 [Paper]     | 6352  | 2 [Paper pack]  | 897   | 3 [Metal]   | 936   | 4 [Glass]    | 982   |\n",
       "| 5 [Plastic]       | 2943  | 6 [Styrofoam] | 1263  | 7 [Plastic bag] | 5178  | 8 [Battery] | 159   | 9 [Clothing] | 468   |\n",
       "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset 확인\n",
    "datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-12 01:40:34,198 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
      "2024-10-12 01:40:34,199 - mmcv - INFO - load model from: torchvision://resnet50\n",
      "2024-10-12 01:40:34,200 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /data/ephemeral/home/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca587b95be554ac3adc4aeea462ab4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-12 01:40:40,157 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2024-10-12 01:40:40,279 - mmcv - INFO - \n",
      "backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,280 - mmcv - INFO - \n",
      "backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,280 - mmcv - INFO - \n",
      "backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,281 - mmcv - INFO - \n",
      "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,282 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,282 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,283 - mmcv - INFO - \n",
      "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,283 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,284 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,284 - mmcv - INFO - \n",
      "backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,285 - mmcv - INFO - \n",
      "backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,285 - mmcv - INFO - \n",
      "backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,286 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,287 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,287 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,288 - mmcv - INFO - \n",
      "backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,288 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,289 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,289 - mmcv - INFO - \n",
      "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,290 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,290 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,291 - mmcv - INFO - \n",
      "backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,292 - mmcv - INFO - \n",
      "backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,292 - mmcv - INFO - \n",
      "backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,293 - mmcv - INFO - \n",
      "backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,293 - mmcv - INFO - \n",
      "backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,294 - mmcv - INFO - \n",
      "backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,294 - mmcv - INFO - \n",
      "backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,295 - mmcv - INFO - \n",
      "backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,295 - mmcv - INFO - \n",
      "backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,296 - mmcv - INFO - \n",
      "backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,297 - mmcv - INFO - \n",
      "backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,297 - mmcv - INFO - \n",
      "backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,298 - mmcv - INFO - \n",
      "backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,298 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,299 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,299 - mmcv - INFO - \n",
      "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,299 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,300 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,300 - mmcv - INFO - \n",
      "backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,301 - mmcv - INFO - \n",
      "backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,303 - mmcv - INFO - \n",
      "backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,303 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,304 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,304 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,305 - mmcv - INFO - \n",
      "backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,305 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,305 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,306 - mmcv - INFO - \n",
      "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,306 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,307 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,307 - mmcv - INFO - \n",
      "backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,308 - mmcv - INFO - \n",
      "backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,308 - mmcv - INFO - \n",
      "backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,309 - mmcv - INFO - \n",
      "backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,309 - mmcv - INFO - \n",
      "backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,310 - mmcv - INFO - \n",
      "backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,310 - mmcv - INFO - \n",
      "backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,311 - mmcv - INFO - \n",
      "backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,315 - mmcv - INFO - \n",
      "backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,315 - mmcv - INFO - \n",
      "backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,316 - mmcv - INFO - \n",
      "backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,316 - mmcv - INFO - \n",
      "backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,317 - mmcv - INFO - \n",
      "backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,317 - mmcv - INFO - \n",
      "backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,318 - mmcv - INFO - \n",
      "backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,318 - mmcv - INFO - \n",
      "backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,318 - mmcv - INFO - \n",
      "backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,319 - mmcv - INFO - \n",
      "backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,319 - mmcv - INFO - \n",
      "backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,320 - mmcv - INFO - \n",
      "backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,320 - mmcv - INFO - \n",
      "backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,321 - mmcv - INFO - \n",
      "backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,321 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,322 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,322 - mmcv - INFO - \n",
      "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,322 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,323 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,323 - mmcv - INFO - \n",
      "backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,324 - mmcv - INFO - \n",
      "backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,324 - mmcv - INFO - \n",
      "backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,325 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,325 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,326 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,329 - mmcv - INFO - \n",
      "backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,329 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,330 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,330 - mmcv - INFO - \n",
      "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,331 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,331 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,332 - mmcv - INFO - \n",
      "backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,332 - mmcv - INFO - \n",
      "backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,333 - mmcv - INFO - \n",
      "backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,333 - mmcv - INFO - \n",
      "backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,335 - mmcv - INFO - \n",
      "backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,335 - mmcv - INFO - \n",
      "backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,336 - mmcv - INFO - \n",
      "backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,336 - mmcv - INFO - \n",
      "backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,337 - mmcv - INFO - \n",
      "backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,337 - mmcv - INFO - \n",
      "backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,337 - mmcv - INFO - \n",
      "backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,338 - mmcv - INFO - \n",
      "backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,338 - mmcv - INFO - \n",
      "backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,339 - mmcv - INFO - \n",
      "backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,339 - mmcv - INFO - \n",
      "backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,340 - mmcv - INFO - \n",
      "backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,340 - mmcv - INFO - \n",
      "backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,341 - mmcv - INFO - \n",
      "backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,341 - mmcv - INFO - \n",
      "backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,342 - mmcv - INFO - \n",
      "backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,342 - mmcv - INFO - \n",
      "backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,343 - mmcv - INFO - \n",
      "backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,343 - mmcv - INFO - \n",
      "backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,344 - mmcv - INFO - \n",
      "backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,344 - mmcv - INFO - \n",
      "backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,345 - mmcv - INFO - \n",
      "backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,345 - mmcv - INFO - \n",
      "backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,346 - mmcv - INFO - \n",
      "backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,346 - mmcv - INFO - \n",
      "backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,346 - mmcv - INFO - \n",
      "backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,347 - mmcv - INFO - \n",
      "backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,347 - mmcv - INFO - \n",
      "backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,348 - mmcv - INFO - \n",
      "backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,348 - mmcv - INFO - \n",
      "backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,349 - mmcv - INFO - \n",
      "backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,349 - mmcv - INFO - \n",
      "backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,349 - mmcv - INFO - \n",
      "backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,350 - mmcv - INFO - \n",
      "backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,350 - mmcv - INFO - \n",
      "backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,351 - mmcv - INFO - \n",
      "backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,351 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,352 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,352 - mmcv - INFO - \n",
      "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,352 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,353 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,353 - mmcv - INFO - \n",
      "backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,354 - mmcv - INFO - \n",
      "backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,354 - mmcv - INFO - \n",
      "backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,355 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,355 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,356 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,356 - mmcv - INFO - \n",
      "backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,356 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,357 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,357 - mmcv - INFO - \n",
      "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,358 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,358 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,359 - mmcv - INFO - \n",
      "backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,359 - mmcv - INFO - \n",
      "backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,360 - mmcv - INFO - \n",
      "backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,360 - mmcv - INFO - \n",
      "backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,361 - mmcv - INFO - \n",
      "backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,361 - mmcv - INFO - \n",
      "backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,361 - mmcv - INFO - \n",
      "backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,362 - mmcv - INFO - \n",
      "backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,362 - mmcv - INFO - \n",
      "backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,363 - mmcv - INFO - \n",
      "backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,363 - mmcv - INFO - \n",
      "backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,364 - mmcv - INFO - \n",
      "backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-10-12 01:40:40,364 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,365 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,368 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,368 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,369 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,369 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,370 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,370 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,371 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,371 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,372 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,372 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,373 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,373 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,373 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,374 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,374 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,376 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,377 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,377 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,378 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,378 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,379 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,379 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,379 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,380 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,380 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,381 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,381 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,382 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,382 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,383 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,383 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,384 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,384 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,385 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,385 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,388 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,389 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,389 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,389 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,390 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,390 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,391 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,391 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,392 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,393 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,393 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,393 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,394 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,394 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,395 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,395 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,397 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,398 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,400 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,401 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,401 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,402 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,403 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,404 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,406 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,407 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,408 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,409 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,409 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,410 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,410 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,411 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,411 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,412 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,412 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,413 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,413 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,414 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,414 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,414 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,415 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.1.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,416 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,416 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.1.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,417 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,417 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,418 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,418 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,418 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,419 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,420 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,420 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,421 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,421 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,422 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,422 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,423 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,423 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,424 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,424 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.1.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,425 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,425 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.1.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,426 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,426 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,427 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,427 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,427 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,428 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,429 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,429 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,430 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,430 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,430 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,431 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,431 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,432 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,432 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,433 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.1.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,433 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,434 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.1.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,434 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,435 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,435 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,436 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,436 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,437 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,437 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,438 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,438 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,439 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,439 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,440 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,440 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,441 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,441 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,442 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.1.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,442 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,443 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.1.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,443 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,443 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,444 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,444 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,445 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,445 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,446 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,446 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,447 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,447 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,447 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,448 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,449 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,449 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,449 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,450 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.1.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,451 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,451 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.1.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,452 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,452 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,452 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,453 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,454 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,454 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,454 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,455 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,455 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,456 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,456 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,457 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,457 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,458 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,458 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,458 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.1.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,459 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,459 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.1.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,460 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,460 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,461 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,461 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2024-10-12 01:40:40,462 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,462 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,462 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,463 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,463 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,464 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,465 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.post_norm.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,465 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.post_norm.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,466 - mmcv - INFO - \n",
      "bbox_head.input_proj.weight - torch.Size([256, 2048, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,467 - mmcv - INFO - \n",
      "bbox_head.input_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,467 - mmcv - INFO - \n",
      "bbox_head.fc_cls.weight - torch.Size([11, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,468 - mmcv - INFO - \n",
      "bbox_head.fc_cls.bias - torch.Size([11]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,468 - mmcv - INFO - \n",
      "bbox_head.reg_ffn.layers.0.0.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,469 - mmcv - INFO - \n",
      "bbox_head.reg_ffn.layers.0.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,469 - mmcv - INFO - \n",
      "bbox_head.reg_ffn.layers.1.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,470 - mmcv - INFO - \n",
      "bbox_head.reg_ffn.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,470 - mmcv - INFO - \n",
      "bbox_head.fc_reg.weight - torch.Size([4, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,471 - mmcv - INFO - \n",
      "bbox_head.fc_reg.bias - torch.Size([4]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2024-10-12 01:40:40,471 - mmcv - INFO - \n",
      "bbox_head.query_embedding.weight - torch.Size([100, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# 모델 build 및 pretrained network 불러오기\n",
    "model = build_detector(cfg.model)\n",
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-12 01:40:44,377 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2024-10-12 01:40:44,413 - mmdet - INFO - Start running, host: root@instance-12171, work_dir: /data/ephemeral/home/Jihwan/level2-objectdetection-cv-07/mmdetection/work_dirs/detr_r50\n",
      "2024-10-12 01:40:44,413 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2024-10-12 01:40:44,414 - mmdet - INFO - workflow: [('train', 1)], max: 150 epochs\n",
      "2024-10-12 01:40:44,415 - mmdet - INFO - Checkpoints will be saved to /data/ephemeral/home/Jihwan/level2-objectdetection-cv-07/mmdetection/work_dirs/detr_r50 by HardDiskBackend.\n",
      "/data/ephemeral/home/Jihwan/level2-objectdetection-cv-07/mmdetection/mmdet/models/utils/positional_encoding.py:81: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature**(2 * (dim_t // 2) / self.num_feats)\n",
      "/data/ephemeral/home/Jihwan/level2-objectdetection-cv-07/mmdetection/mmdet/models/losses/cross_entropy_loss.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  class_weight = cls_score.new_tensor(\n",
      "2024-10-12 01:41:02,213 - mmdet - INFO - Epoch [1][50/1221]\tlr: 1.000e-04, eta: 18:05:55, time: 0.356, data_time: 0.053, memory: 6161, loss_cls: 1.2192, loss_bbox: 3.3689, loss_iou: 1.9696, d0.loss_cls: 1.2155, d0.loss_bbox: 3.3418, d0.loss_iou: 1.9640, d1.loss_cls: 1.1987, d1.loss_bbox: 3.3637, d1.loss_iou: 1.9698, d2.loss_cls: 1.2121, d2.loss_bbox: 3.3755, d2.loss_iou: 1.9640, d3.loss_cls: 1.2145, d3.loss_bbox: 3.3716, d3.loss_iou: 1.9627, d4.loss_cls: 1.2175, d4.loss_bbox: 3.3540, d4.loss_iou: 1.9922, loss: 39.2754, grad_norm: 114.2827\n",
      "2024-10-12 01:41:15,727 - mmdet - INFO - Epoch [1][100/1221]\tlr: 1.000e-04, eta: 15:55:05, time: 0.270, data_time: 0.008, memory: 6161, loss_cls: 1.1739, loss_bbox: 2.9509, loss_iou: 1.9714, d0.loss_cls: 1.1655, d0.loss_bbox: 2.8858, d0.loss_iou: 1.9508, d1.loss_cls: 1.1641, d1.loss_bbox: 2.9480, d1.loss_iou: 1.9870, d2.loss_cls: 1.1677, d2.loss_bbox: 2.9800, d2.loss_iou: 1.9829, d3.loss_cls: 1.1577, d3.loss_bbox: 2.9283, d3.loss_iou: 1.9391, d4.loss_cls: 1.1613, d4.loss_bbox: 2.9332, d4.loss_iou: 1.9735, loss: 36.4212, grad_norm: 112.4841\n",
      "2024-10-12 01:41:29,539 - mmdet - INFO - Epoch [1][150/1221]\tlr: 1.000e-04, eta: 15:17:22, time: 0.276, data_time: 0.008, memory: 6161, loss_cls: 1.2288, loss_bbox: 2.6622, loss_iou: 2.0210, d0.loss_cls: 1.2155, d0.loss_bbox: 2.4283, d0.loss_iou: 1.8887, d1.loss_cls: 1.2146, d1.loss_bbox: 2.5489, d1.loss_iou: 1.9851, d2.loss_cls: 1.2237, d2.loss_bbox: 2.6703, d2.loss_iou: 2.0443, d3.loss_cls: 1.2299, d3.loss_bbox: 2.5583, d3.loss_iou: 1.9568, d4.loss_cls: 1.2290, d4.loss_bbox: 2.5300, d4.loss_iou: 1.9680, loss: 34.6035, grad_norm: 161.9764\n",
      "2024-10-12 01:41:43,421 - mmdet - INFO - Epoch [1][200/1221]\tlr: 1.000e-04, eta: 14:59:28, time: 0.278, data_time: 0.008, memory: 6223, loss_cls: 1.2247, loss_bbox: 2.2622, loss_iou: 1.7245, d0.loss_cls: 1.2244, d0.loss_bbox: 2.0482, d0.loss_iou: 1.6708, d1.loss_cls: 1.2323, d1.loss_bbox: 2.0620, d1.loss_iou: 1.6501, d2.loss_cls: 1.2243, d2.loss_bbox: 2.2221, d2.loss_iou: 1.7263, d3.loss_cls: 1.2276, d3.loss_bbox: 2.2234, d3.loss_iou: 1.7349, d4.loss_cls: 1.2120, d4.loss_bbox: 2.1789, d4.loss_iou: 1.7338, loss: 30.5825, grad_norm: 289.9958\n",
      "2024-10-12 01:41:57,304 - mmdet - INFO - Epoch [1][250/1221]\tlr: 1.000e-04, eta: 14:48:40, time: 0.278, data_time: 0.009, memory: 6223, loss_cls: 1.1819, loss_bbox: 1.6391, loss_iou: 1.5210, d0.loss_cls: 1.1728, d0.loss_bbox: 1.6616, d0.loss_iou: 1.5307, d1.loss_cls: 1.1849, d1.loss_bbox: 1.6334, d1.loss_iou: 1.5414, d2.loss_cls: 1.1791, d2.loss_bbox: 1.6414, d2.loss_iou: 1.5524, d3.loss_cls: 1.1977, d3.loss_bbox: 1.6292, d3.loss_iou: 1.5302, d4.loss_cls: 1.1899, d4.loss_bbox: 1.6513, d4.loss_iou: 1.5540, loss: 26.1920, grad_norm: 416.2601\n",
      "2024-10-12 01:42:11,184 - mmdet - INFO - Epoch [1][300/1221]\tlr: 1.000e-04, eta: 14:41:20, time: 0.278, data_time: 0.009, memory: 6223, loss_cls: 1.1842, loss_bbox: 1.6811, loss_iou: 1.5004, d0.loss_cls: 1.1782, d0.loss_bbox: 1.6573, d0.loss_iou: 1.5130, d1.loss_cls: 1.1971, d1.loss_bbox: 1.6729, d1.loss_iou: 1.4952, d2.loss_cls: 1.1951, d2.loss_bbox: 1.6628, d2.loss_iou: 1.5013, d3.loss_cls: 1.1955, d3.loss_bbox: 1.6959, d3.loss_iou: 1.5241, d4.loss_cls: 1.1935, d4.loss_bbox: 1.6869, d4.loss_iou: 1.5251, loss: 26.2594, grad_norm: 409.8191\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "train_detector(model, datasets[0], cfg, distributed=False, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
