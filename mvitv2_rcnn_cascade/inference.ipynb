{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d28a840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9614999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89687c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터셋 삭제\n",
    "dataset_name = 'coco_trash_final'\n",
    "if dataset_name in DatasetCatalog:\n",
    "    DatasetCatalog.remove(dataset_name)\n",
    "if dataset_name in MetadataCatalog:\n",
    "    MetadataCatalog.remove(dataset_name)\n",
    "\n",
    "# Register Dataset\n",
    "try:\n",
    "    register_coco_instances('coco_trash_final', {}, '/data/ephemeral/home/data/dataset/test.json', '/data/ephemeral/home/data/dataset/')\n",
    "except AssertionError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f0617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:47:09 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/vitdet_rcnn_cascade/output/model_0049999.pth ...\n",
      "\u001b[32m[10/21 12:47:10 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from /data/ephemeral/home/data/dataset/test.json\n",
      "\u001b[32m[10/21 12:47:10 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 0            |    Paper    | 0            | Paper pack | 0            |\n",
      "|     Metal     | 0            |    Glass    | 0            |  Plastic   | 0            |\n",
      "|   Styrofoam   | 0            | Plastic bag | 0            |  Battery   | 0            |\n",
      "|   Clothing    | 0            |             |              |            |              |\n",
      "|     total     | 0            |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/21 12:47:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=1024)]\n",
      "\u001b[32m[10/21 12:47:10 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/21 12:47:10 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:47:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.61 MiB\n",
      "\u001b[32m[10/21 12:47:10 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[10/21 12:47:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0013 s/iter. Inference: 0.2483 s/iter. Eval: 0.0002 s/iter. Total: 0.2498 s/iter. ETA=0:20:14\n",
      "\u001b[32m[10/21 12:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 32/4871. Dataloading: 0.0015 s/iter. Inference: 0.2473 s/iter. Eval: 0.0002 s/iter. Total: 0.2491 s/iter. ETA=0:20:05\n",
      "\u001b[32m[10/21 12:47:25 d2.evaluation.evaluator]: \u001b[0mInference done 52/4871. Dataloading: 0.0016 s/iter. Inference: 0.2476 s/iter. Eval: 0.0002 s/iter. Total: 0.2495 s/iter. ETA=0:20:02\n",
      "\u001b[32m[10/21 12:47:31 d2.evaluation.evaluator]: \u001b[0mInference done 73/4871. Dataloading: 0.0016 s/iter. Inference: 0.2477 s/iter. Eval: 0.0002 s/iter. Total: 0.2496 s/iter. ETA=0:19:57\n",
      "\u001b[32m[10/21 12:47:36 d2.evaluation.evaluator]: \u001b[0mInference done 94/4871. Dataloading: 0.0016 s/iter. Inference: 0.2474 s/iter. Eval: 0.0002 s/iter. Total: 0.2493 s/iter. ETA=0:19:50\n",
      "\u001b[32m[10/21 12:47:41 d2.evaluation.evaluator]: \u001b[0mInference done 114/4871. Dataloading: 0.0016 s/iter. Inference: 0.2475 s/iter. Eval: 0.0002 s/iter. Total: 0.2495 s/iter. ETA=0:19:46\n",
      "\u001b[32m[10/21 12:47:46 d2.evaluation.evaluator]: \u001b[0mInference done 134/4871. Dataloading: 0.0016 s/iter. Inference: 0.2476 s/iter. Eval: 0.0002 s/iter. Total: 0.2496 s/iter. ETA=0:19:42\n",
      "\u001b[32m[10/21 12:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 155/4871. Dataloading: 0.0016 s/iter. Inference: 0.2477 s/iter. Eval: 0.0002 s/iter. Total: 0.2496 s/iter. ETA=0:19:37\n",
      "\u001b[32m[10/21 12:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 175/4871. Dataloading: 0.0017 s/iter. Inference: 0.2477 s/iter. Eval: 0.0002 s/iter. Total: 0.2498 s/iter. ETA=0:19:32\n",
      "\u001b[32m[10/21 12:48:01 d2.evaluation.evaluator]: \u001b[0mInference done 195/4871. Dataloading: 0.0017 s/iter. Inference: 0.2478 s/iter. Eval: 0.0002 s/iter. Total: 0.2498 s/iter. ETA=0:19:28\n",
      "\u001b[32m[10/21 12:48:06 d2.evaluation.evaluator]: \u001b[0mInference done 215/4871. Dataloading: 0.0017 s/iter. Inference: 0.2478 s/iter. Eval: 0.0002 s/iter. Total: 0.2499 s/iter. ETA=0:19:23\n",
      "\u001b[32m[10/21 12:48:11 d2.evaluation.evaluator]: \u001b[0mInference done 235/4871. Dataloading: 0.0017 s/iter. Inference: 0.2479 s/iter. Eval: 0.0002 s/iter. Total: 0.2499 s/iter. ETA=0:19:18\n",
      "\u001b[32m[10/21 12:48:16 d2.evaluation.evaluator]: \u001b[0mInference done 255/4871. Dataloading: 0.0017 s/iter. Inference: 0.2480 s/iter. Eval: 0.0002 s/iter. Total: 0.2500 s/iter. ETA=0:19:14\n",
      "\u001b[32m[10/21 12:48:21 d2.evaluation.evaluator]: \u001b[0mInference done 275/4871. Dataloading: 0.0018 s/iter. Inference: 0.2480 s/iter. Eval: 0.0002 s/iter. Total: 0.2501 s/iter. ETA=0:19:09\n",
      "\u001b[32m[10/21 12:48:26 d2.evaluation.evaluator]: \u001b[0mInference done 295/4871. Dataloading: 0.0018 s/iter. Inference: 0.2480 s/iter. Eval: 0.0002 s/iter. Total: 0.2501 s/iter. ETA=0:19:04\n",
      "\u001b[32m[10/21 12:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 315/4871. Dataloading: 0.0018 s/iter. Inference: 0.2480 s/iter. Eval: 0.0002 s/iter. Total: 0.2501 s/iter. ETA=0:18:59\n",
      "\u001b[32m[10/21 12:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 335/4871. Dataloading: 0.0018 s/iter. Inference: 0.2480 s/iter. Eval: 0.0002 s/iter. Total: 0.2502 s/iter. ETA=0:18:54\n",
      "\u001b[32m[10/21 12:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 355/4871. Dataloading: 0.0018 s/iter. Inference: 0.2481 s/iter. Eval: 0.0002 s/iter. Total: 0.2502 s/iter. ETA=0:18:49\n",
      "\u001b[32m[10/21 12:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 375/4871. Dataloading: 0.0018 s/iter. Inference: 0.2481 s/iter. Eval: 0.0002 s/iter. Total: 0.2503 s/iter. ETA=0:18:45\n",
      "\u001b[32m[10/21 12:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 395/4871. Dataloading: 0.0018 s/iter. Inference: 0.2483 s/iter. Eval: 0.0002 s/iter. Total: 0.2504 s/iter. ETA=0:18:40\n",
      "\u001b[32m[10/21 12:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 415/4871. Dataloading: 0.0018 s/iter. Inference: 0.2483 s/iter. Eval: 0.0002 s/iter. Total: 0.2504 s/iter. ETA=0:18:35\n",
      "\u001b[32m[10/21 12:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 435/4871. Dataloading: 0.0018 s/iter. Inference: 0.2484 s/iter. Eval: 0.0002 s/iter. Total: 0.2505 s/iter. ETA=0:18:31\n",
      "\u001b[32m[10/21 12:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 455/4871. Dataloading: 0.0018 s/iter. Inference: 0.2484 s/iter. Eval: 0.0002 s/iter. Total: 0.2505 s/iter. ETA=0:18:26\n",
      "\u001b[32m[10/21 12:49:11 d2.evaluation.evaluator]: \u001b[0mInference done 475/4871. Dataloading: 0.0018 s/iter. Inference: 0.2484 s/iter. Eval: 0.0002 s/iter. Total: 0.2506 s/iter. ETA=0:18:21\n",
      "\u001b[32m[10/21 12:49:16 d2.evaluation.evaluator]: \u001b[0mInference done 495/4871. Dataloading: 0.0018 s/iter. Inference: 0.2484 s/iter. Eval: 0.0002 s/iter. Total: 0.2506 s/iter. ETA=0:18:16\n",
      "\u001b[32m[10/21 12:49:21 d2.evaluation.evaluator]: \u001b[0mInference done 515/4871. Dataloading: 0.0018 s/iter. Inference: 0.2485 s/iter. Eval: 0.0002 s/iter. Total: 0.2506 s/iter. ETA=0:18:11\n",
      "\u001b[32m[10/21 12:49:26 d2.evaluation.evaluator]: \u001b[0mInference done 535/4871. Dataloading: 0.0018 s/iter. Inference: 0.2485 s/iter. Eval: 0.0002 s/iter. Total: 0.2506 s/iter. ETA=0:18:06\n",
      "\u001b[32m[10/21 12:49:31 d2.evaluation.evaluator]: \u001b[0mInference done 555/4871. Dataloading: 0.0018 s/iter. Inference: 0.2485 s/iter. Eval: 0.0002 s/iter. Total: 0.2507 s/iter. ETA=0:18:01\n",
      "\u001b[32m[10/21 12:49:37 d2.evaluation.evaluator]: \u001b[0mInference done 576/4871. Dataloading: 0.0018 s/iter. Inference: 0.2485 s/iter. Eval: 0.0002 s/iter. Total: 0.2506 s/iter. ETA=0:17:56\n",
      "\u001b[32m[10/21 12:49:42 d2.evaluation.evaluator]: \u001b[0mInference done 596/4871. Dataloading: 0.0018 s/iter. Inference: 0.2485 s/iter. Eval: 0.0002 s/iter. Total: 0.2507 s/iter. ETA=0:17:51\n",
      "\u001b[32m[10/21 12:49:47 d2.evaluation.evaluator]: \u001b[0mInference done 616/4871. Dataloading: 0.0018 s/iter. Inference: 0.2485 s/iter. Eval: 0.0002 s/iter. Total: 0.2507 s/iter. ETA=0:17:46\n",
      "\u001b[32m[10/21 12:49:52 d2.evaluation.evaluator]: \u001b[0mInference done 636/4871. Dataloading: 0.0018 s/iter. Inference: 0.2485 s/iter. Eval: 0.0002 s/iter. Total: 0.2507 s/iter. ETA=0:17:41\n",
      "\u001b[32m[10/21 12:49:57 d2.evaluation.evaluator]: \u001b[0mInference done 656/4871. Dataloading: 0.0018 s/iter. Inference: 0.2485 s/iter. Eval: 0.0002 s/iter. Total: 0.2507 s/iter. ETA=0:17:36\n",
      "\u001b[32m[10/21 12:50:02 d2.evaluation.evaluator]: \u001b[0mInference done 676/4871. Dataloading: 0.0018 s/iter. Inference: 0.2486 s/iter. Eval: 0.0002 s/iter. Total: 0.2507 s/iter. ETA=0:17:31\n",
      "\u001b[32m[10/21 12:50:07 d2.evaluation.evaluator]: \u001b[0mInference done 696/4871. Dataloading: 0.0018 s/iter. Inference: 0.2486 s/iter. Eval: 0.0002 s/iter. Total: 0.2508 s/iter. ETA=0:17:26\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import (\n",
    "    AMPTrainer,\n",
    "    SimpleTrainer,\n",
    "    default_argument_parser,\n",
    "    default_setup,\n",
    "    default_writers,\n",
    "    hooks,\n",
    "    launch,\n",
    ")\n",
    "import logging\n",
    "from detectron2.engine.defaults import create_ddp_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.evaluation import inference_on_dataset, print_csv_format\n",
    "from detectron2.config import LazyConfig, instantiate\n",
    "\n",
    "cfg=LazyConfig.load('/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/vitdet_rcnn_cascade/output/config.yaml')\n",
    "\n",
    "def do_test(cfg, model):\n",
    "    cfg.dataloader.test.dataset.names='coco_trash_final'\n",
    "    cfg.dataloader.evaluator.dataset_name='coco_trash_final'\n",
    "    if \"evaluator\" in cfg.dataloader:\n",
    "        ret = inference_on_dataset(\n",
    "            model,\n",
    "            instantiate(cfg.dataloader.test),\n",
    "            instantiate(cfg.dataloader.evaluator),\n",
    "        )\n",
    "        print_csv_format(ret)\n",
    "        return ret\n",
    "\n",
    "\n",
    "\n",
    "model = instantiate(cfg.model)\n",
    "model.to(cfg.train.device)\n",
    "model = create_ddp_model(model)\n",
    "DetectionCheckpointer(model).load('/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/vitdet_rcnn_cascade/output/model_0049999.pth')\n",
    "print(do_test(cfg, model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35f0552b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataloader': {'evaluator': {'_target_': 'detectron2.evaluation.COCOEvaluator', 'dataset_name': 'coco_trash_final'}, 'test': {'_target_': 'detectron2.data.build_detection_test_loader', 'dataset': {'_target_': 'detectron2.data.get_detection_dataset_dicts', 'filter_empty': False, 'names': 'coco_trash_test'}, 'mapper': {'_target_': 'detectron2.data.DatasetMapper', 'augmentations': [{'_target_': 'detectron2.data.transforms.ResizeShortestEdge', 'max_size': 1024, 'short_edge_length': 1024}], 'image_format': '${...train.mapper.image_format}', 'is_train': False}, 'num_workers': 4, 'dataset_names': 'coco_trash_final'}, 'train': {'_target_': 'detectron2.data.build_detection_train_loader', 'dataset': {'_target_': 'detectron2.data.get_detection_dataset_dicts', 'names': 'coco_trash_train'}, 'mapper': {'_target_': 'detectron2.data.DatasetMapper', 'augmentations': [{'_target_': 'detectron2.data.transforms.RandomFlip', 'horizontal': True}, {'_target_': 'detectron2.data.transforms.ResizeScale', 'max_scale': 2.0, 'min_scale': 0.1, 'target_height': 1024, 'target_width': 1024}, {'_target_': 'detectron2.data.transforms.FixedSizeCrop', 'crop_size': [1024, 1024], 'pad': False}], 'image_format': 'RGB', 'is_train': True, 'recompute_boxes': False, 'use_instance_mask': False}, 'num_workers': 4, 'total_batch_size': 2}}, 'lr_multiplier': {'_target_': 'detectron2.solver.WarmupParamScheduler', 'scheduler': {'_target_': 'fvcore.common.param_scheduler.MultiStepParamScheduler', 'milestones': [163889, 177546], 'num_updates': 184375, 'values': [1.0, 0.1, 0.01]}, 'warmup_factor': 0.001, 'warmup_length': 0.0013559322033898306}, 'model': {'_target_': 'detectron2.modeling.GeneralizedRCNN', 'backbone': {'_target_': 'detectron2.modeling.SimpleFeaturePyramid', 'in_feature': '${.net.out_feature}', 'net': {'_target_': 'detectron2.modeling.ViT', 'depth': 12, 'drop_path_rate': 0.1, 'embed_dim': 768, 'img_size': 1024, 'mlp_ratio': 4, 'norm_layer': functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06), 'num_heads': 12, 'out_feature': 'last_feat', 'patch_size': 16, 'qkv_bias': True, 'residual_block_indexes': [], 'use_rel_pos': True, 'window_block_indexes': [0, 1, 3, 4, 6, 7, 9, 10], 'window_size': 14}, 'norm': 'LN', 'out_channels': 256, 'scale_factors': [4.0, 2.0, 1.0, 0.5], 'square_pad': 1024, 'top_block': {'_target_': 'detectron2.modeling.backbone.fpn.LastLevelMaxPool'}}, 'input_format': 'RGB', 'pixel_mean': [123.675, 116.28, 103.53], 'pixel_std': [58.395, 57.12, 57.375], 'proposal_generator': {'_target_': 'detectron2.modeling.proposal_generator.RPN', 'anchor_generator': {'_target_': 'detectron2.modeling.anchor_generator.DefaultAnchorGenerator', 'aspect_ratios': [0.5, 1.0, 2.0], 'offset': 0.0, 'sizes': [[32], [64], [128], [256], [512]], 'strides': [4, 8, 16, 32, 64]}, 'anchor_matcher': {'_target_': 'detectron2.modeling.matcher.Matcher', 'allow_low_quality_matches': True, 'labels': [0, -1, 1], 'thresholds': [0.3, 0.7]}, 'batch_size_per_image': 256, 'box2box_transform': {'_target_': 'detectron2.modeling.box_regression.Box2BoxTransform', 'weights': [1.0, 1.0, 1.0, 1.0]}, 'head': {'_target_': 'detectron2.modeling.proposal_generator.StandardRPNHead', 'conv_dims': [-1, -1], 'in_channels': 256, 'num_anchors': 3}, 'in_features': ['p2', 'p3', 'p4', 'p5', 'p6'], 'nms_thresh': 0.7, 'positive_fraction': 0.5, 'post_nms_topk': [1000, 1000], 'pre_nms_topk': [2000, 1000]}, 'roi_heads': {'_target_': 'detectron2.modeling.roi_heads.CascadeROIHeads', 'batch_size_per_image': 512, 'box_heads': [{'_target_': 'detectron2.modeling.roi_heads.FastRCNNConvFCHead', 'conv_dims': [256, 256, 256, 256], 'conv_norm': 'LN', 'fc_dims': [1024], 'input_shape': {'channels': 256, 'height': 7, 'width': 7, 'stride': None}}, {'_target_': 'detectron2.modeling.roi_heads.FastRCNNConvFCHead', 'conv_dims': [256, 256, 256, 256], 'conv_norm': 'LN', 'fc_dims': [1024], 'input_shape': {'channels': 256, 'height': 7, 'width': 7, 'stride': None}}, {'_target_': 'detectron2.modeling.roi_heads.FastRCNNConvFCHead', 'conv_dims': [256, 256, 256, 256], 'conv_norm': 'LN', 'fc_dims': [1024], 'input_shape': {'channels': 256, 'height': 7, 'width': 7, 'stride': None}}], 'box_in_features': ['p2', 'p3', 'p4', 'p5'], 'box_pooler': {'_target_': 'detectron2.modeling.poolers.ROIPooler', 'output_size': 7, 'pooler_type': 'ROIAlignV2', 'sampling_ratio': 0, 'scales': [0.25, 0.125, 0.0625, 0.03125]}, 'box_predictors': [{'_target_': 'detectron2.modeling.FastRCNNOutputLayers', 'box2box_transform': {'_target_': 'detectron2.modeling.box_regression.Box2BoxTransform', 'weights': [10, 10, 5, 5]}, 'cls_agnostic_bbox_reg': True, 'input_shape': {'channels': 1024, 'height': None, 'width': None, 'stride': None}, 'num_classes': '${...num_classes}', 'test_score_thresh': 0.05}, {'_target_': 'detectron2.modeling.FastRCNNOutputLayers', 'box2box_transform': {'_target_': 'detectron2.modeling.box_regression.Box2BoxTransform', 'weights': [20, 20, 10, 10]}, 'cls_agnostic_bbox_reg': True, 'input_shape': {'channels': 1024, 'height': None, 'width': None, 'stride': None}, 'num_classes': '${...num_classes}', 'test_score_thresh': 0.05}, {'_target_': 'detectron2.modeling.FastRCNNOutputLayers', 'box2box_transform': {'_target_': 'detectron2.modeling.box_regression.Box2BoxTransform', 'weights': [30, 30, 15, 15]}, 'cls_agnostic_bbox_reg': True, 'input_shape': {'channels': 1024, 'height': None, 'width': None, 'stride': None}, 'num_classes': '${...num_classes}', 'test_score_thresh': 0.05}], 'num_classes': 10, 'positive_fraction': 0.25, 'proposal_matchers': [{'_target_': 'detectron2.modeling.matcher.Matcher', 'allow_low_quality_matches': False, 'labels': [0, 1], 'thresholds': [0.5]}, {'_target_': 'detectron2.modeling.matcher.Matcher', 'allow_low_quality_matches': False, 'labels': [0, 1], 'thresholds': [0.6]}, {'_target_': 'detectron2.modeling.matcher.Matcher', 'allow_low_quality_matches': False, 'labels': [0, 1], 'thresholds': [0.7]}]}}, 'optimizer': {'_target_': 'torch.optim.AdamW', 'betas': [0.9, 0.999], 'lr': 0.0001, 'params': {'_target_': 'detectron2.solver.get_default_optimizer_params', 'base_lr': '${..lr}', 'lr_factor_func': functools.partial(<function get_vit_lr_decay_rate at 0x7fd9d3836680>, lr_decay_rate=0.7, num_layers=12), 'overrides': {'pos_embed': {'weight_decay': 0.0}}, 'weight_decay_norm': 0.0}, 'weight_decay': 0.1}, 'train': {'amp': {'enabled': True}, 'checkpointer': {'max_to_keep': 5, 'period': 5000}, 'ddp': {'broadcast_buffers': False, 'find_unused_parameters': False, 'fp16_compression': True}, 'device': 'cuda', 'eval_period': 500, 'init_checkpoint': 'detectron2://ImageNetPretrained/MAE/mae_pretrain_vit_base.pth?matching_heuristics=True', 'log_period': 20, 'max_iter': 184375, 'output_dir': '/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/vitdet_rcnn_cascade/output'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d82cff70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/18 12:31:15 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/swin_rcnn/output/model_final.pth ...\n",
      "\u001b[32m[10/18 12:31:17 d2.data.datasets.coco]: \u001b[0mLoaded 550 images in COCO format from /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/Split_data/valid_1_10.json\n",
      "\u001b[32m[10/18 12:31:17 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/18 12:31:17 d2.data.common]: \u001b[0mSerializing 550 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/18 12:31:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.26 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 550/550 [02:37<00:00,  3.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from detectron2.config import LazyConfig, instantiate\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.data import build_detection_test_loader\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# mapper - input data를 어떤 형식으로 return할지\n",
    "def MyMapper(dataset_dict):\n",
    "    \n",
    "    # deepcopy를 통해 원본 데이터에 영향을 주지 않음\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    \n",
    "    # file_name 확인\n",
    "    if 'file_name' not in dataset_dict:\n",
    "        raise ValueError(\"dataset_dict does not contain 'file_name'.\")\n",
    "    \n",
    "    # 이미지 읽기\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    image_tensor = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "\n",
    "    # 배치 차원 추가 (1, C, H, W)\n",
    "    #image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "    \n",
    "    # 이미지 데이터 추가\n",
    "    #image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "    dataset_dict['image'] = image_tensor  # 디버깅용 출력\n",
    "    # 변환된 데이터셋 반환\n",
    "    return dataset_dict\n",
    "\n",
    "# LazyConfig 설정 파일 로드\n",
    "cfg = LazyConfig.load(\"/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/swin_rcnn/output/config.yaml\")\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "model = instantiate(cfg.model)\n",
    "model = model.to(torch.device(\"cuda\"))\n",
    "\n",
    "cfg.MODEL = instantiate(cfg.model)\n",
    "cfg.DATALOADER = instantiate(cfg.dataloader)\n",
    "# 제안을 사용하지 않도록 설정\n",
    "cfg.MODEL.LOAD_PROPOSALS = False\n",
    "cfg.DATALOADER.test.dataset.names='coco_trash_test'\n",
    "cfg.DATALOADER.NUM_WORKERS=4,\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS=True\n",
    "\n",
    "# # num_workers와 batch_size가 ListConfig일 수 있으므로 int로 변환\n",
    "# cfg.DATALOADER.NUM_WORKERS = int(cfg.DATALOADER.NUM_WORKERS)\n",
    "# cfg.DATALOADER.BATCH_SIZE = int(cfg.DATALOADER.BATCH_SIZE)\n",
    "# 체크포인트 로드\n",
    "checkpointer = DetectionCheckpointer(model)\n",
    "checkpointer.load(\"/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/swin_rcnn/output/model_final.pth\")\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()\n",
    "\n",
    "# test_loader 설정\n",
    "test_loader = build_detection_test_loader(cfg,'coco_trash_test',mapper=MyMapper,\n",
    "                                        num_workers=cfg.DATALOADER.NUM_WORKERS[0])\n",
    "\n",
    "# 예측 수행\n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "\n",
    "for data in tqdm(test_loader):\n",
    "    \n",
    "    prediction_string = ''\n",
    "    data=data[0]\n",
    "    with torch.no_grad():\n",
    "        batched_inputs = [{\"image\": data['image'].to(torch.device(\"cuda\"))}]\n",
    "        outputs = model(batched_inputs)[0]['instances']  # model에 올바른 형식으로 전달\n",
    "    \n",
    "    # 예측 결과 처리\n",
    "    targets = outputs.pred_classes.cpu().tolist()\n",
    "    boxes = [i.cpu().detach().numpy() for i in outputs.pred_boxes]\n",
    "    scores = outputs.scores.cpu().tolist()\n",
    "    \n",
    "    for target, box, score in zip(targets, boxes, scores):\n",
    "        prediction_string += (str(target) + ' ' + str(score) + ' ' + str(box[0]) + ' ' \n",
    "        + str(box[1]) + ' ' + str(box[2]) + ' ' + str(box[3]) + ' ')\n",
    "    \n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(data['file_name'].replace('/data/ephemeral/home/data/dataset/train/', ''))\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv(os.path.join(cfg.train.output_dir, 'submission_det2.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58d932bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/550 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', dtype=torch.int64)\n",
      "0012.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(test_loader):\n",
    "    data=data[0]\n",
    "    with torch.no_grad():\n",
    "        batched_inputs = [{\"image\": data['image'].to(torch.device(\"cuda\"))}]\n",
    "        outputs = model(batched_inputs)[0]['instances']  # model에 올바른 형식으로 전달\n",
    "    print(outputs.pred_classes)\n",
    "    print(data['file_name'].replace('/data/ephemeral/home/data/dataset/train/', ''))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
