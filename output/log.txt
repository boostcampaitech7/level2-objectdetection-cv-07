[10/23 11:15:52] detectron2 INFO: Rank of current process: 0. World size: 1
[10/23 11:15:53] detectron2 INFO: Environment info:
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2._C                    not built correctly: /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops7reshape4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEE
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
detectron2 arch flags            /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.12.1+cu116 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            Tesla V100-SXM2-32GB (arch=7.0)
Driver version                   535.161.08
CUDA_HOME                        None - invalid!
Pillow                           9.4.0
torchvision                      0.13.1+cu116 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags           /opt/conda/lib/python3.10/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/23 11:15:53] detectron2 INFO: Command line arguments: Namespace(config_file='/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/detectron2/mvitv2_rcnn_cascade/MViTv2/configs/cascade_mask_rcnn_mvitv2_h_in21k_lsj_3x.py', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49152', opts=[])
[10/23 11:15:53] detectron2 INFO: Contents of args.config_file=/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/detectron2/mvitv2_rcnn_cascade/MViTv2/configs/cascade_mask_rcnn_mvitv2_h_in21k_lsj_3x.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mcascade_mask_rcnn_mvitv2_b_3x[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15moptimizer[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mlr_multiplier[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mcoco_loader_lsj[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m


[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15membed_dim[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m192[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15mdepth[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15mnum_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15mlast_block_indexes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m[38;5;141m3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m11[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m71[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m79[39m[38;5;15m)[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15mdrop_path_rate[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15muse_act_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/mvitv2/MViTv2_H_in21k.pyth[39m[38;5;186m"[39m


[38;5;242m# trash image dataÏóê ÎßûÍ≤å ÌÅ¥ÎûòÏä§ Í∞úÏàò ÏàòÏ†ï[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mroi_heads[39m[38;5;197m.[39m[38;5;15mnum_classes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m10[39m

[38;5;242m# Îç∞Ïù¥ÌÑ∞ÏÖã Îì±Î°ù[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetectron2[39m[38;5;15m.[39m[38;5;15mdata[39m[38;5;15m.[39m[38;5;15mdatasets[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mregister_coco_instances[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetectron2[39m[38;5;15m.[39m[38;5;15mdata[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mDatasetCatalog[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mMetadataCatalog[39m

[38;5;242m# MetadataCatalogÎäî Î©îÌÉÄÎç∞Ïù¥ÌÑ∞Î•º ÏÑ§Ï†ï[39m
[38;5;15mMetadataCatalog[39m[38;5;197m.[39m[38;5;15mget[39m[38;5;15m([39m[38;5;186m'[39m[38;5;186mcoco_trash_train[39m[38;5;186m'[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mthing_classes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mGeneral trash[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mPaper[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mPaper pack[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMetal[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m
[38;5;15m                                                         [39m[38;5;186m"[39m[38;5;186mGlass[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mPlastic[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStyrofoam[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mPlastic bag[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBattery[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mClothing[39m[38;5;186m"[39m[38;5;15m][39m


[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmapper[39m[38;5;197m.[39m[38;5;15muse_instance_mask[39m[38;5;197m=[39m[38;5;81mFalse[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmapper[39m[38;5;197m.[39m[38;5;15mrecompute_boxes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;197m.[39m[38;5;15mnames[39m[38;5;197m=[39m[38;5;186m'[39m[38;5;186mcoco_trash_train[39m[38;5;186m'[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtest[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;197m.[39m[38;5;15mnames[39m[38;5;197m=[39m[38;5;186m'[39m[38;5;186mcoco_trash_test[39m[38;5;186m'[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mevaluator[39m[38;5;197m.[39m[38;5;15mdataset_name[39m[38;5;197m=[39m[38;5;186m'[39m[38;5;186mcoco_trash_test[39m[38;5;186m'[39m


[38;5;242m# ÌõàÎ†® Ïù¥ÌÑ∞Î†àÏù¥ÏÖò Ïàò ÏÑ§Ï†ï[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmax_iter[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m20000[39m

[38;5;242m# Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû• Ï£ºÍ∏∞ ÏÑ§Ï†ï[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mperiod[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m5[39m
[38;5;242m# ÌÖåÏä§Ìä∏ Ï£ºÍ∏∞ ÏÑ§Ï†ï[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15meval_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m500[39m

[38;5;242m# ÌïÑÏöîÏóê Îî∞Îùº ÌïôÏäµÎ•† Ïä§ÏºÄÏ§ÑÎü¨ Ï°∞Ï†ï[39m
[38;5;15mlr_multiplier[39m[38;5;197m.[39m[38;5;15mscheduler[39m[38;5;197m.[39m[38;5;15mmilestones[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m[[39m[38;5;141m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m10000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m15000[39m[38;5;15m][39m
[38;5;15mlr_multiplier[39m[38;5;197m.[39m[38;5;15mscheduler[39m[38;5;197m.[39m[38;5;15mvalues[39m[38;5;197m=[39m[38;5;15m[[39m[38;5;141m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.01[39m[38;5;15m][39m

[38;5;81mdel[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mroi_heads[39m[38;5;15m[[39m[38;5;186m'[39m[38;5;186mmask_in_features[39m[38;5;186m'[39m[38;5;15m][39m
[38;5;81mdel[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mroi_heads[39m[38;5;15m[[39m[38;5;186m'[39m[38;5;186mmask_pooler[39m[38;5;186m'[39m[38;5;15m][39m
[38;5;81mdel[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mroi_heads[39m[38;5;15m[[39m[38;5;186m'[39m[38;5;186mmask_head[39m[38;5;186m'[39m[38;5;15m][39m

[38;5;242m### batch size[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mtotal_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m

[10/23 11:15:53] d2.config.lazy WARNING: The config contains objects that cannot serialize to a valid yaml. ./output/config.yaml is human-readable but cannot be loaded.
[10/23 11:15:53] d2.config.lazy WARNING: Config is saved using cloudpickle at ./output/config.yaml.pkl.
[10/23 11:15:53] detectron2 INFO: Full config saved to ./output/config.yaml
[10/23 11:15:53] d2.utils.env INFO: Using a generated random seed 54931908
[10/23 11:27:20] detectron2 INFO: Rank of current process: 0. World size: 1
[10/23 11:27:20] detectron2 INFO: Environment info:
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2._C                    not built correctly: /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops7reshape4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEE
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
detectron2 arch flags            /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.12.1+cu116 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            Tesla V100-SXM2-32GB (arch=7.0)
Driver version                   535.161.08
CUDA_HOME                        None - invalid!
Pillow                           9.4.0
torchvision                      0.13.1+cu116 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags           /opt/conda/lib/python3.10/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/23 11:27:20] detectron2 INFO: Command line arguments: Namespace(config_file='/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/detectron2/mvitv2_rcnn_cascade/MViTv2/configs/cascade_mask_rcnn_mvitv2_h_in21k_lsj_3x.py', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49152', opts=[])
[10/23 11:27:20] detectron2 INFO: Contents of args.config_file=/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/detectron2/mvitv2_rcnn_cascade/MViTv2/configs/cascade_mask_rcnn_mvitv2_h_in21k_lsj_3x.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mcascade_mask_rcnn_mvitv2_b_3x[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15moptimizer[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mlr_multiplier[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mcoco_loader_lsj[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m


[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15membed_dim[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m192[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15mdepth[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15mnum_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15mlast_block_indexes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m[38;5;141m3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m11[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m71[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m79[39m[38;5;15m)[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15mdrop_path_rate[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15muse_act_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/mvitv2/MViTv2_H_in21k.pyth[39m[38;5;186m"[39m


[38;5;242m# trash image dataÏóê ÎßûÍ≤å ÌÅ¥ÎûòÏä§ Í∞úÏàò ÏàòÏ†ï[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mroi_heads[39m[38;5;197m.[39m[38;5;15mnum_classes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m10[39m

[38;5;242m# Îç∞Ïù¥ÌÑ∞ÏÖã Îì±Î°ù[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetectron2[39m[38;5;15m.[39m[38;5;15mdata[39m[38;5;15m.[39m[38;5;15mdatasets[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mregister_coco_instances[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetectron2[39m[38;5;15m.[39m[38;5;15mdata[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mDatasetCatalog[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mMetadataCatalog[39m

[38;5;242m# MetadataCatalogÎäî Î©îÌÉÄÎç∞Ïù¥ÌÑ∞Î•º ÏÑ§Ï†ï[39m
[38;5;15mMetadataCatalog[39m[38;5;197m.[39m[38;5;15mget[39m[38;5;15m([39m[38;5;186m'[39m[38;5;186mcoco_trash_train[39m[38;5;186m'[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mthing_classes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mGeneral trash[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mPaper[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mPaper pack[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMetal[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m
[38;5;15m                                                         [39m[38;5;186m"[39m[38;5;186mGlass[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mPlastic[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStyrofoam[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mPlastic bag[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBattery[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mClothing[39m[38;5;186m"[39m[38;5;15m][39m


[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmapper[39m[38;5;197m.[39m[38;5;15muse_instance_mask[39m[38;5;197m=[39m[38;5;81mFalse[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmapper[39m[38;5;197m.[39m[38;5;15mrecompute_boxes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;197m.[39m[38;5;15mnames[39m[38;5;197m=[39m[38;5;186m'[39m[38;5;186mcoco_trash_train[39m[38;5;186m'[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtest[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;197m.[39m[38;5;15mnames[39m[38;5;197m=[39m[38;5;186m'[39m[38;5;186mcoco_trash_test[39m[38;5;186m'[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mevaluator[39m[38;5;197m.[39m[38;5;15mdataset_name[39m[38;5;197m=[39m[38;5;186m'[39m[38;5;186mcoco_trash_test[39m[38;5;186m'[39m


[38;5;242m# ÌõàÎ†® Ïù¥ÌÑ∞Î†àÏù¥ÏÖò Ïàò ÏÑ§Ï†ï[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmax_iter[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m20000[39m

[38;5;242m# Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû• Ï£ºÍ∏∞ ÏÑ§Ï†ï[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mperiod[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m5[39m
[38;5;242m# ÌÖåÏä§Ìä∏ Ï£ºÍ∏∞ ÏÑ§Ï†ï[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15meval_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1000[39m

[38;5;242m# ÌïÑÏöîÏóê Îî∞Îùº ÌïôÏäµÎ•† Ïä§ÏºÄÏ§ÑÎü¨ Ï°∞Ï†ï[39m
[38;5;15mlr_multiplier[39m[38;5;197m.[39m[38;5;15mscheduler[39m[38;5;197m.[39m[38;5;15mmilestones[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m[[39m[38;5;141m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m10000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m15000[39m[38;5;15m][39m
[38;5;15mlr_multiplier[39m[38;5;197m.[39m[38;5;15mscheduler[39m[38;5;197m.[39m[38;5;15mvalues[39m[38;5;197m=[39m[38;5;15m[[39m[38;5;141m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.01[39m[38;5;15m][39m

[38;5;81mdel[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mroi_heads[39m[38;5;15m[[39m[38;5;186m'[39m[38;5;186mmask_in_features[39m[38;5;186m'[39m[38;5;15m][39m
[38;5;81mdel[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mroi_heads[39m[38;5;15m[[39m[38;5;186m'[39m[38;5;186mmask_pooler[39m[38;5;186m'[39m[38;5;15m][39m
[38;5;81mdel[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mroi_heads[39m[38;5;15m[[39m[38;5;186m'[39m[38;5;186mmask_head[39m[38;5;186m'[39m[38;5;15m][39m

[38;5;242m### batch size[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mtotal_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m

[10/23 11:27:20] d2.config.lazy WARNING: The config contains objects that cannot serialize to a valid yaml. ./output/config.yaml is human-readable but cannot be loaded.
[10/23 11:27:20] d2.config.lazy WARNING: Config is saved using cloudpickle at ./output/config.yaml.pkl.
[10/23 11:27:20] detectron2 INFO: Full config saved to ./output/config.yaml
[10/23 11:27:20] d2.utils.env INFO: Using a generated random seed 22539810
[10/23 11:27:37] detectron2 INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): MViT(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 192, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.008)
          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.015)
          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (3): MultiScaleBlock(
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.023)
          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (4): MultiScaleBlock(
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=192, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.030)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (proj): Linear(in_features=192, out_features=384, bias=True)
          (pool_skip): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.038)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (6): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.046)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (7): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.053)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (8): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.061)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (9): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.068)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (10): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.076)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (11): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.084)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (12): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.091)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (proj): Linear(in_features=384, out_features=768, bias=True)
          (pool_skip): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        )
        (13): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.099)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (14): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.106)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (15): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.114)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (16): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.122)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (17): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.129)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (18): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.137)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (19): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.144)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (20): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.152)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.159)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (22): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.167)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (23): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.175)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (24): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.182)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (25): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.190)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (26): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.197)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (27): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.205)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (28): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.213)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (29): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.220)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (30): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.228)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (31): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.235)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (32): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.243)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (33): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.251)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (34): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.258)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (35): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.266)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (36): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.273)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (37): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.281)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (38): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.289)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (39): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.296)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (40): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.304)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (41): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.311)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (42): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.319)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (43): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.327)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (44): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.334)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (45): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.342)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (46): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.349)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (47): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.357)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (48): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.365)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (49): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.372)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (50): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.380)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (51): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.387)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (52): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.395)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (53): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.403)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (54): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.410)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (55): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.418)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (56): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.425)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (57): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.433)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (58): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.441)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (59): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.448)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (60): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.456)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (61): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.463)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (62): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.471)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (63): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.478)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (64): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.486)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (65): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.494)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (66): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.501)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (67): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.509)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (68): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.516)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (69): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.524)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (70): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.532)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (71): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.539)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (72): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.547)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (proj): Linear(in_features=768, out_features=1536, bias=True)
          (pool_skip): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        )
        (73): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.554)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (74): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.562)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (75): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.570)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (76): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.577)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (77): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.585)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (78): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.592)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (79): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.600)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (scale2_norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (scale3_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (scale4_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (scale5_norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Sequential(
        (conv0): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (flatten): Flatten(start_dim=1, end_dim=-1)
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
        (fc_relu1): ReLU()
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (flatten): Flatten(start_dim=1, end_dim=-1)
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
        (fc_relu1): ReLU()
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (flatten): Flatten(start_dim=1, end_dim=-1)
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
        (fc_relu1): ReLU()
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=11, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=11, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=11, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[10/23 11:27:45] d2.data.datasets.coco INFO: Loaded 4437 images in COCO format from /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/Split_data/train_0_10.json
[10/23 11:27:45] d2.data.build INFO: Removed 0 images with no usable annotations. 4437 images left.
[10/23 11:27:45] d2.data.build INFO: Distribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
| General trash | 3523         |    Paper    | 5785         | Paper pack | 840          |
|     Metal     | 882          |    Glass    | 891          |  Plastic   | 2707         |
|   Styrofoam   | 1108         | Plastic bag | 4664         |  Battery   | 146          |
|   Clothing    | 412          |             |              |            |              |
|     total     | 20958        |             |              |            |              |[0m
[10/23 11:27:45] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=[1024, 1024])]
[10/23 11:27:45] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/23 11:27:45] d2.data.common INFO: Serializing 4437 elements to byte tensors and concatenating them all ...
[10/23 11:27:45] d2.data.common INFO: Serialized dataset takes 2.07 MiB
[10/23 11:27:45] d2.data.build INFO: Making batched data loader with batch_size=4
[10/23 11:27:45] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/mvitv2/MViTv2_H_in21k.pyth ...
[10/23 11:27:45] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /data/ephemeral/home/.torch/iopath_cache/detectron2/ImageNetPretrained/mvitv2/MViTv2_H_in21k.pyth ...
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv1.norm.bias in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv1.norm.weight in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv2.norm.bias in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv2.norm.weight in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv3.norm.bias in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv3.norm.weight in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv4.norm.bias in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv4.norm.weight in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv1.norm.bias in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv1.norm.weight in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv2.norm.bias in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv2.norm.weight in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv3.norm.bias in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv3.norm.weight in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv4.norm.bias in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv4.norm.weight in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv1.norm.bias in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv1.norm.weight in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv2.norm.bias in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv2.norm.weight in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv3.norm.bias in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv3.norm.weight in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv4.norm.bias in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv4.norm.weight in model is torch.Size([256]).
[10/23 11:27:53] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:27:53] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up - Total num: 404
[10/23 11:27:57] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.scale2_norm.{bias, weight}[0m
[34mbackbone.bottom_up.scale3_norm.{bias, weight}[0m
[34mbackbone.bottom_up.scale4_norm.{bias, weight}[0m
[34mbackbone.bottom_up.scale5_norm.{bias, weight}[0m
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv0.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv1.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.0.conv1.weight[0m
[34mroi_heads.box_head.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.0.conv2.weight[0m
[34mroi_heads.box_head.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.0.conv3.weight[0m
[34mroi_heads.box_head.0.conv4.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.0.conv4.weight[0m
[34mroi_heads.box_head.0.fc1.{bias, weight}[0m
[34mroi_heads.box_head.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.1.conv1.weight[0m
[34mroi_heads.box_head.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.1.conv2.weight[0m
[34mroi_heads.box_head.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.1.conv3.weight[0m
[34mroi_heads.box_head.1.conv4.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.1.conv4.weight[0m
[34mroi_heads.box_head.1.fc1.{bias, weight}[0m
[34mroi_heads.box_head.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.2.conv1.weight[0m
[34mroi_heads.box_head.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.2.conv2.weight[0m
[34mroi_heads.box_head.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.2.conv3.weight[0m
[34mroi_heads.box_head.2.conv4.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.2.conv4.weight[0m
[34mroi_heads.box_head.2.fc1.{bias, weight}[0m
[34mroi_heads.box_predictor.0.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.0.cls_score.{bias, weight}[0m
[34mroi_heads.box_predictor.1.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.1.cls_score.{bias, weight}[0m
[34mroi_heads.box_predictor.2.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.2.cls_score.{bias, weight}[0m
[10/23 11:27:57] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mcls_token[0m
  [35mhead.projection.{bias, weight}[0m
  [35mnorm.{bias, weight}[0m
[10/23 11:27:57] d2.engine.train_loop INFO: Starting training from iteration 0
[10/23 11:31:49] d2.utils.events INFO:  eta: 2 days, 15:27:58  iter: 19  total_loss: 7.575  loss_cls_stage0: 2.302  loss_box_reg_stage0: 0.008076  loss_cls_stage1: 2.305  loss_box_reg_stage1: 0.003304  loss_cls_stage2: 2.17  loss_box_reg_stage2: 0.00219  loss_rpn_cls: 0.6889  loss_rpn_loc: 0.09377    time: 11.3336  last_time: 11.4860  data_time: 0.0335  last_data_time: 0.0114   lr: 4.223e-06  max_mem: 18670M
[10/23 11:35:38] d2.utils.events INFO:  eta: 2 days, 15:28:06  iter: 39  total_loss: 3.414  loss_cls_stage0: 0.8433  loss_box_reg_stage0: 0.06593  loss_cls_stage1: 0.8825  loss_box_reg_stage1: 0.03357  loss_cls_stage2: 0.7155  loss_box_reg_stage2: 0.0155  loss_rpn_cls: 0.6555  loss_rpn_loc: 0.1496    time: 11.3827  last_time: 11.3361  data_time: 0.0119  last_data_time: 0.0090   lr: 8.4998e-06  max_mem: 18670M
[10/23 11:38:46] d2.utils.events INFO:  eta: 2 days, 15:16:28  iter: 59  total_loss: 1.216  loss_cls_stage0: 0.1876  loss_box_reg_stage0: 0.07144  loss_cls_stage1: 0.1252  loss_box_reg_stage1: 0.03983  loss_cls_stage2: 0.09454  loss_box_reg_stage2: 0.0118  loss_rpn_cls: 0.5336  loss_rpn_loc: 0.04094    time: 10.7063  last_time: 5.0768  data_time: 0.0135  last_data_time: 0.0110   lr: 1.2777e-05  max_mem: 18670M
[10/23 11:40:28] d2.utils.events INFO:  eta: 2 days, 14:10:33  iter: 79  total_loss: 1.101  loss_cls_stage0: 0.1944  loss_box_reg_stage0: 0.1086  loss_cls_stage1: 0.1151  loss_box_reg_stage1: 0.06013  loss_cls_stage2: 0.07568  loss_box_reg_stage2: 0.02095  loss_rpn_cls: 0.2588  loss_rpn_loc: 0.1634    time: 9.2656  last_time: 5.0870  data_time: 0.0097  last_data_time: 0.0092   lr: 1.6e-05  max_mem: 18670M
[10/23 11:41:09] d2.engine.hooks INFO: Overall training speed: 85 iterations in 0:12:43 (8.9816 s / it)
[10/23 11:41:09] d2.engine.hooks INFO: Total training time: 0:12:43 (0:00:00 on hooks)
[10/23 11:41:09] d2.utils.events INFO:  eta: 2 days, 13:52:11  iter: 87  total_loss: 1.211  loss_cls_stage0: 0.2112  loss_box_reg_stage0: 0.1363  loss_cls_stage1: 0.1206  loss_box_reg_stage1: 0.07992  loss_cls_stage2: 0.08006  loss_box_reg_stage2: 0.02335  loss_rpn_cls: 0.1742  loss_rpn_loc: 0.1255    time: 8.9243  last_time: 5.2075  data_time: 0.0100  last_data_time: 0.0122   lr: 1.6e-05  max_mem: 18670M
[10/23 11:42:01] detectron2 INFO: Rank of current process: 0. World size: 1
[10/23 11:42:01] detectron2 INFO: Environment info:
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2._C                    not built correctly: /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops7reshape4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEE
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
detectron2 arch flags            /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.12.1+cu116 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            Tesla V100-SXM2-32GB (arch=7.0)
Driver version                   535.161.08
CUDA_HOME                        None - invalid!
Pillow                           9.4.0
torchvision                      0.13.1+cu116 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags           /opt/conda/lib/python3.10/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/23 11:42:01] detectron2 INFO: Command line arguments: Namespace(config_file='/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/detectron2/mvitv2_rcnn_cascade/MViTv2/configs/cascade_mask_rcnn_mvitv2_h_in21k_lsj_3x.py', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49152', opts=[])
[10/23 11:42:01] detectron2 INFO: Contents of args.config_file=/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/detectron2/mvitv2_rcnn_cascade/MViTv2/configs/cascade_mask_rcnn_mvitv2_h_in21k_lsj_3x.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mcascade_mask_rcnn_mvitv2_b_3x[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15moptimizer[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mlr_multiplier[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mcoco_loader_lsj[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m


[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15membed_dim[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m192[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15mdepth[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15mnum_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15mlast_block_indexes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m[38;5;141m3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m11[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m71[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m79[39m[38;5;15m)[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15mdrop_path_rate[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mbottom_up[39m[38;5;197m.[39m[38;5;15muse_act_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/mvitv2/MViTv2_H_in21k.pyth[39m[38;5;186m"[39m


[38;5;242m# trash image dataÏóê ÎßûÍ≤å ÌÅ¥ÎûòÏä§ Í∞úÏàò ÏàòÏ†ï[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mroi_heads[39m[38;5;197m.[39m[38;5;15mnum_classes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m10[39m

[38;5;242m# Îç∞Ïù¥ÌÑ∞ÏÖã Îì±Î°ù[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetectron2[39m[38;5;15m.[39m[38;5;15mdata[39m[38;5;15m.[39m[38;5;15mdatasets[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mregister_coco_instances[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetectron2[39m[38;5;15m.[39m[38;5;15mdata[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mDatasetCatalog[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mMetadataCatalog[39m

[38;5;242m# MetadataCatalogÎäî Î©îÌÉÄÎç∞Ïù¥ÌÑ∞Î•º ÏÑ§Ï†ï[39m
[38;5;15mMetadataCatalog[39m[38;5;197m.[39m[38;5;15mget[39m[38;5;15m([39m[38;5;186m'[39m[38;5;186mcoco_trash_train[39m[38;5;186m'[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mthing_classes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mGeneral trash[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mPaper[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mPaper pack[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMetal[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m
[38;5;15m                                                         [39m[38;5;186m"[39m[38;5;186mGlass[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mPlastic[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStyrofoam[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mPlastic bag[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBattery[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mClothing[39m[38;5;186m"[39m[38;5;15m][39m


[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmapper[39m[38;5;197m.[39m[38;5;15muse_instance_mask[39m[38;5;197m=[39m[38;5;81mFalse[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmapper[39m[38;5;197m.[39m[38;5;15mrecompute_boxes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;197m.[39m[38;5;15mnames[39m[38;5;197m=[39m[38;5;186m'[39m[38;5;186mcoco_trash_train[39m[38;5;186m'[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtest[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;197m.[39m[38;5;15mnames[39m[38;5;197m=[39m[38;5;186m'[39m[38;5;186mcoco_trash_test[39m[38;5;186m'[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mevaluator[39m[38;5;197m.[39m[38;5;15mdataset_name[39m[38;5;197m=[39m[38;5;186m'[39m[38;5;186mcoco_trash_test[39m[38;5;186m'[39m


[38;5;242m# ÌõàÎ†® Ïù¥ÌÑ∞Î†àÏù¥ÏÖò Ïàò ÏÑ§Ï†ï[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmax_iter[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m20000[39m

[38;5;242m# Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû• Ï£ºÍ∏∞ ÏÑ§Ï†ï[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mperiod[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m5[39m
[38;5;242m# ÌÖåÏä§Ìä∏ Ï£ºÍ∏∞ ÏÑ§Ï†ï[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15meval_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1000[39m

[38;5;242m# ÌïÑÏöîÏóê Îî∞Îùº ÌïôÏäµÎ•† Ïä§ÏºÄÏ§ÑÎü¨ Ï°∞Ï†ï[39m
[38;5;15mlr_multiplier[39m[38;5;197m.[39m[38;5;15mscheduler[39m[38;5;197m.[39m[38;5;15mmilestones[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m[[39m[38;5;141m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m10000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m15000[39m[38;5;15m][39m
[38;5;15mlr_multiplier[39m[38;5;197m.[39m[38;5;15mscheduler[39m[38;5;197m.[39m[38;5;15mvalues[39m[38;5;197m=[39m[38;5;15m[[39m[38;5;141m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.01[39m[38;5;15m][39m

[38;5;81mdel[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mroi_heads[39m[38;5;15m[[39m[38;5;186m'[39m[38;5;186mmask_in_features[39m[38;5;186m'[39m[38;5;15m][39m
[38;5;81mdel[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mroi_heads[39m[38;5;15m[[39m[38;5;186m'[39m[38;5;186mmask_pooler[39m[38;5;186m'[39m[38;5;15m][39m
[38;5;81mdel[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mroi_heads[39m[38;5;15m[[39m[38;5;186m'[39m[38;5;186mmask_head[39m[38;5;186m'[39m[38;5;15m][39m

[38;5;242m### batch size[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mtotal_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m

[10/23 11:42:02] d2.config.lazy WARNING: The config contains objects that cannot serialize to a valid yaml. ./output/config.yaml is human-readable but cannot be loaded.
[10/23 11:42:02] d2.config.lazy WARNING: Config is saved using cloudpickle at ./output/config.yaml.pkl.
[10/23 11:42:02] detectron2 INFO: Full config saved to ./output/config.yaml
[10/23 11:42:02] d2.utils.env INFO: Using a generated random seed 3552665
[10/23 11:42:19] detectron2 INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): MViT(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 192, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.008)
          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.015)
          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (3): MultiScaleBlock(
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.023)
          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (4): MultiScaleBlock(
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=192, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.030)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (proj): Linear(in_features=192, out_features=384, bias=True)
          (pool_skip): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.038)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (6): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.046)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (7): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.053)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (8): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.061)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (9): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.068)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (10): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.076)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (11): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.084)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (12): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.091)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (proj): Linear(in_features=384, out_features=768, bias=True)
          (pool_skip): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        )
        (13): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.099)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (14): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.106)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (15): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.114)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (16): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.122)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (17): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.129)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (18): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.137)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (19): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.144)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (20): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.152)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.159)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (22): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.167)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (23): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.175)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (24): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.182)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (25): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.190)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (26): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.197)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (27): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.205)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (28): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.213)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (29): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.220)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (30): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.228)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (31): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.235)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (32): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.243)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (33): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.251)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (34): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.258)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (35): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.266)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (36): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.273)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (37): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.281)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (38): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.289)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (39): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.296)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (40): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.304)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (41): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.311)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (42): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.319)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (43): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.327)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (44): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.334)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (45): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.342)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (46): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.349)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (47): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.357)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (48): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.365)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (49): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.372)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (50): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.380)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (51): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.387)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (52): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.395)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (53): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.403)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (54): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.410)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (55): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.418)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (56): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.425)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (57): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.433)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (58): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.441)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (59): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.448)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (60): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.456)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (61): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.463)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (62): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.471)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (63): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.478)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (64): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.486)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (65): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.494)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (66): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.501)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (67): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.509)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (68): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.516)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (69): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.524)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (70): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.532)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (71): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.539)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (72): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.547)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (proj): Linear(in_features=768, out_features=1536, bias=True)
          (pool_skip): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        )
        (73): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.554)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (74): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.562)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (75): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.570)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (76): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.577)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (77): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.585)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (78): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.592)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (79): MultiScaleBlock(
          (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (pool_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_q): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_k): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (norm_v): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.600)
          (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (scale2_norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (scale3_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (scale4_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (scale5_norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Sequential(
        (conv0): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (flatten): Flatten(start_dim=1, end_dim=-1)
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
        (fc_relu1): ReLU()
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (flatten): Flatten(start_dim=1, end_dim=-1)
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
        (fc_relu1): ReLU()
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (flatten): Flatten(start_dim=1, end_dim=-1)
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
        (fc_relu1): ReLU()
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=11, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=11, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=11, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[10/23 11:42:26] d2.data.datasets.coco INFO: Loaded 3943 images in COCO format from /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/Split_data/train_0_5.json
[10/23 11:42:26] d2.data.build INFO: Removed 0 images with no usable annotations. 3943 images left.
[10/23 11:42:26] d2.data.build INFO: Distribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
| General trash | 3192         |    Paper    | 5274         | Paper pack | 702          |
|     Metal     | 783          |    Glass    | 697          |  Plastic   | 2376         |
|   Styrofoam   | 1005         | Plastic bag | 4168         |  Battery   | 135          |
|   Clothing    | 346          |             |              |            |              |
|     total     | 18678        |             |              |            |              |[0m
[10/23 11:42:26] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=[1024, 1024])]
[10/23 11:42:26] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/23 11:42:26] d2.data.common INFO: Serializing 3943 elements to byte tensors and concatenating them all ...
[10/23 11:42:26] d2.data.common INFO: Serialized dataset takes 1.84 MiB
[10/23 11:42:26] d2.data.build INFO: Making batched data loader with batch_size=4
[10/23 11:42:26] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/mvitv2/MViTv2_H_in21k.pyth ...
[10/23 11:42:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /data/ephemeral/home/.torch/iopath_cache/detectron2/ImageNetPretrained/mvitv2/MViTv2_H_in21k.pyth ...
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv1.norm.bias in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv1.norm.weight in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv2.norm.bias in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv2.norm.weight in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv3.norm.bias in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv3.norm.weight in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv4.norm.bias in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.0.conv4.norm.weight in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv1.norm.bias in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv1.norm.weight in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv2.norm.bias in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv2.norm.weight in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv3.norm.bias in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv3.norm.weight in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv4.norm.bias in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.1.conv4.norm.weight in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv1.norm.bias in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv1.norm.weight in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv2.norm.bias in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv2.norm.weight in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv3.norm.bias in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv3.norm.weight in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv4.norm.bias in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1536]), while shape of roi_heads.box_head.2.conv4.norm.weight in model is torch.Size([256]).
[10/23 11:42:34] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/23 11:42:34] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up - Total num: 404
[10/23 11:42:38] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.scale2_norm.{bias, weight}[0m
[34mbackbone.bottom_up.scale3_norm.{bias, weight}[0m
[34mbackbone.bottom_up.scale4_norm.{bias, weight}[0m
[34mbackbone.bottom_up.scale5_norm.{bias, weight}[0m
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv0.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv1.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.0.conv1.weight[0m
[34mroi_heads.box_head.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.0.conv2.weight[0m
[34mroi_heads.box_head.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.0.conv3.weight[0m
[34mroi_heads.box_head.0.conv4.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.0.conv4.weight[0m
[34mroi_heads.box_head.0.fc1.{bias, weight}[0m
[34mroi_heads.box_head.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.1.conv1.weight[0m
[34mroi_heads.box_head.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.1.conv2.weight[0m
[34mroi_heads.box_head.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.1.conv3.weight[0m
[34mroi_heads.box_head.1.conv4.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.1.conv4.weight[0m
[34mroi_heads.box_head.1.fc1.{bias, weight}[0m
[34mroi_heads.box_head.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.2.conv1.weight[0m
[34mroi_heads.box_head.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.2.conv2.weight[0m
[34mroi_heads.box_head.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.2.conv3.weight[0m
[34mroi_heads.box_head.2.conv4.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.2.conv4.weight[0m
[34mroi_heads.box_head.2.fc1.{bias, weight}[0m
[34mroi_heads.box_predictor.0.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.0.cls_score.{bias, weight}[0m
[34mroi_heads.box_predictor.1.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.1.cls_score.{bias, weight}[0m
[34mroi_heads.box_predictor.2.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.2.cls_score.{bias, weight}[0m
[10/23 11:42:38] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mcls_token[0m
  [35mhead.projection.{bias, weight}[0m
  [35mnorm.{bias, weight}[0m
[10/23 11:42:38] d2.engine.train_loop INFO: Starting training from iteration 0
[10/23 11:46:28] d2.utils.events INFO:  eta: 2 days, 15:13:57  iter: 19  total_loss: 7.271  loss_cls_stage0: 2.054  loss_box_reg_stage0: 0.0005349  loss_cls_stage1: 2.097  loss_box_reg_stage1: 0.0009278  loss_cls_stage2: 2.308  loss_box_reg_stage2: 0.001522  loss_rpn_cls: 0.6927  loss_rpn_loc: 0.1305    time: 11.3200  last_time: 11.0743  data_time: 0.0315  last_data_time: 0.0087   lr: 4.223e-06  max_mem: 18670M
[10/23 11:50:11] d2.utils.events INFO:  eta: 2 days, 15:10:09  iter: 39  total_loss: 3.597  loss_cls_stage0: 0.88  loss_box_reg_stage0: 0.03831  loss_cls_stage1: 0.8591  loss_box_reg_stage1: 0.01562  loss_cls_stage2: 0.9283  loss_box_reg_stage2: 0.003002  loss_rpn_cls: 0.6599  loss_rpn_loc: 0.09554    time: 11.2272  last_time: 6.8635  data_time: 0.0098  last_data_time: 0.0107   lr: 8.4998e-06  max_mem: 18670M
[10/23 11:51:53] d2.utils.events INFO:  eta: 2 days, 13:50:16  iter: 59  total_loss: 1.424  loss_cls_stage0: 0.2364  loss_box_reg_stage0: 0.06189  loss_cls_stage1: 0.1697  loss_box_reg_stage1: 0.03659  loss_cls_stage2: 0.1499  loss_box_reg_stage2: 0.01116  loss_rpn_cls: 0.5189  loss_rpn_loc: 0.1363    time: 9.1077  last_time: 5.0744  data_time: 0.0107  last_data_time: 0.0100   lr: 1.2777e-05  max_mem: 18670M
[10/23 11:53:35] d2.utils.events INFO:  eta: 1 day, 4:10:19  iter: 79  total_loss: 0.8477  loss_cls_stage0: 0.1999  loss_box_reg_stage0: 0.1225  loss_cls_stage1: 0.1117  loss_box_reg_stage1: 0.05344  loss_cls_stage2: 0.07561  loss_box_reg_stage2: 0.01969  loss_rpn_cls: 0.1809  loss_rpn_loc: 0.08279    time: 8.0742  last_time: 5.0790  data_time: 0.0097  last_data_time: 0.0099   lr: 1.6e-05  max_mem: 18670M
[10/23 11:55:21] d2.utils.events INFO:  eta: 1 day, 4:12:59  iter: 99  total_loss: 0.9167  loss_cls_stage0: 0.2097  loss_box_reg_stage0: 0.1313  loss_cls_stage1: 0.1179  loss_box_reg_stage1: 0.07258  loss_cls_stage2: 0.07708  loss_box_reg_stage2: 0.02258  loss_rpn_cls: 0.1318  loss_rpn_loc: 0.06805    time: 7.5088  last_time: 7.6690  data_time: 0.0114  last_data_time: 0.0106   lr: 1.6e-05  max_mem: 18670M
[10/23 11:59:09] d2.utils.events INFO:  eta: 1 day, 10:08:32  iter: 119  total_loss: 0.9662  loss_cls_stage0: 0.2359  loss_box_reg_stage0: 0.1532  loss_cls_stage1: 0.13  loss_box_reg_stage1: 0.08545  loss_cls_stage2: 0.07818  loss_box_reg_stage2: 0.02548  loss_rpn_cls: 0.1541  loss_rpn_loc: 0.09896    time: 8.1733  last_time: 11.5289  data_time: 0.0114  last_data_time: 0.0092   lr: 1.6e-05  max_mem: 18670M
[10/23 12:02:58] d2.utils.events INFO:  eta: 2 days, 13:33:55  iter: 139  total_loss: 1.029  loss_cls_stage0: 0.2586  loss_box_reg_stage0: 0.1584  loss_cls_stage1: 0.1384  loss_box_reg_stage1: 0.0899  loss_cls_stage2: 0.08747  loss_box_reg_stage2: 0.0295  loss_rpn_cls: 0.1292  loss_rpn_loc: 0.1058    time: 8.6487  last_time: 11.4853  data_time: 0.0130  last_data_time: 0.0120   lr: 1.6e-05  max_mem: 18670M
[10/23 12:05:46] d2.utils.events INFO:  eta: 2 days, 13:30:12  iter: 159  total_loss: 0.783  loss_cls_stage0: 0.1955  loss_box_reg_stage0: 0.1323  loss_cls_stage1: 0.1052  loss_box_reg_stage1: 0.08273  loss_cls_stage2: 0.05245  loss_box_reg_stage2: 0.02326  loss_rpn_cls: 0.08922  loss_rpn_loc: 0.07704    time: 8.6131  last_time: 5.0745  data_time: 0.0093  last_data_time: 0.0101   lr: 1.6e-05  max_mem: 18670M
[10/23 12:07:27] d2.utils.events INFO:  eta: 1 day, 15:17:57  iter: 179  total_loss: 0.8542  loss_cls_stage0: 0.2182  loss_box_reg_stage0: 0.1446  loss_cls_stage1: 0.1066  loss_box_reg_stage1: 0.08059  loss_cls_stage2: 0.06377  loss_box_reg_stage2: 0.0259  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.08844    time: 8.2148  last_time: 5.0689  data_time: 0.0106  last_data_time: 0.0094   lr: 1.6e-05  max_mem: 18670M
[10/23 12:09:09] d2.utils.events INFO:  eta: 1 day, 4:11:22  iter: 199  total_loss: 0.92  loss_cls_stage0: 0.2131  loss_box_reg_stage0: 0.1511  loss_cls_stage1: 0.1168  loss_box_reg_stage1: 0.08498  loss_cls_stage2: 0.07246  loss_box_reg_stage2: 0.02996  loss_rpn_cls: 0.1111  loss_rpn_loc: 0.08752    time: 7.8990  last_time: 5.0785  data_time: 0.0108  last_data_time: 0.0106   lr: 1.6e-05  max_mem: 18670M
[10/23 12:10:50] d2.utils.events INFO:  eta: 1 day, 3:58:59  iter: 219  total_loss: 1.031  loss_cls_stage0: 0.2358  loss_box_reg_stage0: 0.1974  loss_cls_stage1: 0.1269  loss_box_reg_stage1: 0.08594  loss_cls_stage2: 0.07527  loss_box_reg_stage2: 0.03646  loss_rpn_cls: 0.09328  loss_rpn_loc: 0.0901    time: 7.6400  last_time: 5.0754  data_time: 0.0105  last_data_time: 0.0088   lr: 1.6e-05  max_mem: 18670M
[10/23 12:12:32] d2.utils.events INFO:  eta: 1 day, 3:55:58  iter: 239  total_loss: 0.9382  loss_cls_stage0: 0.2463  loss_box_reg_stage0: 0.1769  loss_cls_stage1: 0.1318  loss_box_reg_stage1: 0.09718  loss_cls_stage2: 0.07454  loss_box_reg_stage2: 0.0361  loss_rpn_cls: 0.08783  loss_rpn_loc: 0.05424    time: 7.4249  last_time: 5.0872  data_time: 0.0097  last_data_time: 0.0079   lr: 1.6e-05  max_mem: 18670M
[10/23 12:14:14] d2.utils.events INFO:  eta: 1 day, 3:53:42  iter: 259  total_loss: 1.004  loss_cls_stage0: 0.2628  loss_box_reg_stage0: 0.2104  loss_cls_stage1: 0.1393  loss_box_reg_stage1: 0.1007  loss_cls_stage2: 0.07339  loss_box_reg_stage2: 0.03049  loss_rpn_cls: 0.0805  loss_rpn_loc: 0.09882    time: 7.2430  last_time: 5.0722  data_time: 0.0105  last_data_time: 0.0094   lr: 1.6e-05  max_mem: 18670M
[10/23 12:15:55] d2.utils.events INFO:  eta: 1 day, 3:51:19  iter: 279  total_loss: 1.333  loss_cls_stage0: 0.3364  loss_box_reg_stage0: 0.2863  loss_cls_stage1: 0.1749  loss_box_reg_stage1: 0.1533  loss_cls_stage2: 0.09336  loss_box_reg_stage2: 0.03968  loss_rpn_cls: 0.1039  loss_rpn_loc: 0.0762    time: 7.0868  last_time: 5.0659  data_time: 0.0113  last_data_time: 0.0103   lr: 1.6e-05  max_mem: 18670M
[10/23 12:17:36] d2.utils.events INFO:  eta: 1 day, 3:48:58  iter: 299  total_loss: 1.129  loss_cls_stage0: 0.3122  loss_box_reg_stage0: 0.269  loss_cls_stage1: 0.167  loss_box_reg_stage1: 0.1331  loss_cls_stage2: 0.08311  loss_box_reg_stage2: 0.03708  loss_rpn_cls: 0.05896  loss_rpn_loc: 0.06217    time: 6.9512  last_time: 5.0569  data_time: 0.0104  last_data_time: 0.0090   lr: 1.6e-05  max_mem: 18670M
[10/23 12:19:18] d2.utils.events INFO:  eta: 1 day, 3:46:28  iter: 319  total_loss: 1.203  loss_cls_stage0: 0.328  loss_box_reg_stage0: 0.2853  loss_cls_stage1: 0.1698  loss_box_reg_stage1: 0.1508  loss_cls_stage2: 0.0994  loss_box_reg_stage2: 0.05502  loss_rpn_cls: 0.06982  loss_rpn_loc: 0.06523    time: 6.8323  last_time: 5.0652  data_time: 0.0107  last_data_time: 0.0098   lr: 1.6e-05  max_mem: 18670M
[10/23 12:20:59] d2.utils.events INFO:  eta: 1 day, 3:44:36  iter: 339  total_loss: 1.224  loss_cls_stage0: 0.3204  loss_box_reg_stage0: 0.2648  loss_cls_stage1: 0.1714  loss_box_reg_stage1: 0.1443  loss_cls_stage2: 0.08246  loss_box_reg_stage2: 0.04754  loss_rpn_cls: 0.07424  loss_rpn_loc: 0.1409    time: 6.7282  last_time: 5.1404  data_time: 0.0105  last_data_time: 0.0091   lr: 1.6e-05  max_mem: 18670M
