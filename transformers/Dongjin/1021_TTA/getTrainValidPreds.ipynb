{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection, Trainer\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "sys.path.append(\"../../../transformers/Dongjin/1011_model_search\")\n",
    "import utils\n",
    "import dataset\n",
    "import train_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DetaForObjectDetection(\n",
       "  (model): DetaModel(\n",
       "    (backbone): DetaBackboneWithPositionalEncodings(\n",
       "      (model): SwinBackbone(\n",
       "        (embeddings): SwinEmbeddings(\n",
       "          (patch_embeddings): SwinPatchEmbeddings(\n",
       "            (projection): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "          )\n",
       "          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (encoder): SwinEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0): SwinStage(\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): SwinPatchMerging(\n",
       "                (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "                (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinStage(\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): SwinPatchMerging(\n",
       "                (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (2): SwinStage(\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (2): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (4): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (5): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (6): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (7): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (8): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (9): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (10): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (11): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (12): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (13): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (14): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (15): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (16): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (17): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): SwinPatchMerging(\n",
       "                (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
       "                (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (3): SwinStage(\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                      (key): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                      (value): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                      (key): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                      (value): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (hidden_states_norms): ModuleDict(\n",
       "          (stage2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (stage3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (stage4): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (position_embedding): DetaSinePositionEmbedding()\n",
       "    )\n",
       "    (input_proj): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(1536, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder): DetaEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): DetaEncoderLayer(\n",
       "          (self_attn): DetaMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): DetaEncoderLayer(\n",
       "          (self_attn): DetaMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): DetaEncoderLayer(\n",
       "          (self_attn): DetaMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): DetaEncoderLayer(\n",
       "          (self_attn): DetaMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): DetaEncoderLayer(\n",
       "          (self_attn): DetaMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): DetaEncoderLayer(\n",
       "          (self_attn): DetaMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): DetaDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): DetaDecoderLayer(\n",
       "          (self_attn): DetaMultiheadAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): DetaMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): DetaDecoderLayer(\n",
       "          (self_attn): DetaMultiheadAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): DetaMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): DetaDecoderLayer(\n",
       "          (self_attn): DetaMultiheadAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): DetaMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): DetaDecoderLayer(\n",
       "          (self_attn): DetaMultiheadAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): DetaMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): DetaDecoderLayer(\n",
       "          (self_attn): DetaMultiheadAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): DetaMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): DetaDecoderLayer(\n",
       "          (self_attn): DetaMultiheadAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): DetaMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (bbox_embed): ModuleList(\n",
       "        (0): DetaMLPPredictionHead(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (1): DetaMLPPredictionHead(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (2): DetaMLPPredictionHead(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (3): DetaMLPPredictionHead(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (4): DetaMLPPredictionHead(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (5): DetaMLPPredictionHead(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (6): DetaMLPPredictionHead(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (class_embed): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=10, bias=True)\n",
       "        (1): Linear(in_features=256, out_features=10, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "        (3): Linear(in_features=256, out_features=10, bias=True)\n",
       "        (4): Linear(in_features=256, out_features=10, bias=True)\n",
       "        (5): Linear(in_features=256, out_features=10, bias=True)\n",
       "        (6): Linear(in_features=256, out_features=10, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (enc_output): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (enc_output_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (pos_trans): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (pos_trans_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (pix_trans): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (pix_trans_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (class_embed): ModuleList(\n",
       "    (0): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (5): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (6): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       "  (bbox_embed): ModuleList(\n",
       "    (0): DetaMLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): DetaMLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): DetaMLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): DetaMLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): DetaMLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (5): DetaMLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (6): DetaMLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '../../../transformers/Dongjin/1011_model_search/result/1015/jozhang97/deta-swin-large_3_img_size_720'\n",
    "coco_dir_path = '../../../Split_data'\n",
    "checkpoint_dir = 'checkpoint-15704'\n",
    "device = 'cuda'\n",
    "\n",
    "checkpoint_path = os.path.join(model_path, checkpoint_dir)\n",
    "run_name = os.path.split(model_path)[-1]\n",
    "json_path = os.path.join(model_path, run_name + '.json')\n",
    "\n",
    "conf = utils.read_json(json_path)\n",
    "conf['coco_dir_path'] = coco_dir_path\n",
    "train_info_path = os.path.join(conf['coco_dir_path'], conf['train_info_name'])\n",
    "valid_info_path = os.path.join(conf['coco_dir_path'], conf['valid_info_name'])\n",
    "\n",
    "coco_train = COCO(train_info_path)\n",
    "coco_valid = COCO(valid_info_path)\n",
    "\n",
    "id2label = utils.get_id2label(conf['classes'])\n",
    "label2id = utils.get_label2id(id2label)\n",
    "\n",
    "train = dataset.COCO2dataset(conf['data_dir_path'], coco_train)\n",
    "valid = dataset.COCO2dataset(conf['data_dir_path'], coco_valid)\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint_path)\n",
    "model = AutoModelForObjectDetection.from_pretrained(checkpoint_path)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_eval(conf, model, image_processor, coco_data, data, result_path):\n",
    "    batch_size = 8\n",
    "\n",
    "    image_names = []\n",
    "    prediction_strings = []\n",
    "    batch_indices = get_batch_indices(batch_size, len(data))\n",
    "\n",
    "    for batch_index in tqdm(batch_indices):\n",
    "        batch = data[batch_index]\n",
    "        image_name, prediction_string = get_predictions(batch, coco_data, model, image_processor)\n",
    "        \n",
    "        image_names.extend(image_name)\n",
    "        prediction_strings.extend(prediction_string)\n",
    "\n",
    "    submission = pd.DataFrame()\n",
    "    submission['PredictionString'] = prediction_strings\n",
    "    submission['image_id'] = image_names\n",
    "    submission.to_csv(result_path, index=None)\n",
    "\n",
    "\n",
    "def get_batch_indices(batch_size, n):\n",
    "    i = 0\n",
    "    batch_index = []\n",
    "    batch_indices = []\n",
    "\n",
    "    while True:\n",
    "        if (i == n): \n",
    "            batch_indices.append(batch_index)\n",
    "            break\n",
    "\n",
    "        batch_index.append(i)\n",
    "\n",
    "        if (len(batch_index) % batch_size == 0):\n",
    "            batch_indices.append(batch_index)\n",
    "            batch_index = []\n",
    "            \n",
    "        i += 1  \n",
    "\n",
    "    return batch_indices\n",
    "        \n",
    "\n",
    "def get_predictions(batch, coco_data, model, image_processor):\n",
    "    threshold = 0.05\n",
    "    device = \"cuda\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        images = [np.array(image) for image in batch['image']]\n",
    "        images = [np.fliplr(image) for image in images] # horizontal flip\n",
    "        image_ids = batch['image_id']\n",
    "        image_infos = coco_data.loadImgs(image_ids)\n",
    "\n",
    "        inputs = image_processor(images=images, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs.to(device))\n",
    "        target_sizes = [image.shape for image in images]\n",
    "        results = image_processor.post_process_object_detection(outputs, threshold=threshold, target_sizes=target_sizes)\n",
    "        \n",
    "        # horizontal flip\n",
    "        for taget_size, result in zip(target_sizes, results):\n",
    "            x1 = result['boxes'][:, 0]\n",
    "            x2 = result['boxes'][:, 2]\n",
    "            w, h, _ = taget_size\n",
    "            x1, x2 = w - x2, w - x1\n",
    "            result['boxes'][:, 0] = x1\n",
    "            result['boxes'][:, 2] = x2\n",
    "\n",
    "\n",
    "        image_names = [image_info['file_name'] for image_info in image_infos]\n",
    "        prediction_strings = []\n",
    "\n",
    "        for result in results:\n",
    "            _, indices = torch.sort(result['scores'], descending=True)\n",
    "            result[\"scores\"] = result[\"scores\"][indices].detach().cpu().numpy() \n",
    "            result[\"labels\"] = result[\"labels\"][indices].detach().cpu().numpy() \n",
    "            result[\"boxes\"] = result[\"boxes\"][indices].detach().cpu().numpy() \n",
    "\n",
    "            prediction_string = ''\n",
    "\n",
    "            for box, score, label in zip(result[\"boxes\"], result[\"scores\"], result[\"labels\"]):\n",
    "                prediction_string += str(label) + ' ' + str(score) + ' ' + str(box[0]) + ' ' + str(\n",
    "                        box[1]) + ' ' + str(box[2]) + ' ' + str(box[3]) + ' '\n",
    "\n",
    "            prediction_strings.append(prediction_string)\n",
    "        \n",
    "        return image_names, prediction_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scores': tensor([0.7441, 0.7353, 0.7322, 0.7318, 0.7002, 0.6796, 0.6282, 0.6057, 0.3084,\n",
      "        0.2251, 0.1991, 0.1882, 0.1861, 0.1757, 0.1583, 0.1578, 0.1543, 0.1511,\n",
      "        0.1491, 0.1488, 0.1477, 0.1471, 0.1466, 0.1459, 0.1454, 0.1419, 0.1417,\n",
      "        0.1336, 0.1331, 0.1330, 0.1297, 0.1250, 0.1243, 0.1173, 0.1147, 0.1130,\n",
      "        0.1125, 0.1119, 0.1113, 0.1062, 0.1059, 0.1056, 0.1035, 0.1030, 0.1024,\n",
      "        0.1023, 0.1021, 0.0990, 0.0990, 0.0982, 0.0979, 0.0971, 0.0954, 0.0947,\n",
      "        0.0931, 0.0923, 0.0920, 0.0883, 0.0880, 0.0879, 0.0875, 0.0873, 0.0854,\n",
      "        0.0850, 0.0845, 0.0845, 0.0843, 0.0839, 0.0834, 0.0829, 0.0824, 0.0818,\n",
      "        0.0815, 0.0799, 0.0786, 0.0784, 0.0780, 0.0760, 0.0749, 0.0746, 0.0733,\n",
      "        0.0730, 0.0722, 0.0721, 0.0716, 0.0708, 0.0681, 0.0664, 0.0663, 0.0656,\n",
      "        0.0652, 0.0648, 0.0642, 0.0640, 0.0639, 0.0638, 0.0638, 0.0638, 0.0635,\n",
      "        0.0630], device='cuda:0'), 'labels': tensor([1, 3, 0, 0, 5, 5, 3, 2, 5, 3, 5, 4, 3, 1, 5, 3, 5, 4, 2, 3, 5, 3, 5, 6,\n",
      "        0, 0, 5, 0, 0, 2, 5, 5, 0, 5, 5, 5, 1, 7, 0, 6, 2, 0, 5, 5, 7, 1, 2, 7,\n",
      "        0, 9, 0, 3, 7, 0, 8, 3, 2, 1, 4, 7, 0, 4, 9, 0, 3, 6, 1, 5, 7, 8, 2, 6,\n",
      "        1, 0, 9, 1, 2, 5, 7, 0, 2, 3, 2, 7, 6, 0, 5, 1, 3, 2, 0, 2, 9, 3, 5, 9,\n",
      "        0, 7, 3, 7], device='cuda:0'), 'boxes': tensor([[ 778.6502,  315.2985, 1011.5012,  612.9981],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 465.5514,  207.7502,  723.9962,  540.9921],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [   1.3822,  218.7113,   94.8717,  311.1155],\n",
      "        [ 359.4089,  391.4749,  517.6821,  668.7358],\n",
      "        [ 656.1011,  442.0494,  776.0936,  517.7913],\n",
      "        [ 217.2696,  346.2196,  433.6705,  621.5932],\n",
      "        [ 655.4739,  442.4456,  775.6816,  517.6057],\n",
      "        [ 409.8338,  711.8602,  483.1415,  834.0850],\n",
      "        [ 217.8059,  346.0786,  433.8354,  621.5297],\n",
      "        [ 655.4739,  442.4456,  775.6816,  517.6057],\n",
      "        [   1.2916,  218.8226,   94.9297,  311.7359],\n",
      "        [ 217.8059,  346.0786,  433.8354,  621.5297],\n",
      "        [ 325.8198,  391.5695,  431.8688,  622.0830],\n",
      "        [ 360.8919,  651.4943,  483.6541,  833.8088],\n",
      "        [ 362.3544,  391.0851,  491.2032,  611.7552],\n",
      "        [   1.3822,  218.7113,   94.8717,  311.1155],\n",
      "        [ 325.8198,  391.5695,  431.8688,  622.0830],\n",
      "        [ 355.1738,  391.3824,  517.5295,  669.0980],\n",
      "        [ 359.5523,  393.0928,  517.5010,  831.4114],\n",
      "        [ 217.8059,  346.0786,  433.8354,  621.5297],\n",
      "        [ 366.9768,  390.5417,  497.6404,  549.2115],\n",
      "        [ 217.8059,  346.0786,  433.8354,  621.5297],\n",
      "        [  85.1897,  140.8028,  706.7692,  564.2272],\n",
      "        [ 126.9095,  250.5313,  464.7582,  604.7968],\n",
      "        [ 209.4334,  347.0942,  503.3325,  647.2461],\n",
      "        [ 655.4739,  442.4456,  775.6816,  517.6057],\n",
      "        [ 217.2696,  346.2196,  433.6705,  621.5932],\n",
      "        [ 355.1738,  391.3824,  517.5295,  669.0980],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [ 325.8198,  391.5695,  431.8688,  622.0830],\n",
      "        [ 329.0384,  412.7116,  470.2057,  667.8933],\n",
      "        [ 365.8902,  406.2079,  464.6684,  660.9292],\n",
      "        [ 324.5330,  352.3061,  502.7090,  621.7075],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [  85.5373,  137.6720,  465.1129,  564.9393],\n",
      "        [ 355.1738,  391.3824,  517.5295,  669.0980],\n",
      "        [ 355.1738,  391.3824,  517.5295,  669.0980],\n",
      "        [ 195.0364,  344.7653,  492.3886,  635.9763],\n",
      "        [ 148.1873,  245.1732,  187.4681,  337.4754],\n",
      "        [ 465.5514,  207.7502,  723.9962,  540.9921],\n",
      "        [ 352.0477,  394.5016,  432.7845,  662.3511],\n",
      "        [ 355.1738,  391.3824,  517.5295,  669.0980],\n",
      "        [ 465.5514,  207.7502,  723.9962,  540.9921],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 217.8059,  346.0786,  433.8354,  621.5297],\n",
      "        [   1.3822,  218.7113,   94.8717,  311.1155],\n",
      "        [ 466.7307,  207.8635,  723.1024,  540.6624],\n",
      "        [ 324.9500,  425.6913,  397.2512,  620.0085],\n",
      "        [ 465.5514,  207.7502,  723.9962,  540.9921],\n",
      "        [ 466.5471,  208.1253,  722.9681,  540.8897],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 656.1011,  442.0494,  776.0936,  517.7913],\n",
      "        [ 395.8285,  654.6523,  504.2373,  836.6983],\n",
      "        [ 326.0700,  397.5153,  400.3293,  621.8553],\n",
      "        [ 355.1738,  391.3824,  517.5295,  669.0980],\n",
      "        [ 359.4089,  391.4749,  517.6821,  668.7358],\n",
      "        [ 325.8198,  391.5695,  431.8688,  622.0830],\n",
      "        [ 119.4912,  345.9283,  437.0136,  596.7042],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [ 778.6502,  315.2985, 1011.5012,  612.9981],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [ 465.5514,  207.7502,  723.9962,  540.9921],\n",
      "        [ 325.8198,  391.5695,  431.8688,  622.0830],\n",
      "        [ 324.9500,  425.6913,  397.2512,  620.0085],\n",
      "        [ 778.6502,  315.2985, 1011.5012,  612.9981],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 258.0635,  393.7287,  432.0467,  648.3378],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [ 209.4334,  347.0942,  503.3325,  647.2461],\n",
      "        [  83.9964,  139.6692,  347.8687,  563.6283],\n",
      "        [ 217.2696,  346.2196,  433.6705,  621.5932],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 778.6502,  315.2985, 1011.5012,  612.9981],\n",
      "        [  27.4036,  220.4476,   98.6010,  316.1158],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 100.1107,  230.2809,  441.2153,  462.2042],\n",
      "        [ 465.5514,  207.7502,  723.9962,  540.9921],\n",
      "        [ 325.8198,  391.5695,  431.8688,  622.0830],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [   1.2916,  218.8226,   94.9297,  311.7359],\n",
      "        [   1.2916,  218.8226,   94.9297,  311.7359],\n",
      "        [  84.9937,  139.0483,  254.3431,  561.2309],\n",
      "        [  22.1257,  219.0667,   93.3076,  296.6317],\n",
      "        [ 326.0700,  397.5153,  400.3293,  621.8553],\n",
      "        [ 404.7162,  660.4641,  432.5581,  727.9486],\n",
      "        [   1.2916,  218.8226,   94.9297,  311.7359],\n",
      "        [ 195.0364,  344.7653,  492.3886,  635.9763],\n",
      "        [ 119.4912,  345.9283,  437.0136,  596.7042],\n",
      "        [ 656.1011,  442.0494,  776.0936,  517.7913],\n",
      "        [ 777.3280,  315.5199, 1011.3490,  613.0735],\n",
      "        [ 381.4859,  459.4701,  543.1158,  676.3350],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 507.4013,  208.1630,  722.0801,  459.1306],\n",
      "        [ 324.9500,  425.6913,  397.2512,  620.0085],\n",
      "        [ 359.5523,  393.0928,  517.5010,  831.4114],\n",
      "        [ 359.3502,  394.6809,  469.8839,  642.5767]], device='cuda:0')}\n",
      "{'scores': tensor([0.7482, 0.7419, 0.0907, 0.0885, 0.0880, 0.0817, 0.0775, 0.0685, 0.0673,\n",
      "        0.0644, 0.0617, 0.0614, 0.0571, 0.0548], device='cuda:0'), 'labels': tensor([1, 0, 1, 0, 9, 3, 2, 3, 5, 7, 6, 6, 7, 2], device='cuda:0'), 'boxes': tensor([[308.5378,  35.0457, 775.7632, 340.6089],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [308.5378,  35.0457, 775.7632, 340.6089],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [308.5378,  35.0457, 775.7632, 340.6089],\n",
      "        [308.5378,  35.0457, 775.7632, 340.6089],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [308.5378,  35.0457, 775.7632, 340.6089],\n",
      "        [308.5378,  35.0457, 775.7632, 340.6089],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632]], device='cuda:0')}\n",
      "{'scores': tensor([0.4504, 0.2518, 0.1806, 0.1281, 0.1278, 0.0655, 0.0620],\n",
      "       device='cuda:0'), 'labels': tensor([3, 0, 5, 7, 9, 1, 2], device='cuda:0'), 'boxes': tensor([[200.8370, 124.6671, 722.3461, 773.7098],\n",
      "        [201.9363, 124.1790, 722.2684, 773.3661],\n",
      "        [199.9280, 124.0154, 721.7917, 773.2966],\n",
      "        [199.9280, 124.0154, 721.7917, 773.2966],\n",
      "        [201.9363, 124.1790, 722.2684, 773.3661],\n",
      "        [201.9363, 124.1790, 722.2684, 773.3661],\n",
      "        [201.9363, 124.1790, 722.2684, 773.3661]], device='cuda:0')}\n",
      "{'scores': tensor([0.7883, 0.1098, 0.1006, 0.0991, 0.0877, 0.0842, 0.0769, 0.0676, 0.0576,\n",
      "        0.0550], device='cuda:0'), 'labels': tensor([3, 8, 2, 0, 5, 1, 9, 7, 4, 3], device='cuda:0'), 'boxes': tensor([[265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [297.0123, 371.6659, 809.3974, 720.4988]], device='cuda:0')}\n",
      "{'scores': tensor([0.7594, 0.0984, 0.0872, 0.0822, 0.0748, 0.0711, 0.0702, 0.0613, 0.0579],\n",
      "       device='cuda:0'), 'labels': tensor([5, 0, 6, 2, 7, 3, 4, 1, 0], device='cuda:0'), 'boxes': tensor([[373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [215.5792, 480.9597, 266.5557, 553.6134]], device='cuda:0')}\n",
      "{'scores': tensor([0.7883, 0.1614, 0.0983, 0.0803, 0.0790, 0.0788, 0.0776, 0.0741, 0.0708,\n",
      "        0.0609, 0.0600], device='cuda:0'), 'labels': tensor([3, 5, 0, 7, 1, 8, 2, 3, 9, 4, 0], device='cuda:0'), 'boxes': tensor([[225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [224.8651, 335.4649, 761.3983, 789.5120],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [417.8435, 325.7064, 762.0325, 785.4609],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [ 10.5070, 475.7509,  80.8015, 580.8353]], device='cuda:0')}\n",
      "{'scores': tensor([0.7731, 0.7613, 0.7566, 0.7438, 0.6723, 0.6664, 0.6532, 0.6361, 0.5981,\n",
      "        0.5895, 0.5725, 0.5652, 0.5065, 0.3839, 0.3630, 0.3498, 0.3464, 0.3409,\n",
      "        0.3386, 0.3258, 0.3119, 0.3080, 0.3011, 0.2990, 0.2935, 0.2924, 0.2878,\n",
      "        0.2827, 0.2819, 0.2770, 0.2729, 0.2714, 0.2713, 0.2673, 0.2667, 0.2660,\n",
      "        0.2578, 0.2538, 0.2537, 0.2488, 0.2327, 0.2223, 0.2217, 0.2209, 0.2204,\n",
      "        0.2201, 0.2163, 0.2153, 0.2105, 0.2085, 0.2079, 0.2064, 0.2060, 0.2049,\n",
      "        0.2020, 0.2005, 0.1999, 0.1996, 0.1992, 0.1977, 0.1977, 0.1961, 0.1958,\n",
      "        0.1942, 0.1934, 0.1905, 0.1865, 0.1840, 0.1791, 0.1772, 0.1770, 0.1723,\n",
      "        0.1696, 0.1682, 0.1638, 0.1592, 0.1582, 0.1572, 0.1549, 0.1549, 0.1544,\n",
      "        0.1538, 0.1523, 0.1521, 0.1510, 0.1504, 0.1495, 0.1482, 0.1479, 0.1461,\n",
      "        0.1461, 0.1457, 0.1443, 0.1416, 0.1401, 0.1397, 0.1395, 0.1383, 0.1370,\n",
      "        0.1370], device='cuda:0'), 'labels': tensor([7, 1, 7, 7, 1, 1, 1, 1, 5, 1, 1, 4, 6, 1, 1, 1, 1, 2, 1, 1, 3, 1, 0, 1,\n",
      "        5, 1, 1, 1, 1, 0, 5, 0, 1, 3, 1, 1, 0, 1, 1, 1, 1, 4, 1, 0, 2, 1, 1, 1,\n",
      "        1, 1, 5, 1, 5, 0, 1, 1, 9, 0, 1, 9, 1, 0, 1, 0, 1, 6, 1, 7, 2, 7, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 6, 1, 6, 1, 7, 1, 2, 0, 2, 0, 1, 6, 0, 2, 0, 5,\n",
      "        1, 1, 0, 7], device='cuda:0'), 'boxes': tensor([[ 226.3018,  162.7742,  717.1052,  502.2882],\n",
      "        [ 429.1338,  535.6178,  964.2008,  924.3009],\n",
      "        [ 569.0553,  335.5429,  930.7526,  609.7160],\n",
      "        [ 336.6885,  697.8237,  531.6828,  933.5876],\n",
      "        [ 140.4936,  425.0450,  427.6938,  548.5714],\n",
      "        [ 546.6537,  686.2161,  854.4598,  842.9509],\n",
      "        [ 333.7734,  504.5112,  481.4003,  574.9340],\n",
      "        [ 125.9838,  429.2997,  617.7039,  739.9421],\n",
      "        [ 611.0068,  602.7675,  675.3857,  643.2050],\n",
      "        [ 265.8467,  426.6813,  524.2316,  537.2575],\n",
      "        [ 354.7243,  378.5492,  459.6606,  483.7935],\n",
      "        [ 625.7095,  696.8499,  857.3857,  754.6140],\n",
      "        [ 798.3951,  403.4160, 1024.6028,  927.6812],\n",
      "        [ 797.5085,  402.9925, 1024.1213,  927.8068],\n",
      "        [ 331.0331,  540.2670,  419.7289,  578.4784],\n",
      "        [ 129.6185,  414.4320,  550.8447,  663.4594],\n",
      "        [ 255.9461,  548.2955,  362.4917,  577.2986],\n",
      "        [ 544.7516,  657.7150,  631.1815,  714.1170],\n",
      "        [ 507.2545,  638.9487,  785.1500,  714.0779],\n",
      "        [ 198.4292,  435.9532,  384.4160,  548.7195],\n",
      "        [ 282.8943,  336.2091,  387.8306,  461.8073],\n",
      "        [ 127.6829,  484.7948,  421.7230,  655.8839],\n",
      "        [ 236.3060,  652.8295,  282.6295,  690.9948],\n",
      "        [ 241.4388,  536.6970,  419.8481,  582.2012],\n",
      "        [ 282.8943,  336.2091,  387.8306,  461.8073],\n",
      "        [ 326.2243,  380.5213,  472.3506,  485.6541],\n",
      "        [ 264.0580,  427.0073,  484.3386,  516.3437],\n",
      "        [ 397.3994,  496.9916,  618.9120,  710.0753],\n",
      "        [ 324.2621,  449.6317,  524.3403,  536.9089],\n",
      "        [ 797.9028,  402.4478, 1024.3264,  928.0424],\n",
      "        [ 625.5157,  696.5332,  856.9667,  754.3920],\n",
      "        [ 131.6188,  454.0277,  209.1707,  536.0825],\n",
      "        [ 544.7516,  657.7150,  631.1815,  714.1170],\n",
      "        [ 610.9133,  603.1265,  675.3925,  642.8486],\n",
      "        [ 417.3209,  460.1272,  483.0117,  487.7576],\n",
      "        [ 236.0713,  535.1514,  368.2471,  578.7349],\n",
      "        [ 282.8943,  336.2091,  387.8306,  461.8073],\n",
      "        [ 358.8295,  558.6439,  419.2056,  579.2258],\n",
      "        [ 131.2614,  453.0169,  266.1986,  541.3118],\n",
      "        [ 131.1056,  426.7012,  290.5073,  540.5502],\n",
      "        [ 149.8376,  551.7082,  411.7271,  740.1816],\n",
      "        [ 610.9133,  603.1265,  675.3925,  642.8486],\n",
      "        [ 234.3631,  534.6621,  310.2383,  551.8767],\n",
      "        [ 417.3917,  460.1651,  482.7521,  485.8677],\n",
      "        [ 506.9477,  639.8910,  784.2571,  712.1360],\n",
      "        [ 265.0721,  425.8355,  423.1305,  510.4720],\n",
      "        [ 358.9500,  560.4193,  420.8447,  593.3126],\n",
      "        [ 191.0181,  533.6572,  418.8933,  655.0434],\n",
      "        [ 331.4030,  539.4528,  411.7029,  566.9672],\n",
      "        [ 280.3109,  336.4576,  463.2646,  480.6075],\n",
      "        [ 506.9477,  639.8910,  784.2571,  712.1360],\n",
      "        [ 414.1590,  459.1652,  524.3144,  530.9498],\n",
      "        [ 544.7516,  657.7150,  631.1815,  714.1170],\n",
      "        [ 358.8295,  558.6439,  419.2056,  579.2258],\n",
      "        [ 371.1148,  572.9380,  421.6876,  597.0200],\n",
      "        [ 239.3918,  543.2085,  391.8079,  654.2570],\n",
      "        [ 798.3951,  403.4160, 1024.6028,  927.6812],\n",
      "        [ 332.5666,  541.3230,  419.0588,  577.2247],\n",
      "        [ 268.1967,  435.7183,  424.6125,  545.7456],\n",
      "        [ 282.8943,  336.2091,  387.8306,  461.8073],\n",
      "        [ 197.9677,  439.6075,  413.6153,  516.5978],\n",
      "        [ 506.9477,  639.8910,  784.2571,  712.1360],\n",
      "        [ 236.3060,  652.8295,  282.6295,  690.9948],\n",
      "        [ 544.7516,  657.7150,  631.1815,  714.1170],\n",
      "        [ 436.9561,  411.0247,  464.0698,  465.9400],\n",
      "        [ 282.8943,  336.2091,  387.8306,  461.8073],\n",
      "        [ 407.2957,  401.2860,  449.5411,  468.8020],\n",
      "        [ 798.3951,  403.4160, 1024.6028,  927.6812],\n",
      "        [ 513.8856,  646.8477,  632.1157,  713.4475],\n",
      "        [ 506.7814,  639.5263,  783.3229,  713.2429],\n",
      "        [ 200.5494,  506.0603,  467.3352,  654.7463],\n",
      "        [ 426.4690,  401.2781,  464.4621,  466.6406],\n",
      "        [ 278.1664,  367.9803,  531.9589,  531.2588],\n",
      "        [ 322.4777,  439.4332,  489.6257,  513.4194],\n",
      "        [ 233.4245,  534.7205,  294.8539,  549.6591],\n",
      "        [ 283.1301,  554.8260,  363.3337,  579.6655],\n",
      "        [ 322.8156,  391.0318,  543.2256,  533.2257],\n",
      "        [ 354.9955,  646.8802,  377.5598,  666.6711],\n",
      "        [ 320.6923,  454.4252,  421.3444,  507.2752],\n",
      "        [ 131.2614,  453.0169,  266.1986,  541.3118],\n",
      "        [ 507.2545,  638.9487,  785.1500,  714.0779],\n",
      "        [ 236.5269,  533.8517,  335.9250,  552.2382],\n",
      "        [ 544.7516,  657.7150,  631.1815,  714.1170],\n",
      "        [ 264.1723,  376.5440,  468.3997,  508.6102],\n",
      "        [ 417.3917,  460.1651,  482.7521,  485.8677],\n",
      "        [ 269.9695,  552.6536,  420.0078,  654.2171],\n",
      "        [ 544.1862,  655.7931,  620.1182,  691.5502],\n",
      "        [ 254.7578,  549.3882,  362.1638,  577.1096],\n",
      "        [ 283.1240,  336.5036,  388.4673,  462.4387],\n",
      "        [ 358.9500,  560.4193,  420.8447,  593.3126],\n",
      "        [ 513.8856,  646.8477,  632.1157,  713.4475],\n",
      "        [ 429.1338,  535.6178,  964.2008,  924.3009],\n",
      "        [ 371.1148,  572.9380,  421.6876,  597.0200],\n",
      "        [ 546.8308,  686.3000,  853.1764,  842.8620],\n",
      "        [ 234.4031,  534.7255,  308.0677,  552.8723],\n",
      "        [ 236.3060,  652.8295,  282.6295,  690.9948],\n",
      "        [ 282.3590,  337.0878,  389.8030,  463.3150],\n",
      "        [ 411.9703,  408.2258,  456.8542,  484.8467],\n",
      "        [ 513.8856,  646.8477,  632.1157,  713.4475],\n",
      "        [ 236.3060,  652.8295,  282.6295,  690.9948]], device='cuda:0')}\n",
      "{'scores': tensor([0.7640, 0.7562, 0.1354, 0.1333, 0.1083, 0.0953, 0.0943, 0.0942, 0.0937,\n",
      "        0.0930, 0.0913, 0.0900, 0.0896, 0.0892, 0.0842, 0.0712, 0.0695, 0.0682,\n",
      "        0.0624, 0.0613, 0.0505], device='cuda:0'), 'labels': tensor([2, 2, 1, 1, 0, 5, 3, 9, 3, 0, 6, 5, 6, 9, 0, 7, 7, 2, 0, 7, 7],\n",
      "       device='cuda:0'), 'boxes': tensor([[441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [242.8221, 215.5858, 712.4982, 557.5735],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [420.0523, 511.9371, 489.4457, 567.6945],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [443.0174, 562.3284, 708.2859, 716.0160],\n",
      "        [708.0496, 464.2636, 799.5957, 601.3222],\n",
      "        [420.0523, 511.9371, 489.4457, 567.6945],\n",
      "        [249.6829, 199.3697, 333.8858, 246.5086]], device='cuda:0')}\n",
      "tensor([[ 778.6502,  315.2985, 1011.5012,  612.9981],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 465.5514,  207.7502,  723.9962,  540.9921],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [   1.3822,  218.7113,   94.8717,  311.1155],\n",
      "        [ 359.4089,  391.4749,  517.6821,  668.7358],\n",
      "        [ 656.1011,  442.0494,  776.0936,  517.7913],\n",
      "        [ 217.2696,  346.2196,  433.6705,  621.5932],\n",
      "        [ 655.4739,  442.4456,  775.6816,  517.6057],\n",
      "        [ 409.8338,  711.8602,  483.1415,  834.0850],\n",
      "        [ 217.8059,  346.0786,  433.8354,  621.5297],\n",
      "        [ 655.4739,  442.4456,  775.6816,  517.6057],\n",
      "        [   1.2916,  218.8226,   94.9297,  311.7359],\n",
      "        [ 217.8059,  346.0786,  433.8354,  621.5297],\n",
      "        [ 325.8198,  391.5695,  431.8688,  622.0830],\n",
      "        [ 360.8919,  651.4943,  483.6541,  833.8088],\n",
      "        [ 362.3544,  391.0851,  491.2032,  611.7552],\n",
      "        [   1.3822,  218.7113,   94.8717,  311.1155],\n",
      "        [ 325.8198,  391.5695,  431.8688,  622.0830],\n",
      "        [ 355.1738,  391.3824,  517.5295,  669.0980],\n",
      "        [ 359.5523,  393.0928,  517.5010,  831.4114],\n",
      "        [ 217.8059,  346.0786,  433.8354,  621.5297],\n",
      "        [ 366.9768,  390.5417,  497.6404,  549.2115],\n",
      "        [ 217.8059,  346.0786,  433.8354,  621.5297],\n",
      "        [  85.1897,  140.8028,  706.7692,  564.2272],\n",
      "        [ 126.9095,  250.5313,  464.7582,  604.7968],\n",
      "        [ 209.4334,  347.0942,  503.3325,  647.2461],\n",
      "        [ 655.4739,  442.4456,  775.6816,  517.6057],\n",
      "        [ 217.2696,  346.2196,  433.6705,  621.5932],\n",
      "        [ 355.1738,  391.3824,  517.5295,  669.0980],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [ 325.8198,  391.5695,  431.8688,  622.0830],\n",
      "        [ 329.0384,  412.7116,  470.2057,  667.8933],\n",
      "        [ 365.8902,  406.2079,  464.6684,  660.9292],\n",
      "        [ 324.5330,  352.3061,  502.7090,  621.7075],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [  85.5373,  137.6720,  465.1129,  564.9393],\n",
      "        [ 355.1738,  391.3824,  517.5295,  669.0980],\n",
      "        [ 355.1738,  391.3824,  517.5295,  669.0980],\n",
      "        [ 195.0364,  344.7653,  492.3886,  635.9763],\n",
      "        [ 148.1873,  245.1732,  187.4681,  337.4754],\n",
      "        [ 465.5514,  207.7502,  723.9962,  540.9921],\n",
      "        [ 352.0477,  394.5016,  432.7845,  662.3511],\n",
      "        [ 355.1738,  391.3824,  517.5295,  669.0980],\n",
      "        [ 465.5514,  207.7502,  723.9962,  540.9921],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 217.8059,  346.0786,  433.8354,  621.5297],\n",
      "        [   1.3822,  218.7113,   94.8717,  311.1155],\n",
      "        [ 466.7307,  207.8635,  723.1024,  540.6624],\n",
      "        [ 324.9500,  425.6913,  397.2512,  620.0085],\n",
      "        [ 465.5514,  207.7502,  723.9962,  540.9921],\n",
      "        [ 466.5471,  208.1253,  722.9681,  540.8897],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 656.1011,  442.0494,  776.0936,  517.7913],\n",
      "        [ 395.8285,  654.6523,  504.2373,  836.6983],\n",
      "        [ 326.0700,  397.5153,  400.3293,  621.8553],\n",
      "        [ 355.1738,  391.3824,  517.5295,  669.0980],\n",
      "        [ 359.4089,  391.4749,  517.6821,  668.7358],\n",
      "        [ 325.8198,  391.5695,  431.8688,  622.0830],\n",
      "        [ 119.4912,  345.9283,  437.0136,  596.7042],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [ 778.6502,  315.2985, 1011.5012,  612.9981],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [ 465.5514,  207.7502,  723.9962,  540.9921],\n",
      "        [ 325.8198,  391.5695,  431.8688,  622.0830],\n",
      "        [ 324.9500,  425.6913,  397.2512,  620.0085],\n",
      "        [ 778.6502,  315.2985, 1011.5012,  612.9981],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 258.0635,  393.7287,  432.0467,  648.3378],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [ 209.4334,  347.0942,  503.3325,  647.2461],\n",
      "        [  83.9964,  139.6692,  347.8687,  563.6283],\n",
      "        [ 217.2696,  346.2196,  433.6705,  621.5932],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 778.6502,  315.2985, 1011.5012,  612.9981],\n",
      "        [  27.4036,  220.4476,   98.6010,  316.1158],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 100.1107,  230.2809,  441.2153,  462.2042],\n",
      "        [ 465.5514,  207.7502,  723.9962,  540.9921],\n",
      "        [ 325.8198,  391.5695,  431.8688,  622.0830],\n",
      "        [  85.4610,  136.8990,  465.3906,  564.0123],\n",
      "        [   1.2916,  218.8226,   94.9297,  311.7359],\n",
      "        [   1.2916,  218.8226,   94.9297,  311.7359],\n",
      "        [  84.9937,  139.0483,  254.3431,  561.2309],\n",
      "        [  22.1257,  219.0667,   93.3076,  296.6317],\n",
      "        [ 326.0700,  397.5153,  400.3293,  621.8553],\n",
      "        [ 404.7162,  660.4641,  432.5581,  727.9486],\n",
      "        [   1.2916,  218.8226,   94.9297,  311.7359],\n",
      "        [ 195.0364,  344.7653,  492.3886,  635.9763],\n",
      "        [ 119.4912,  345.9283,  437.0136,  596.7042],\n",
      "        [ 656.1011,  442.0494,  776.0936,  517.7913],\n",
      "        [ 777.3280,  315.5199, 1011.3490,  613.0735],\n",
      "        [ 381.4859,  459.4701,  543.1158,  676.3350],\n",
      "        [ 406.3288,  661.2714,  483.2081,  833.6426],\n",
      "        [ 507.4013,  208.1630,  722.0801,  459.1306],\n",
      "        [ 324.9500,  425.6913,  397.2512,  620.0085],\n",
      "        [ 359.5523,  393.0928,  517.5010,  831.4114],\n",
      "        [ 359.3502,  394.6809,  469.8839,  642.5767]], device='cuda:0')\n",
      "tensor([[308.5378,  35.0457, 775.7632, 340.6089],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [308.5378,  35.0457, 775.7632, 340.6089],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [308.5378,  35.0457, 775.7632, 340.6089],\n",
      "        [308.5378,  35.0457, 775.7632, 340.6089],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632],\n",
      "        [308.5378,  35.0457, 775.7632, 340.6089],\n",
      "        [308.5378,  35.0457, 775.7632, 340.6089],\n",
      "        [ 46.9931, 441.2816, 714.7412, 907.9632]], device='cuda:0')\n",
      "tensor([[200.8370, 124.6671, 722.3461, 773.7098],\n",
      "        [201.9363, 124.1790, 722.2684, 773.3661],\n",
      "        [199.9280, 124.0154, 721.7917, 773.2966],\n",
      "        [199.9280, 124.0154, 721.7917, 773.2966],\n",
      "        [201.9363, 124.1790, 722.2684, 773.3661],\n",
      "        [201.9363, 124.1790, 722.2684, 773.3661],\n",
      "        [201.9363, 124.1790, 722.2684, 773.3661]], device='cuda:0')\n",
      "tensor([[265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [265.9642, 427.7209, 742.2261, 720.7914],\n",
      "        [297.0123, 371.6659, 809.3974, 720.4988]], device='cuda:0')\n",
      "tensor([[373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [373.3315, 487.9658, 666.7289, 765.7397],\n",
      "        [215.5792, 480.9597, 266.5557, 553.6134]], device='cuda:0')\n",
      "tensor([[225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [224.8651, 335.4649, 761.3983, 789.5120],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [417.8435, 325.7064, 762.0325, 785.4609],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [225.1425, 335.4840, 760.8925, 789.4736],\n",
      "        [ 10.5070, 475.7509,  80.8015, 580.8353]], device='cuda:0')\n",
      "tensor([[ 226.3018,  162.7742,  717.1052,  502.2882],\n",
      "        [ 429.1338,  535.6178,  964.2008,  924.3009],\n",
      "        [ 569.0553,  335.5429,  930.7526,  609.7160],\n",
      "        [ 336.6885,  697.8237,  531.6828,  933.5876],\n",
      "        [ 140.4936,  425.0450,  427.6938,  548.5714],\n",
      "        [ 546.6537,  686.2161,  854.4598,  842.9509],\n",
      "        [ 333.7734,  504.5112,  481.4003,  574.9340],\n",
      "        [ 125.9838,  429.2997,  617.7039,  739.9421],\n",
      "        [ 611.0068,  602.7675,  675.3857,  643.2050],\n",
      "        [ 265.8467,  426.6813,  524.2316,  537.2575],\n",
      "        [ 354.7243,  378.5492,  459.6606,  483.7935],\n",
      "        [ 625.7095,  696.8499,  857.3857,  754.6140],\n",
      "        [ 798.3951,  403.4160, 1024.6028,  927.6812],\n",
      "        [ 797.5085,  402.9925, 1024.1213,  927.8068],\n",
      "        [ 331.0331,  540.2670,  419.7289,  578.4784],\n",
      "        [ 129.6185,  414.4320,  550.8447,  663.4594],\n",
      "        [ 255.9461,  548.2955,  362.4917,  577.2986],\n",
      "        [ 544.7516,  657.7150,  631.1815,  714.1170],\n",
      "        [ 507.2545,  638.9487,  785.1500,  714.0779],\n",
      "        [ 198.4292,  435.9532,  384.4160,  548.7195],\n",
      "        [ 282.8943,  336.2091,  387.8306,  461.8073],\n",
      "        [ 127.6829,  484.7948,  421.7230,  655.8839],\n",
      "        [ 236.3060,  652.8295,  282.6295,  690.9948],\n",
      "        [ 241.4388,  536.6970,  419.8481,  582.2012],\n",
      "        [ 282.8943,  336.2091,  387.8306,  461.8073],\n",
      "        [ 326.2243,  380.5213,  472.3506,  485.6541],\n",
      "        [ 264.0580,  427.0073,  484.3386,  516.3437],\n",
      "        [ 397.3994,  496.9916,  618.9120,  710.0753],\n",
      "        [ 324.2621,  449.6317,  524.3403,  536.9089],\n",
      "        [ 797.9028,  402.4478, 1024.3264,  928.0424],\n",
      "        [ 625.5157,  696.5332,  856.9667,  754.3920],\n",
      "        [ 131.6188,  454.0277,  209.1707,  536.0825],\n",
      "        [ 544.7516,  657.7150,  631.1815,  714.1170],\n",
      "        [ 610.9133,  603.1265,  675.3925,  642.8486],\n",
      "        [ 417.3209,  460.1272,  483.0117,  487.7576],\n",
      "        [ 236.0713,  535.1514,  368.2471,  578.7349],\n",
      "        [ 282.8943,  336.2091,  387.8306,  461.8073],\n",
      "        [ 358.8295,  558.6439,  419.2056,  579.2258],\n",
      "        [ 131.2614,  453.0169,  266.1986,  541.3118],\n",
      "        [ 131.1056,  426.7012,  290.5073,  540.5502],\n",
      "        [ 149.8376,  551.7082,  411.7271,  740.1816],\n",
      "        [ 610.9133,  603.1265,  675.3925,  642.8486],\n",
      "        [ 234.3631,  534.6621,  310.2383,  551.8767],\n",
      "        [ 417.3917,  460.1651,  482.7521,  485.8677],\n",
      "        [ 506.9477,  639.8910,  784.2571,  712.1360],\n",
      "        [ 265.0721,  425.8355,  423.1305,  510.4720],\n",
      "        [ 358.9500,  560.4193,  420.8447,  593.3126],\n",
      "        [ 191.0181,  533.6572,  418.8933,  655.0434],\n",
      "        [ 331.4030,  539.4528,  411.7029,  566.9672],\n",
      "        [ 280.3109,  336.4576,  463.2646,  480.6075],\n",
      "        [ 506.9477,  639.8910,  784.2571,  712.1360],\n",
      "        [ 414.1590,  459.1652,  524.3144,  530.9498],\n",
      "        [ 544.7516,  657.7150,  631.1815,  714.1170],\n",
      "        [ 358.8295,  558.6439,  419.2056,  579.2258],\n",
      "        [ 371.1148,  572.9380,  421.6876,  597.0200],\n",
      "        [ 239.3918,  543.2085,  391.8079,  654.2570],\n",
      "        [ 798.3951,  403.4160, 1024.6028,  927.6812],\n",
      "        [ 332.5666,  541.3230,  419.0588,  577.2247],\n",
      "        [ 268.1967,  435.7183,  424.6125,  545.7456],\n",
      "        [ 282.8943,  336.2091,  387.8306,  461.8073],\n",
      "        [ 197.9677,  439.6075,  413.6153,  516.5978],\n",
      "        [ 506.9477,  639.8910,  784.2571,  712.1360],\n",
      "        [ 236.3060,  652.8295,  282.6295,  690.9948],\n",
      "        [ 544.7516,  657.7150,  631.1815,  714.1170],\n",
      "        [ 436.9561,  411.0247,  464.0698,  465.9400],\n",
      "        [ 282.8943,  336.2091,  387.8306,  461.8073],\n",
      "        [ 407.2957,  401.2860,  449.5411,  468.8020],\n",
      "        [ 798.3951,  403.4160, 1024.6028,  927.6812],\n",
      "        [ 513.8856,  646.8477,  632.1157,  713.4475],\n",
      "        [ 506.7814,  639.5263,  783.3229,  713.2429],\n",
      "        [ 200.5494,  506.0603,  467.3352,  654.7463],\n",
      "        [ 426.4690,  401.2781,  464.4621,  466.6406],\n",
      "        [ 278.1664,  367.9803,  531.9589,  531.2588],\n",
      "        [ 322.4777,  439.4332,  489.6257,  513.4194],\n",
      "        [ 233.4245,  534.7205,  294.8539,  549.6591],\n",
      "        [ 283.1301,  554.8260,  363.3337,  579.6655],\n",
      "        [ 322.8156,  391.0318,  543.2256,  533.2257],\n",
      "        [ 354.9955,  646.8802,  377.5598,  666.6711],\n",
      "        [ 320.6923,  454.4252,  421.3444,  507.2752],\n",
      "        [ 131.2614,  453.0169,  266.1986,  541.3118],\n",
      "        [ 507.2545,  638.9487,  785.1500,  714.0779],\n",
      "        [ 236.5269,  533.8517,  335.9250,  552.2382],\n",
      "        [ 544.7516,  657.7150,  631.1815,  714.1170],\n",
      "        [ 264.1723,  376.5440,  468.3997,  508.6102],\n",
      "        [ 417.3917,  460.1651,  482.7521,  485.8677],\n",
      "        [ 269.9695,  552.6536,  420.0078,  654.2171],\n",
      "        [ 544.1862,  655.7931,  620.1182,  691.5502],\n",
      "        [ 254.7578,  549.3882,  362.1638,  577.1096],\n",
      "        [ 283.1240,  336.5036,  388.4673,  462.4387],\n",
      "        [ 358.9500,  560.4193,  420.8447,  593.3126],\n",
      "        [ 513.8856,  646.8477,  632.1157,  713.4475],\n",
      "        [ 429.1338,  535.6178,  964.2008,  924.3009],\n",
      "        [ 371.1148,  572.9380,  421.6876,  597.0200],\n",
      "        [ 546.8308,  686.3000,  853.1764,  842.8620],\n",
      "        [ 234.4031,  534.7255,  308.0677,  552.8723],\n",
      "        [ 236.3060,  652.8295,  282.6295,  690.9948],\n",
      "        [ 282.3590,  337.0878,  389.8030,  463.3150],\n",
      "        [ 411.9703,  408.2258,  456.8542,  484.8467],\n",
      "        [ 513.8856,  646.8477,  632.1157,  713.4475],\n",
      "        [ 236.3060,  652.8295,  282.6295,  690.9948]], device='cuda:0')\n",
      "tensor([[441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [242.8221, 215.5858, 712.4982, 557.5735],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [420.0523, 511.9371, 489.4457, 567.6945],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [242.8491, 216.5627, 712.7031, 557.9733],\n",
      "        [441.7453, 382.1303, 713.9452, 716.0679],\n",
      "        [443.0174, 562.3284, 708.2859, 716.0160],\n",
      "        [708.0496, 464.2636, 799.5957, 601.3222],\n",
      "        [420.0523, 511.9371, 489.4457, 567.6945],\n",
      "        [249.6829, 199.3697, 333.8858, 246.5086]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('result', exist_ok=True)\n",
    "test_eval(conf, model, image_processor, coco_valid, valid, 'result/' + run_name + '_valid.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mimages\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
