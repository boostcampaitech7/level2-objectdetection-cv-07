{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import fast version of function compute_overlap, will use slow one. Check cython intallation\n"
     ]
    }
   ],
   "source": [
    "from map_boxes import mean_average_precision_for_boxes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = 'valid'\n",
    "iou_threshold = 0.5\n",
    "\n",
    "GT_JSON = f'../../../Split_data/{select}_3_5.json'\n",
    "PRED_CSV = f'./result/deta-swin-large_3_img_size_720_{select}.csv'\n",
    "\n",
    "LABEL_NAME = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\",\n",
    "              \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "958it [00:00, 5165.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# load ground truth\n",
    "with open(GT_JSON, 'r') as outfile:\n",
    "    test_anno = (json.load(outfile))\n",
    "\n",
    "# load prediction\n",
    "pred_df = pd.read_csv(PRED_CSV)\n",
    "\n",
    "pred = []\n",
    "file_names = pred_df['image_id'].values.tolist()\n",
    "bboxes = pred_df['PredictionString'].values.tolist()\n",
    "\n",
    "for file_name, bbox in tqdm(zip(file_names, bboxes)):\n",
    "    boxes = np.array(str(bbox).strip().split(' '))\n",
    "\n",
    "    if len(boxes) % 6 == 0:\n",
    "        boxes = boxes.reshape(-1, 6)\n",
    "    elif isinstance(bbox, float):\n",
    "        print(f'{file_name} empty box')\n",
    "        continue\n",
    "    else:\n",
    "        raise Exception('error', 'invalid box type')\n",
    "    \n",
    "    for box in boxes:\n",
    "        pred.append([file_name, box[0], box[1], float(box[2]), float(box[4]), float(box[3]), float(box[5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Number of files in annotations: 958\n",
      "Number of files in predictions: 958\n",
      "Unique classes: 10\n",
      "Detections length: 958\n",
      "Annotations length: 958\n",
      "0                              | 0.423034 |     804\n",
      "1                              | 0.618705 |    1214\n",
      "2                              | 0.671341 |     180\n",
      "3                              | 0.648315 |     190\n",
      "4                              | 0.786109 |     229\n",
      "5                              | 0.583906 |     595\n",
      "6                              | 0.560847 |     328\n",
      "7                              | 0.765935 |     941\n",
      "8                              | 0.870503 |      51\n",
      "9                              | 0.744020 |      55\n",
      "mAP: 0.667272\n",
      "mAP@50: 0.6672715213606737\n"
     ]
    }
   ],
   "source": [
    "gt = []\n",
    "coco = COCO(GT_JSON)\n",
    "\n",
    "for image_id in coco.getImgIds():\n",
    "    image_info = coco.loadImgs(image_id)[0]\n",
    "    annotation_id = coco.getAnnIds(imgIds=image_info['id'])\n",
    "    annotation_info_list = coco.loadAnns(annotation_id)\n",
    "    file_name = image_info['file_name']\n",
    "\n",
    "    for annotation in annotation_info_list:\n",
    "        gt.append([file_name, annotation['category_id'],\n",
    "                float(annotation['bbox'][0]),\n",
    "                float(annotation['bbox'][0]) + float(annotation['bbox'][2]),\n",
    "                float(annotation['bbox'][1]),\n",
    "                float(annotation['bbox'][1]) + float(annotation['bbox'][3])])\n",
    "        \n",
    "mean_ap, average_precisions = mean_average_precision_for_boxes(gt, pred, iou_threshold=iou_threshold)\n",
    "print(f'mAP@{iou_threshold*100:.0f}: {mean_ap}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
