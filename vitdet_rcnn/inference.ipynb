{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d28a840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9614999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89687c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터셋 삭제\n",
    "dataset_name = 'coco_trash_test'\n",
    "if dataset_name in DatasetCatalog:\n",
    "    DatasetCatalog.remove(dataset_name)\n",
    "if dataset_name in MetadataCatalog:\n",
    "    MetadataCatalog.remove(dataset_name)\n",
    "\n",
    "# Register Dataset\n",
    "try:\n",
    "    register_coco_instances('coco_trash_test', {}, '/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/Split_data/valid_1_10.json', '/data/ephemeral/home/data/dataset/')\n",
    "except AssertionError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d82cff70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/18 12:31:15 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/swin_rcnn/output/model_final.pth ...\n",
      "\u001b[32m[10/18 12:31:17 d2.data.datasets.coco]: \u001b[0mLoaded 550 images in COCO format from /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/Split_data/valid_1_10.json\n",
      "\u001b[32m[10/18 12:31:17 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/18 12:31:17 d2.data.common]: \u001b[0mSerializing 550 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/18 12:31:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.26 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 550/550 [02:37<00:00,  3.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from detectron2.config import LazyConfig, instantiate\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.data import build_detection_test_loader\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# mapper - input data를 어떤 형식으로 return할지\n",
    "def MyMapper(dataset_dict):\n",
    "    \n",
    "    # deepcopy를 통해 원본 데이터에 영향을 주지 않음\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    \n",
    "    # file_name 확인\n",
    "    if 'file_name' not in dataset_dict:\n",
    "        raise ValueError(\"dataset_dict does not contain 'file_name'.\")\n",
    "    \n",
    "    # 이미지 읽기\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    image_tensor = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "\n",
    "    # 배치 차원 추가 (1, C, H, W)\n",
    "    #image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "    \n",
    "    # 이미지 데이터 추가\n",
    "    #image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "    dataset_dict['image'] = image_tensor  # 디버깅용 출력\n",
    "    # 변환된 데이터셋 반환\n",
    "    return dataset_dict\n",
    "\n",
    "# LazyConfig 설정 파일 로드\n",
    "cfg = LazyConfig.load(\"/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/swin_rcnn/output/config.yaml\")\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "model = instantiate(cfg.model)\n",
    "model = model.to(torch.device(\"cuda\"))\n",
    "\n",
    "cfg.MODEL = instantiate(cfg.model)\n",
    "cfg.DATALOADER = instantiate(cfg.dataloader)\n",
    "# 제안을 사용하지 않도록 설정\n",
    "cfg.MODEL.LOAD_PROPOSALS = False\n",
    "cfg.DATALOADER.test.dataset.names='coco_trash_test'\n",
    "cfg.DATALOADER.NUM_WORKERS=4,\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS=True\n",
    "\n",
    "# # num_workers와 batch_size가 ListConfig일 수 있으므로 int로 변환\n",
    "# cfg.DATALOADER.NUM_WORKERS = int(cfg.DATALOADER.NUM_WORKERS)\n",
    "# cfg.DATALOADER.BATCH_SIZE = int(cfg.DATALOADER.BATCH_SIZE)\n",
    "# 체크포인트 로드\n",
    "checkpointer = DetectionCheckpointer(model)\n",
    "checkpointer.load(\"/data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/swin_rcnn/output/model_final.pth\")\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()\n",
    "\n",
    "# test_loader 설정\n",
    "test_loader = build_detection_test_loader(cfg,'coco_trash_test',mapper=MyMapper,\n",
    "                                        num_workers=cfg.DATALOADER.NUM_WORKERS[0])\n",
    "\n",
    "# 예측 수행\n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "\n",
    "for data in tqdm(test_loader):\n",
    "    \n",
    "    prediction_string = ''\n",
    "    data=data[0]\n",
    "    with torch.no_grad():\n",
    "        batched_inputs = [{\"image\": data['image'].to(torch.device(\"cuda\"))}]\n",
    "        outputs = model(batched_inputs)[0]['instances']  # model에 올바른 형식으로 전달\n",
    "    \n",
    "    # 예측 결과 처리\n",
    "    targets = outputs.pred_classes.cpu().tolist()\n",
    "    boxes = [i.cpu().detach().numpy() for i in outputs.pred_boxes]\n",
    "    scores = outputs.scores.cpu().tolist()\n",
    "    \n",
    "    for target, box, score in zip(targets, boxes, scores):\n",
    "        prediction_string += (str(target) + ' ' + str(score) + ' ' + str(box[0]) + ' ' \n",
    "        + str(box[1]) + ' ' + str(box[2]) + ' ' + str(box[3]) + ' ')\n",
    "    \n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(data['file_name'].replace('/data/ephemeral/home/data/dataset/train/', ''))\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv(os.path.join(cfg.train.output_dir, 'submission_det2.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58d932bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/550 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', dtype=torch.int64)\n",
      "0012.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(test_loader):\n",
    "    data=data[0]\n",
    "    with torch.no_grad():\n",
    "        batched_inputs = [{\"image\": data['image'].to(torch.device(\"cuda\"))}]\n",
    "        outputs = model(batched_inputs)[0]['instances']  # model에 올바른 형식으로 전달\n",
    "    print(outputs.pred_classes)\n",
    "    print(data['file_name'].replace('/data/ephemeral/home/data/dataset/train/', ''))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
