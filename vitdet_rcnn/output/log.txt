[10/18 19:13:37] detectron2 INFO: Rank of current process: 0. World size: 1
[10/18 19:13:38] detectron2 INFO: Environment info:
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2._C                    not built correctly: /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops7reshape4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEE
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
detectron2 arch flags            /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.12.1+cu116 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            Tesla V100-SXM2-32GB (arch=7.0)
Driver version                   535.161.08
CUDA_HOME                        None - invalid!
Pillow                           10.4.0
torchvision                      0.13.1+cu116 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags           /opt/conda/lib/python3.10/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/18 19:13:38] detectron2 INFO: Command line arguments: Namespace(config_file='ViTDet/configs/COCO/mask_rcnn_vitdet_l_100ep.py', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49152', opts=[])
[10/18 19:13:38] detectron2 INFO: Contents of args.config_file=ViTDet/configs/COCO/mask_rcnn_vitdet_l_100ep.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mfunctools[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpartial[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mmask_rcnn_vitdet_b_100ep[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdataloader[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mlr_multiplier[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mmodel[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mtrain[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15moptimizer[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mget_vit_lr_decay_rate[39m[38;5;15m,[39m
[38;5;15m)[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MAE/mae_pretrain_vit_large.pth?matching_heuristics=True[39m[38;5;186m"[39m
[38;5;15m)[39m

[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15membed_dim[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15mdepth[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15mnum_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15mdrop_path_rate[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;242m# 5, 11, 17, 23 for global attention[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15mwindow_block_indexes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m5[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;197m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m6[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m11[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;197m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m17[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;197m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m18[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m23[39m[38;5;15m)[39m[38;5;15m)[39m
[38;5;15m)[39m

[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mpartial[39m[38;5;15m([39m[38;5;15mget_vit_lr_decay_rate[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mlr_decay_rate[39m[38;5;197m=[39m[38;5;141m0.8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mnum_layers[39m[38;5;197m=[39m[38;5;141m24[39m[38;5;15m)[39m

[10/18 19:13:38] detectron2 INFO: Full config saved to /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/vitdet_rcnn/output/config.yaml
[10/18 19:13:38] d2.utils.env INFO: Using a generated random seed 38698044
[10/18 19:13:43] detectron2 INFO: Model:
GeneralizedRCNN(
  (backbone): SimpleFeaturePyramid(
    (simfp_2): Sequential(
      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm()
      (2): GELU(approximate=none)
      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
      (4): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (5): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_3): Sequential(
      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
      (1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_4): Sequential(
      (0): Conv2d(
        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_5): Sequential(
      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): Conv2d(
        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (net): ViT(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      )
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.017)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.035)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.052)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.070)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.087)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (6): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.104)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (7): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.122)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (8): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.139)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (9): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.157)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (10): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.174)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (11): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.191)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (12): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.209)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (13): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.226)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (14): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.243)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (15): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.261)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (16): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.278)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (17): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.296)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (18): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.313)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (19): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.330)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (20): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.348)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (21): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.365)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (22): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.383)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (23): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.400)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
    (top_block): LastLevelMaxPool()
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Sequential(
        (conv0): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (conv1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[10/18 19:13:46] d2.data.datasets.coco INFO: Loaded 4437 images in COCO format from /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/Split_data/train_0_10.json
[10/18 19:13:46] d2.data.build INFO: Removed 0 images with no usable annotations. 4437 images left.
[10/18 19:13:46] d2.data.build INFO: Distribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
| General trash | 3523         |    Paper    | 5785         | Paper pack | 840          |
|     Metal     | 882          |    Glass    | 891          |  Plastic   | 2707         |
|   Styrofoam   | 1108         | Plastic bag | 4664         |  Battery   | 146          |
|   Clothing    | 412          |             |              |            |              |
|     total     | 20958        |             |              |            |              |[0m
[10/18 19:13:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=[1024, 1024], pad=False)]
[10/18 19:13:46] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/18 19:13:46] d2.data.common INFO: Serializing 4437 elements to byte tensors and concatenating them all ...
[10/18 19:13:46] d2.data.common INFO: Serialized dataset takes 2.07 MiB
[10/18 19:13:46] d2.data.build INFO: Making batched data loader with batch_size=2
[10/18 19:13:46] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MAE/mae_pretrain_vit_large.pth?matching_heuristics=True ...
[10/18 19:14:06] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /data/ephemeral/home/.torch/iopath_cache/detectron2/ImageNetPretrained/MAE/mae_pretrain_vit_large.pth ...
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.4.norm.bias in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.4.norm.weight in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.5.norm.bias in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.5.norm.weight in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.1.norm.bias in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.1.norm.weight in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.2.norm.bias in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.2.norm.weight in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.0.norm.bias in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.0.norm.weight in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.1.norm.bias in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.1.norm.weight in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.1.norm.bias in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.1.norm.weight in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.2.norm.bias in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.2.norm.weight in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv1.norm.bias in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv1.norm.weight in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv2.norm.bias in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv2.norm.weight in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv3.norm.bias in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv3.norm.weight in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv4.norm.bias in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv4.norm.weight in model is torch.Size([256]).
[10/18 19:14:07] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:14:07] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.net - Total num: 146
[10/18 19:14:07] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.net.blocks.0.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.1.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.10.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.11.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.12.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.13.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.14.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.15.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.16.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.17.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.18.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.19.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.2.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.20.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.21.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.22.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.23.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.3.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.4.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.5.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.6.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.7.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.8.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.9.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.simfp_2.0.{bias, weight}[0m
[34mbackbone.simfp_2.1.{bias, weight}[0m
[34mbackbone.simfp_2.3.{bias, weight}[0m
[34mbackbone.simfp_2.4.norm.{bias, weight}[0m
[34mbackbone.simfp_2.4.weight[0m
[34mbackbone.simfp_2.5.norm.{bias, weight}[0m
[34mbackbone.simfp_2.5.weight[0m
[34mbackbone.simfp_3.0.{bias, weight}[0m
[34mbackbone.simfp_3.1.norm.{bias, weight}[0m
[34mbackbone.simfp_3.1.weight[0m
[34mbackbone.simfp_3.2.norm.{bias, weight}[0m
[34mbackbone.simfp_3.2.weight[0m
[34mbackbone.simfp_4.0.norm.{bias, weight}[0m
[34mbackbone.simfp_4.0.weight[0m
[34mbackbone.simfp_4.1.norm.{bias, weight}[0m
[34mbackbone.simfp_4.1.weight[0m
[34mbackbone.simfp_5.1.norm.{bias, weight}[0m
[34mbackbone.simfp_5.1.weight[0m
[34mbackbone.simfp_5.2.norm.{bias, weight}[0m
[34mbackbone.simfp_5.2.weight[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv0.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv1.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.conv1.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv1.weight[0m
[34mroi_heads.box_head.conv2.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv2.weight[0m
[34mroi_heads.box_head.conv3.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv3.weight[0m
[34mroi_heads.box_head.conv4.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv4.weight[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[10/18 19:14:07] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mcls_token[0m
  [35mnorm.{bias, weight}[0m
[10/18 19:14:07] d2.engine.train_loop INFO: Starting training from iteration 0
[10/18 19:14:10] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py", line 504, in run_step
    self.grad_scaler.scale(losses).backward()
  File "/opt/conda/lib/python3.10/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 31.74 GiB total capacity; 28.27 GiB already allocated; 226.38 MiB free; 30.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[10/18 19:14:10] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[10/18 19:14:10] d2.utils.events INFO:  iter: 1  total_loss: 5.292  loss_cls: 4.505  loss_box_reg: 0.0001246  loss_rpn_cls: 0.6974  loss_rpn_loc: 0.08961    data_time: 0.2209  last_data_time: 0.2209   lr: 1e-07  max_mem: 29875M
[10/18 19:17:25] detectron2 INFO: Rank of current process: 0. World size: 1
[10/18 19:17:26] detectron2 INFO: Environment info:
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2._C                    not built correctly: /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops7reshape4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEE
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
detectron2 arch flags            /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.12.1+cu116 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            Tesla V100-SXM2-32GB (arch=7.0)
Driver version                   535.161.08
CUDA_HOME                        None - invalid!
Pillow                           10.4.0
torchvision                      0.13.1+cu116 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags           /opt/conda/lib/python3.10/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/18 19:17:26] detectron2 INFO: Command line arguments: Namespace(config_file='ViTDet/configs/COCO/mask_rcnn_vitdet_l_100ep.py', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49152', opts=[])
[10/18 19:17:26] detectron2 INFO: Contents of args.config_file=ViTDet/configs/COCO/mask_rcnn_vitdet_l_100ep.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mfunctools[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpartial[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mmask_rcnn_vitdet_b_100ep[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdataloader[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mlr_multiplier[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mmodel[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mtrain[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15moptimizer[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mget_vit_lr_decay_rate[39m[38;5;15m,[39m
[38;5;15m)[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MAE/mae_pretrain_vit_large.pth?matching_heuristics=True[39m[38;5;186m"[39m
[38;5;15m)[39m

[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15membed_dim[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15mdepth[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15mnum_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15mdrop_path_rate[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;242m# 5, 11, 17, 23 for global attention[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15mwindow_block_indexes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m5[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;197m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m6[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m11[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;197m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m17[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;197m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m18[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m23[39m[38;5;15m)[39m[38;5;15m)[39m
[38;5;15m)[39m

[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mpartial[39m[38;5;15m([39m[38;5;15mget_vit_lr_decay_rate[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mlr_decay_rate[39m[38;5;197m=[39m[38;5;141m0.8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mnum_layers[39m[38;5;197m=[39m[38;5;141m24[39m[38;5;15m)[39m

[10/18 19:17:26] detectron2 INFO: Full config saved to /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/vitdet_rcnn/output/config.yaml
[10/18 19:17:26] d2.utils.env INFO: Using a generated random seed 26694176
[10/18 19:17:32] detectron2 INFO: Model:
GeneralizedRCNN(
  (backbone): SimpleFeaturePyramid(
    (simfp_2): Sequential(
      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm()
      (2): GELU(approximate=none)
      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
      (4): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (5): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_3): Sequential(
      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
      (1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_4): Sequential(
      (0): Conv2d(
        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_5): Sequential(
      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): Conv2d(
        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (net): ViT(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      )
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.017)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.035)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.052)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.070)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.087)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (6): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.104)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (7): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.122)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (8): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.139)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (9): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.157)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (10): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.174)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (11): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.191)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (12): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.209)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (13): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.226)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (14): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.243)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (15): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.261)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (16): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.278)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (17): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.296)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (18): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.313)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (19): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.330)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (20): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.348)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (21): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.365)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (22): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.383)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (23): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.400)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
    (top_block): LastLevelMaxPool()
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Sequential(
        (conv0): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (conv1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=11, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)
    )
  )
)
[10/18 19:17:34] d2.data.datasets.coco INFO: Loaded 4437 images in COCO format from /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/Split_data/train_0_10.json
[10/18 19:17:34] d2.data.build INFO: Removed 0 images with no usable annotations. 4437 images left.
[10/18 19:17:34] d2.data.build INFO: Distribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
| General trash | 3523         |    Paper    | 5785         | Paper pack | 840          |
|     Metal     | 882          |    Glass    | 891          |  Plastic   | 2707         |
|   Styrofoam   | 1108         | Plastic bag | 4664         |  Battery   | 146          |
|   Clothing    | 412          |             |              |            |              |
|     total     | 20958        |             |              |            |              |[0m
[10/18 19:17:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=[1024, 1024], pad=False)]
[10/18 19:17:34] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/18 19:17:34] d2.data.common INFO: Serializing 4437 elements to byte tensors and concatenating them all ...
[10/18 19:17:34] d2.data.common INFO: Serialized dataset takes 2.07 MiB
[10/18 19:17:34] d2.data.build INFO: Making batched data loader with batch_size=2
[10/18 19:17:34] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MAE/mae_pretrain_vit_large.pth?matching_heuristics=True ...
[10/18 19:17:34] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /data/ephemeral/home/.torch/iopath_cache/detectron2/ImageNetPretrained/MAE/mae_pretrain_vit_large.pth ...
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.4.norm.bias in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.4.norm.weight in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.5.norm.bias in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.5.norm.weight in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.1.norm.bias in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.1.norm.weight in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.2.norm.bias in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.2.norm.weight in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.0.norm.bias in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.0.norm.weight in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.1.norm.bias in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.1.norm.weight in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.1.norm.bias in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.1.norm.weight in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.2.norm.bias in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.2.norm.weight in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv1.norm.bias in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv1.norm.weight in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv2.norm.bias in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv2.norm.weight in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv3.norm.bias in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv3.norm.weight in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv4.norm.bias in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv4.norm.weight in model is torch.Size([256]).
[10/18 19:17:35] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:17:35] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.net - Total num: 146
[10/18 19:17:35] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.net.blocks.0.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.1.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.10.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.11.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.12.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.13.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.14.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.15.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.16.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.17.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.18.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.19.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.2.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.20.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.21.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.22.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.23.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.3.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.4.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.5.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.6.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.7.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.8.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.9.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.simfp_2.0.{bias, weight}[0m
[34mbackbone.simfp_2.1.{bias, weight}[0m
[34mbackbone.simfp_2.3.{bias, weight}[0m
[34mbackbone.simfp_2.4.norm.{bias, weight}[0m
[34mbackbone.simfp_2.4.weight[0m
[34mbackbone.simfp_2.5.norm.{bias, weight}[0m
[34mbackbone.simfp_2.5.weight[0m
[34mbackbone.simfp_3.0.{bias, weight}[0m
[34mbackbone.simfp_3.1.norm.{bias, weight}[0m
[34mbackbone.simfp_3.1.weight[0m
[34mbackbone.simfp_3.2.norm.{bias, weight}[0m
[34mbackbone.simfp_3.2.weight[0m
[34mbackbone.simfp_4.0.norm.{bias, weight}[0m
[34mbackbone.simfp_4.0.weight[0m
[34mbackbone.simfp_4.1.norm.{bias, weight}[0m
[34mbackbone.simfp_4.1.weight[0m
[34mbackbone.simfp_5.1.norm.{bias, weight}[0m
[34mbackbone.simfp_5.1.weight[0m
[34mbackbone.simfp_5.2.norm.{bias, weight}[0m
[34mbackbone.simfp_5.2.weight[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv0.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv1.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.conv1.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv1.weight[0m
[34mroi_heads.box_head.conv2.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv2.weight[0m
[34mroi_heads.box_head.conv3.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv3.weight[0m
[34mroi_heads.box_head.conv4.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv4.weight[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[10/18 19:17:35] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mcls_token[0m
  [35mnorm.{bias, weight}[0m
[10/18 19:17:35] d2.engine.train_loop INFO: Starting training from iteration 0
[10/18 19:17:39] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py", line 504, in run_step
    self.grad_scaler.scale(losses).backward()
  File "/opt/conda/lib/python3.10/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 31.74 GiB total capacity; 28.28 GiB already allocated; 144.38 MiB free; 30.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[10/18 19:17:39] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[10/18 19:17:39] d2.utils.events INFO:  iter: 1  total_loss: 3.318  loss_cls: 2.326  loss_box_reg: 0.0007228  loss_rpn_cls: 0.6948  loss_rpn_loc: 0.2964    data_time: 0.1845  last_data_time: 0.1845   lr: 1e-07  max_mem: 29875M
[10/18 19:18:30] detectron2 INFO: Rank of current process: 0. World size: 1
[10/18 19:18:31] detectron2 INFO: Environment info:
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2._C                    not built correctly: /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops7reshape4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEE
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
detectron2 arch flags            /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.12.1+cu116 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            Tesla V100-SXM2-32GB (arch=7.0)
Driver version                   535.161.08
CUDA_HOME                        None - invalid!
Pillow                           10.4.0
torchvision                      0.13.1+cu116 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags           /opt/conda/lib/python3.10/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/18 19:18:31] detectron2 INFO: Command line arguments: Namespace(config_file='ViTDet/configs/COCO/mask_rcnn_vitdet_l_100ep.py', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49152', opts=[])
[10/18 19:18:31] detectron2 INFO: Contents of args.config_file=ViTDet/configs/COCO/mask_rcnn_vitdet_l_100ep.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mfunctools[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpartial[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mmask_rcnn_vitdet_b_100ep[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdataloader[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mlr_multiplier[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mmodel[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mtrain[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15moptimizer[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mget_vit_lr_decay_rate[39m[38;5;15m,[39m
[38;5;15m)[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MAE/mae_pretrain_vit_large.pth?matching_heuristics=True[39m[38;5;186m"[39m
[38;5;15m)[39m

[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15membed_dim[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15mdepth[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15mnum_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15mdrop_path_rate[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;242m# 5, 11, 17, 23 for global attention[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mbackbone[39m[38;5;197m.[39m[38;5;15mnet[39m[38;5;197m.[39m[38;5;15mwindow_block_indexes[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m5[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;197m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m6[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m11[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;197m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m17[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;197m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m18[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m23[39m[38;5;15m)[39m[38;5;15m)[39m
[38;5;15m)[39m

[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mpartial[39m[38;5;15m([39m[38;5;15mget_vit_lr_decay_rate[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mlr_decay_rate[39m[38;5;197m=[39m[38;5;141m0.8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mnum_layers[39m[38;5;197m=[39m[38;5;141m24[39m[38;5;15m)[39m

[10/18 19:18:31] detectron2 INFO: Full config saved to /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/vitdet_rcnn/output/config.yaml
[10/18 19:18:31] d2.utils.env INFO: Using a generated random seed 31704843
[10/18 19:18:36] detectron2 INFO: Model:
GeneralizedRCNN(
  (backbone): SimpleFeaturePyramid(
    (simfp_2): Sequential(
      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm()
      (2): GELU(approximate=none)
      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
      (4): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (5): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_3): Sequential(
      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
      (1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_4): Sequential(
      (0): Conv2d(
        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_5): Sequential(
      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): Conv2d(
        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (net): ViT(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      )
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.017)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.035)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.052)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.070)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.087)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (6): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.104)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (7): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.122)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (8): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.139)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (9): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.157)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (10): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.174)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (11): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.191)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (12): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.209)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (13): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.226)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (14): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.243)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (15): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.261)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (16): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.278)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (17): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.296)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (18): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.313)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (19): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.330)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (20): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.348)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (21): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.365)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (22): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.383)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (23): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.400)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
    (top_block): LastLevelMaxPool()
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Sequential(
        (conv0): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (conv1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=11, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)
    )
  )
)
[10/18 19:18:39] d2.data.datasets.coco INFO: Loaded 4437 images in COCO format from /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/Split_data/train_0_10.json
[10/18 19:18:39] d2.data.build INFO: Removed 0 images with no usable annotations. 4437 images left.
[10/18 19:18:39] d2.data.build INFO: Distribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
| General trash | 3523         |    Paper    | 5785         | Paper pack | 840          |
|     Metal     | 882          |    Glass    | 891          |  Plastic   | 2707         |
|   Styrofoam   | 1108         | Plastic bag | 4664         |  Battery   | 146          |
|   Clothing    | 412          |             |              |            |              |
|     total     | 20958        |             |              |            |              |[0m
[10/18 19:18:39] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=[1024, 1024], pad=False)]
[10/18 19:18:39] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/18 19:18:39] d2.data.common INFO: Serializing 4437 elements to byte tensors and concatenating them all ...
[10/18 19:18:39] d2.data.common INFO: Serialized dataset takes 2.07 MiB
[10/18 19:18:39] d2.data.build INFO: Making batched data loader with batch_size=1
[10/18 19:18:39] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MAE/mae_pretrain_vit_large.pth?matching_heuristics=True ...
[10/18 19:18:39] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /data/ephemeral/home/.torch/iopath_cache/detectron2/ImageNetPretrained/MAE/mae_pretrain_vit_large.pth ...
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.4.norm.bias in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.4.norm.weight in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.5.norm.bias in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.5.norm.weight in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.1.norm.bias in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.1.norm.weight in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.2.norm.bias in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.2.norm.weight in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.0.norm.bias in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.0.norm.weight in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.1.norm.bias in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.1.norm.weight in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.1.norm.bias in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.1.norm.weight in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.2.norm.bias in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.2.norm.weight in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv1.norm.bias in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv1.norm.weight in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv2.norm.bias in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv2.norm.weight in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv3.norm.bias in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv3.norm.weight in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv4.norm.bias in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv4.norm.weight in model is torch.Size([256]).
[10/18 19:18:40] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/18 19:18:40] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.net - Total num: 146
[10/18 19:18:40] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.net.blocks.0.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.1.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.10.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.11.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.12.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.13.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.14.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.15.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.16.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.17.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.18.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.19.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.2.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.20.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.21.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.22.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.23.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.3.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.4.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.5.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.6.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.7.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.8.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.9.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.simfp_2.0.{bias, weight}[0m
[34mbackbone.simfp_2.1.{bias, weight}[0m
[34mbackbone.simfp_2.3.{bias, weight}[0m
[34mbackbone.simfp_2.4.norm.{bias, weight}[0m
[34mbackbone.simfp_2.4.weight[0m
[34mbackbone.simfp_2.5.norm.{bias, weight}[0m
[34mbackbone.simfp_2.5.weight[0m
[34mbackbone.simfp_3.0.{bias, weight}[0m
[34mbackbone.simfp_3.1.norm.{bias, weight}[0m
[34mbackbone.simfp_3.1.weight[0m
[34mbackbone.simfp_3.2.norm.{bias, weight}[0m
[34mbackbone.simfp_3.2.weight[0m
[34mbackbone.simfp_4.0.norm.{bias, weight}[0m
[34mbackbone.simfp_4.0.weight[0m
[34mbackbone.simfp_4.1.norm.{bias, weight}[0m
[34mbackbone.simfp_4.1.weight[0m
[34mbackbone.simfp_5.1.norm.{bias, weight}[0m
[34mbackbone.simfp_5.1.weight[0m
[34mbackbone.simfp_5.2.norm.{bias, weight}[0m
[34mbackbone.simfp_5.2.weight[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv0.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv1.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.conv1.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv1.weight[0m
[34mroi_heads.box_head.conv2.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv2.weight[0m
[34mroi_heads.box_head.conv3.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv3.weight[0m
[34mroi_heads.box_head.conv4.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv4.weight[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[10/18 19:18:40] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mcls_token[0m
  [35mnorm.{bias, weight}[0m
[10/18 19:18:40] d2.engine.train_loop INFO: Starting training from iteration 0
[10/18 19:18:52] d2.utils.events INFO:  eta: 1 day, 1:51:24  iter: 19  total_loss: 2.955  loss_cls: 2.152  loss_box_reg: 0.006538  loss_rpn_cls: 0.6898  loss_rpn_loc: 0.02571    time: 0.5020  last_time: 0.5045  data_time: 0.0123  last_data_time: 0.0032   lr: 7.6924e-06  max_mem: 19559M
[10/18 19:19:02] d2.utils.events INFO:  eta: 1 day, 1:51:54  iter: 39  total_loss: 1.27  loss_cls: 0.3713  loss_box_reg: 0.0345  loss_rpn_cls: 0.6777  loss_rpn_loc: 0.02309    time: 0.5034  last_time: 0.5078  data_time: 0.0032  last_data_time: 0.0042   lr: 1.5684e-05  max_mem: 19559M
[10/18 19:19:13] d2.utils.events INFO:  eta: 1 day, 1:51:34  iter: 59  total_loss: 0.8009  loss_cls: 0.07074  loss_box_reg: 0.01707  loss_rpn_cls: 0.6411  loss_rpn_loc: 0.03274    time: 0.5037  last_time: 0.5053  data_time: 0.0035  last_data_time: 0.0054   lr: 2.3676e-05  max_mem: 19559M
[10/18 19:19:23] d2.utils.events INFO:  eta: 1 day, 1:51:34  iter: 79  total_loss: 0.829  loss_cls: 0.1857  loss_box_reg: 0.09851  loss_rpn_cls: 0.4599  loss_rpn_loc: 0.02488    time: 0.5039  last_time: 0.5056  data_time: 0.0029  last_data_time: 0.0029   lr: 3.1668e-05  max_mem: 19559M
[10/18 19:19:33] d2.utils.events INFO:  eta: 1 day, 1:51:34  iter: 99  total_loss: 0.5599  loss_cls: 0.154  loss_box_reg: 0.093  loss_rpn_cls: 0.2016  loss_rpn_loc: 0.1007    time: 0.5044  last_time: 0.5027  data_time: 0.0030  last_data_time: 0.0028   lr: 3.966e-05  max_mem: 19561M
[10/18 19:19:34] d2.engine.hooks INFO: Overall training speed: 99 iterations in 0:00:50 (0.5090 s / it)
[10/18 19:19:34] d2.engine.hooks INFO: Total training time: 0:00:50 (0:00:00 on hooks)
[10/18 19:19:34] d2.utils.events INFO:  eta: 1 day, 1:51:33  iter: 101  total_loss: 0.5599  loss_cls: 0.1685  loss_box_reg: 0.09154  loss_rpn_cls: 0.2016  loss_rpn_loc: 0.1007    time: 0.5044  last_time: 0.5022  data_time: 0.0030  last_data_time: 0.0027   lr: 4.006e-05  max_mem: 19561M
[10/19 21:11:53] detectron2 INFO: Rank of current process: 0. World size: 1
[10/19 21:11:54] detectron2 INFO: Environment info:
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2._C                    not built correctly: /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops7reshape4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEE
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
detectron2 arch flags            /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.12.1+cu116 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            Tesla V100-SXM2-32GB (arch=7.0)
Driver version                   535.161.08
CUDA_HOME                        None - invalid!
Pillow                           11.0.0
torchvision                      0.13.1+cu116 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags           /opt/conda/lib/python3.10/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.10.0
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/19 21:11:54] detectron2 INFO: Command line arguments: Namespace(config_file='ViTDet/configs/COCO/mask_rcnn_vitdet_l_100ep.py', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49152', opts=[])
[10/19 21:11:54] detectron2 INFO: Contents of args.config_file=ViTDet/configs/COCO/mask_rcnn_vitdet_l_100ep.py:
[38;5;204mfrom[39m[38;5;15m [39m[38;5;15mfunctools[39m[38;5;15m [39m[38;5;204mimport[39m[38;5;15m [39m[38;5;15mpartial[39m

[38;5;204mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mmask_rcnn_vitdet_b_100ep[39m[38;5;15m [39m[38;5;204mimport[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdataloader[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mlr_multiplier[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mmodel[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mtrain[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15moptimizer[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mget_vit_lr_decay_rate[39m[38;5;15m,[39m
[38;5;15m)[39m

[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MAE/mae_pretrain_vit_large.pth?matching_heuristics=True[39m[38;5;186m"[39m
[38;5;15m)[39m

[38;5;15mmodel[39m[38;5;204m.[39m[38;5;15mbackbone[39m[38;5;204m.[39m[38;5;15mnet[39m[38;5;204m.[39m[38;5;15membed_dim[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;204m.[39m[38;5;15mbackbone[39m[38;5;204m.[39m[38;5;15mnet[39m[38;5;204m.[39m[38;5;15mdepth[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15mmodel[39m[38;5;204m.[39m[38;5;15mbackbone[39m[38;5;204m.[39m[38;5;15mnet[39m[38;5;204m.[39m[38;5;15mnum_heads[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15mmodel[39m[38;5;204m.[39m[38;5;15mbackbone[39m[38;5;204m.[39m[38;5;15mnet[39m[38;5;204m.[39m[38;5;15mdrop_path_rate[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;245m# 5, 11, 17, 23 for global attention[39m
[38;5;15mmodel[39m[38;5;204m.[39m[38;5;15mbackbone[39m[38;5;204m.[39m[38;5;15mnet[39m[38;5;204m.[39m[38;5;15mwindow_block_indexes[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m5[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;204m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m6[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m11[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;204m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m17[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;204m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m18[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m23[39m[38;5;15m)[39m[38;5;15m)[39m
[38;5;15m)[39m

[38;5;15moptimizer[39m[38;5;204m.[39m[38;5;15mparams[39m[38;5;204m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mpartial[39m[38;5;15m([39m[38;5;15mget_vit_lr_decay_rate[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mlr_decay_rate[39m[38;5;204m=[39m[38;5;141m0.8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mnum_layers[39m[38;5;204m=[39m[38;5;141m24[39m[38;5;15m)[39m

[10/19 21:11:54] detectron2 INFO: Full config saved to /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/vitdet_rcnn/output/config.yaml
[10/19 21:11:54] d2.utils.env INFO: Using a generated random seed 54505279
[10/19 21:12:00] detectron2 INFO: Model:
GeneralizedRCNN(
  (backbone): SimpleFeaturePyramid(
    (simfp_2): Sequential(
      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm()
      (2): GELU(approximate=none)
      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
      (4): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (5): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_3): Sequential(
      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
      (1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_4): Sequential(
      (0): Conv2d(
        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_5): Sequential(
      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): Conv2d(
        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (net): ViT(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      )
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.017)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.035)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.052)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.070)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.087)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (6): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.104)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (7): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.122)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (8): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.139)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (9): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.157)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (10): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.174)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (11): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.191)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (12): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.209)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (13): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.226)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (14): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.243)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (15): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.261)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (16): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.278)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (17): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.296)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (18): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.313)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (19): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.330)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (20): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.348)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (21): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.365)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (22): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.383)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (23): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.400)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
    (top_block): LastLevelMaxPool()
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Sequential(
        (conv0): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (conv1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=11, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)
    )
  )
)
[10/19 21:12:04] d2.data.datasets.coco INFO: Loaded 4437 images in COCO format from /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/Split_data/train_0_10.json
[10/19 21:12:04] d2.data.build INFO: Removed 0 images with no usable annotations. 4437 images left.
[10/19 21:12:04] d2.data.build INFO: Distribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
| General trash | 3523         |    Paper    | 5785         | Paper pack | 840          |
|     Metal     | 882          |    Glass    | 891          |  Plastic   | 2707         |
|   Styrofoam   | 1108         | Plastic bag | 4664         |  Battery   | 146          |
|   Clothing    | 412          |             |              |            |              |
|     total     | 20958        |             |              |            |              |[0m
[10/19 21:13:39] detectron2 INFO: Rank of current process: 0. World size: 1
[10/19 21:13:39] detectron2 INFO: Environment info:
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2._C                    not built correctly: /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops7reshape4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEE
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
detectron2 arch flags            /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.12.1+cu116 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            Tesla V100-SXM2-32GB (arch=7.0)
Driver version                   535.161.08
CUDA_HOME                        None - invalid!
Pillow                           11.0.0
torchvision                      0.13.1+cu116 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags           /opt/conda/lib/python3.10/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.10.0
-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/19 21:13:39] detectron2 INFO: Command line arguments: Namespace(config_file='ViTDet/configs/COCO/mask_rcnn_vitdet_l_100ep.py', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49152', opts=[])
[10/19 21:13:39] detectron2 INFO: Contents of args.config_file=ViTDet/configs/COCO/mask_rcnn_vitdet_l_100ep.py:
[38;5;204mfrom[39m[38;5;15m [39m[38;5;15mfunctools[39m[38;5;15m [39m[38;5;204mimport[39m[38;5;15m [39m[38;5;15mpartial[39m

[38;5;204mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mmask_rcnn_vitdet_b_100ep[39m[38;5;15m [39m[38;5;204mimport[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdataloader[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mlr_multiplier[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mmodel[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mtrain[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15moptimizer[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15mget_vit_lr_decay_rate[39m[38;5;15m,[39m
[38;5;15m)[39m

[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MAE/mae_pretrain_vit_large.pth?matching_heuristics=True[39m[38;5;186m"[39m
[38;5;15m)[39m

[38;5;15mmodel[39m[38;5;204m.[39m[38;5;15mbackbone[39m[38;5;204m.[39m[38;5;15mnet[39m[38;5;204m.[39m[38;5;15membed_dim[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;204m.[39m[38;5;15mbackbone[39m[38;5;204m.[39m[38;5;15mnet[39m[38;5;204m.[39m[38;5;15mdepth[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15mmodel[39m[38;5;204m.[39m[38;5;15mbackbone[39m[38;5;204m.[39m[38;5;15mnet[39m[38;5;204m.[39m[38;5;15mnum_heads[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15mmodel[39m[38;5;204m.[39m[38;5;15mbackbone[39m[38;5;204m.[39m[38;5;15mnet[39m[38;5;204m.[39m[38;5;15mdrop_path_rate[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;245m# 5, 11, 17, 23 for global attention[39m
[38;5;15mmodel[39m[38;5;204m.[39m[38;5;15mbackbone[39m[38;5;204m.[39m[38;5;15mnet[39m[38;5;204m.[39m[38;5;15mwindow_block_indexes[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m5[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;204m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m6[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m11[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;204m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m17[39m[38;5;15m)[39m[38;5;15m)[39m[38;5;15m [39m[38;5;204m+[39m[38;5;15m [39m[38;5;15mlist[39m[38;5;15m([39m[38;5;15mrange[39m[38;5;15m([39m[38;5;141m18[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m23[39m[38;5;15m)[39m[38;5;15m)[39m
[38;5;15m)[39m

[38;5;15moptimizer[39m[38;5;204m.[39m[38;5;15mparams[39m[38;5;204m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mpartial[39m[38;5;15m([39m[38;5;15mget_vit_lr_decay_rate[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mlr_decay_rate[39m[38;5;204m=[39m[38;5;141m0.8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mnum_layers[39m[38;5;204m=[39m[38;5;141m24[39m[38;5;15m)[39m

[10/19 21:13:39] detectron2 INFO: Full config saved to /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/vitdet_rcnn/output/config.yaml
[10/19 21:13:39] d2.utils.env INFO: Using a generated random seed 40210610
[10/19 21:13:46] detectron2 INFO: Model:
GeneralizedRCNN(
  (backbone): SimpleFeaturePyramid(
    (simfp_2): Sequential(
      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm()
      (2): GELU(approximate=none)
      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
      (4): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (5): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_3): Sequential(
      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
      (1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_4): Sequential(
      (0): Conv2d(
        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_5): Sequential(
      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): Conv2d(
        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (net): ViT(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      )
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.017)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.035)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.052)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.070)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.087)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (6): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.104)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (7): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.122)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (8): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.139)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (9): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.157)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (10): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.174)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (11): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.191)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (12): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.209)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (13): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.226)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (14): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.243)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (15): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.261)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (16): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.278)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (17): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.296)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (18): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.313)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (19): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.330)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (20): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.348)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (21): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.365)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (22): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.383)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (23): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.400)
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
    (top_block): LastLevelMaxPool()
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Sequential(
        (conv0): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (conv1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=11, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)
    )
  )
)
[10/19 21:13:50] d2.data.datasets.coco INFO: Loaded 4437 images in COCO format from /data/ephemeral/home/Seungcheol/level2-objectdetection-cv-07/Split_data/train_0_10.json
[10/19 21:13:50] d2.data.build INFO: Removed 0 images with no usable annotations. 4437 images left.
[10/19 21:13:50] d2.data.build INFO: Distribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
| General trash | 3523         |    Paper    | 5785         | Paper pack | 840          |
|     Metal     | 882          |    Glass    | 891          |  Plastic   | 2707         |
|   Styrofoam   | 1108         | Plastic bag | 4664         |  Battery   | 146          |
|   Clothing    | 412          |             |              |            |              |
|     total     | 20958        |             |              |            |              |[0m
[10/19 21:13:50] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomFlip(prob=0.5, horizontal=False, vertical=True), RandomBrightness(intensity_min=0.8, intensity_max=1.8), RandomContrast(intensity_min=0.6, intensity_max=1.3)]
[10/19 21:13:50] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/19 21:13:50] d2.data.common INFO: Serializing 4437 elements to byte tensors and concatenating them all ...
[10/19 21:13:50] d2.data.common INFO: Serialized dataset takes 2.07 MiB
[10/19 21:13:50] d2.data.build INFO: Making batched data loader with batch_size=4
[10/19 21:13:50] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MAE/mae_pretrain_vit_large.pth?matching_heuristics=True ...
[10/19 21:13:50] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /data/ephemeral/home/.torch/iopath_cache/detectron2/ImageNetPretrained/MAE/mae_pretrain_vit_large.pth ...
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.4.norm.bias in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.4.norm.weight in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.5.norm.bias in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_2.5.norm.weight in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.1.norm.bias in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.1.norm.weight in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.2.norm.bias in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_3.2.norm.weight in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.0.norm.bias in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.0.norm.weight in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.1.norm.bias in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_4.1.norm.weight in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.1.norm.bias in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.1.norm.weight in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.2.norm.bias in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of backbone.simfp_5.2.norm.weight in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv1.norm.bias in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv1.norm.weight in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv2.norm.bias in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv2.norm.weight in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv3.norm.bias in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv3.norm.weight in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv4.norm.bias in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([1024]), while shape of roi_heads.box_head.conv4.norm.weight in model is torch.Size([256]).
[10/19 21:13:51] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/19 21:13:51] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.net - Total num: 146
[10/19 21:13:51] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.net.blocks.0.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.1.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.10.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.11.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.12.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.13.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.14.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.15.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.16.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.17.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.18.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.19.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.2.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.20.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.21.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.22.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.23.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.3.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.4.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.5.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.6.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.7.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.8.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.net.blocks.9.attn.{rel_pos_h, rel_pos_w}[0m
[34mbackbone.simfp_2.0.{bias, weight}[0m
[34mbackbone.simfp_2.1.{bias, weight}[0m
[34mbackbone.simfp_2.3.{bias, weight}[0m
[34mbackbone.simfp_2.4.norm.{bias, weight}[0m
[34mbackbone.simfp_2.4.weight[0m
[34mbackbone.simfp_2.5.norm.{bias, weight}[0m
[34mbackbone.simfp_2.5.weight[0m
[34mbackbone.simfp_3.0.{bias, weight}[0m
[34mbackbone.simfp_3.1.norm.{bias, weight}[0m
[34mbackbone.simfp_3.1.weight[0m
[34mbackbone.simfp_3.2.norm.{bias, weight}[0m
[34mbackbone.simfp_3.2.weight[0m
[34mbackbone.simfp_4.0.norm.{bias, weight}[0m
[34mbackbone.simfp_4.0.weight[0m
[34mbackbone.simfp_4.1.norm.{bias, weight}[0m
[34mbackbone.simfp_4.1.weight[0m
[34mbackbone.simfp_5.1.norm.{bias, weight}[0m
[34mbackbone.simfp_5.1.weight[0m
[34mbackbone.simfp_5.2.norm.{bias, weight}[0m
[34mbackbone.simfp_5.2.weight[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv0.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv1.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.conv1.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv1.weight[0m
[34mroi_heads.box_head.conv2.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv2.weight[0m
[34mroi_heads.box_head.conv3.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv3.weight[0m
[34mroi_heads.box_head.conv4.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv4.weight[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[10/19 21:13:51] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mcls_token[0m
  [35mnorm.{bias, weight}[0m
[10/19 21:13:51] d2.engine.train_loop INFO: Starting training from iteration 0
[10/19 21:13:54] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py", line 494, in run_step
    loss_dict = self.model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/detectron2/modeling/meta_arch/rcnn.py", line 158, in forward
    features = self.backbone(images.tensor)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/vit.py", line 489, in forward
    bottom_up_features = self.net(x)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/vit.py", line 357, in forward
    x = blk(x)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/vit.py", line 216, in forward
    x, pad_hw = window_partition(x, self.window_size)
  File "/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/utils.py", line 36, in window_partition
    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)
RuntimeError: CUDA out of memory. Tried to allocate 78.00 MiB (GPU 0; 31.74 GiB total capacity; 5.64 GiB already allocated; 40.38 MiB free; 5.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[10/19 21:13:54] d2.engine.hooks INFO: Total training time: 0:00:02 (0:00:00 on hooks)
[10/19 21:13:54] d2.utils.events INFO:  iter: 0       lr: N/A  max_mem: 5775M
